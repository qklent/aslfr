{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import sklearn\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_folder = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ordinal Encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ordinal Encoding\n",
       "                  0\n",
       "!                 1\n",
       "#                 2\n",
       "$                 3\n",
       "%                 4\n",
       "&                 5\n",
       "'                 6\n",
       "(                 7\n",
       ")                 8\n",
       "*                 9\n",
       "+                10\n",
       ",                11\n",
       "-                12\n",
       ".                13\n",
       "/                14\n",
       "0                15\n",
       "1                16\n",
       "2                17\n",
       "3                18\n",
       "4                19\n",
       "5                20\n",
       "6                21\n",
       "7                22\n",
       "8                23\n",
       "9                24\n",
       ":                25\n",
       ";                26\n",
       "=                27\n",
       "?                28\n",
       "@                29\n",
       "[                30\n",
       "_                31\n",
       "a                32\n",
       "b                33\n",
       "c                34\n",
       "d                35\n",
       "e                36\n",
       "f                37\n",
       "g                38\n",
       "h                39\n",
       "i                40\n",
       "j                41\n",
       "k                42\n",
       "l                43\n",
       "m                44\n",
       "n                45\n",
       "o                46\n",
       "p                47\n",
       "q                48\n",
       "r                49\n",
       "s                50\n",
       "t                51\n",
       "u                52\n",
       "v                53\n",
       "w                54\n",
       "x                55\n",
       "y                56\n",
       "z                57\n",
       "~                58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_to_data_folder + '/character_to_prediction_index.json') as json_file:\n",
    "    CHAR2ORD = json.load(json_file)\n",
    "    \n",
    "ORD2CHAR = {j:i for i,j in CHAR2ORD.items()}\n",
    "    \n",
    "display(pd.Series(CHAR2ORD).to_frame('Ordinal Encoding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "SEED = 1337\n",
    "DEBUG = True\n",
    "N_UNIQUE_CHARACTERS = len(CHAR2ORD) + 1 + 1 + 1 + 1#\n",
    "PAD_TOKEN = len(CHAR2ORD) # Padding\n",
    "SOS_TOKEN = len(CHAR2ORD) + 1 # Start Of Sentence\n",
    "EOS_TOKEN = len(CHAR2ORD) + 2 # End Of Sentence\n",
    "NAN_TOKEN = len(CHAR2ORD) + 3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 2 #if IS_INTERACTIVE else 100\n",
    "NUM_WARMUP_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.05\n",
    "NUM_WORKERS = 2\n",
    "TRAIN_MODEL = True\n",
    "LOAD_WEIGHTS = False\n",
    "MAX_LR = 1e-3\n",
    "WARMUP_METHOD = 'exp'\n",
    "USE_VAL = True\n",
    "MAX_PHRASE_LENGTH = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f27e85bb650>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORD2CHAR[PAD_TOKEN] = \"<PAD>\"\n",
    "ORD2CHAR[SOS_TOKEN] = \"<SOS>\"\n",
    "ORD2CHAR[EOS_TOKEN] = \"<EOS>\"\n",
    "ORD2CHAR[NAN_TOKEN] = \"<NAN>\"\n",
    "CHAR2ORD[\"<PAD>\"] = PAD_TOKEN\n",
    "ORD2CHAR[\"<SOS>\"] = SOS_TOKEN\n",
    "ORD2CHAR[\"<EOS>\"] = EOS_TOKEN\n",
    "CHAR2ORD[\"<NAN>\"] = NAN_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (54719, 128, 164), X_val shape: (7236, 128, 164)\n"
     ]
    }
   ],
   "source": [
    "if USE_VAL:\n",
    "    # TRAIN\n",
    "    X_train = np.load(path_to_data_folder + '/X_train.npy')\n",
    "    y_train = np.load(path_to_data_folder + '/y_train.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    # VAL\n",
    "    X_val = np.load(path_to_data_folder + '/X_val.npy')\n",
    "    y_val = np.load(path_to_data_folder + '/y_val.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_VAL_SAMPLES = len(X_val)\n",
    "    # Shapes\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "# Train On All Data\n",
    "else:\n",
    "    # TRAIN\n",
    "    X_train = np.load(path_to_data_folder + '/X.npy')\n",
    "    y_train = np.load(path_to_data_folder + '/y.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    print(f'X_train shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in X i've right hand, left hand, lips coords(x,y) for i in range(number of frames)\n",
    "\n",
    "and in y i have char for X hands and lips position\n",
    "\n",
    "the main problem is that there are 128 frames and only 31 letters, so i gotta combine some frames that represent the same letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54719, 33)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "stride = 2\n",
    "n_embd = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignRecognition(nn.Module):\n",
    "    def __init__(self, frames, kernel_size=2, stride=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(frames, frames // 4, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(frames // 4)\n",
    "        self.lin1 = nn.Linear(41, 128)\n",
    "        self.lin2 = nn.Linear(128, N_UNIQUE_CHARACTERS)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 128 41 1\n",
    "        x = self.gelu(self.bn1(x))\n",
    "        x = x.squeeze(dim=-1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianConfig {\n",
       "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-zh-en\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"swish\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"MarianMTModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bad_words_ids\": [\n",
       "    [\n",
       "      65000\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_attention_heads\": 8,\n",
       "  \"decoder_ffn_dim\": 2048,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 65000,\n",
       "  \"decoder_vocab_size\": 65001,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 8,\n",
       "  \"encoder_ffn_dim\": 2048,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"extra_pos_embeddings\": 65001,\n",
       "  \"forced_eos_token_id\": 0,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_length\": 512,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"marian\",\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 6,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 65000,\n",
       "  \"scale_embedding\": true,\n",
       "  \"share_encoder_decoder_embeddings\": true,\n",
       "  \"static_position_embeddings\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 65001\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vocab_size = N_UNIQUE_CHARACTERS\n",
    "config.max_length = MAX_PHRASE_LENGTH\n",
    "config.max_position_embeddings = MAX_PHRASE_LENGTH\n",
    "config.pad_token_id = PAD_TOKEN\n",
    "config.bos_token_id = SOS_TOKEN # <SOS>\n",
    "config.eos_token_id = EOS_TOKEN\n",
    "config.decoder_start_token_id = SOS_TOKEN\n",
    "config.decoder_vocab_size = N_UNIQUE_CHARACTERS\n",
    "config.extra_pos_embeddings = MAX_PHRASE_LENGTH\n",
    "config.forced_eos_token_id = EOS_TOKEN\n",
    "config.d_model = 128 # this is n_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianConfig {\n",
       "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-zh-en\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"swish\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"MarianMTModel\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bad_words_ids\": [\n",
       "    [\n",
       "      65000\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 60,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 128,\n",
       "  \"decoder_attention_heads\": 8,\n",
       "  \"decoder_ffn_dim\": 2048,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 60,\n",
       "  \"decoder_vocab_size\": 63,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 8,\n",
       "  \"encoder_ffn_dim\": 2048,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 61,\n",
       "  \"extra_pos_embeddings\": 33,\n",
       "  \"forced_eos_token_id\": 61,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"max_length\": 33,\n",
       "  \"max_position_embeddings\": 33,\n",
       "  \"model_type\": \"marian\",\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 6,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 59,\n",
       "  \"scale_embedding\": true,\n",
       "  \"share_encoder_decoder_embeddings\": true,\n",
       "  \"static_position_embeddings\": true,\n",
       "  \"transformers_version\": \"4.31.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 63\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Some weights of MarianMTModel were not initialized from the model checkpoint at Helsinki-NLP/opus-mt-zh-en and are newly initialized because the shapes did not match:\n",
      "- final_logits_bias: found shape torch.Size([1, 65001]) in the checkpoint and torch.Size([1, 63]) in the model instantiated\n",
      "- model.shared.weight: found shape torch.Size([65001, 512]) in the checkpoint and torch.Size([63, 128]) in the model instantiated\n",
      "- model.encoder.embed_tokens.weight: found shape torch.Size([65001, 512]) in the checkpoint and torch.Size([63, 128]) in the model instantiated\n",
      "- model.encoder.embed_positions.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([33, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.0.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.0.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.0.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.1.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.1.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.1.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.2.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.2.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.2.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.3.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.3.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.3.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.4.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.4.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.4.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.encoder.layers.5.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.encoder.layers.5.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.encoder.layers.5.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.embed_tokens.weight: found shape torch.Size([65001, 512]) in the checkpoint and torch.Size([63, 128]) in the model instantiated\n",
      "- model.decoder.embed_positions.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([33, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.0.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.0.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.0.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.1.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.1.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.1.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.2.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.2.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.2.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.3.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.3.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.3.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.4.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.4.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.4.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.self_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.k_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.k_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.v_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.v_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.q_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.q_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.out_proj.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([128, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn.out_proj.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.encoder_attn_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.fc1.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 128]) in the model instantiated\n",
      "- model.decoder.layers.5.fc2.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([128, 2048]) in the model instantiated\n",
      "- model.decoder.layers.5.fc2.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "- model.decoder.layers.5.final_layer_norm.bias: found shape torch.Size([512]) in the checkpoint and torch.Size([128]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\", config=config)\n",
    "transformer = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\", config=config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model_weights(layer):\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f\"weights were resetted for {layer}\")\n",
    "        layer.reset_parameters()\n",
    "    else:\n",
    "        if hasattr(layer, 'children'):\n",
    "            for child in layer.children():\n",
    "                reset_model_weights(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights were resetted for Embedding(63, 128, padding_idx=59)\n",
      "weights were resetted for Embedding(63, 128, padding_idx=59)\n",
      "weights were resetted for MarianSinusoidalPositionalEmbedding(33, 128)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Embedding(63, 128, padding_idx=59)\n",
      "weights were resetted for MarianSinusoidalPositionalEmbedding(33, 128)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=2048, bias=True)\n",
      "weights were resetted for Linear(in_features=2048, out_features=128, bias=True)\n",
      "weights were resetted for LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "weights were resetted for Linear(in_features=128, out_features=63, bias=False)\n"
     ]
    }
   ],
   "source": [
    "reset_model_weights(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.to(device)\n",
    "cnn = SignRecognition(128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def encode(out: torch.tensor) -> str:\n",
    "        \"\"\"\n",
    "        encode output of model into text\n",
    "        \"\"\"\n",
    "        text = []\n",
    "        for x in out:\n",
    "            token = x.argmax().item()\n",
    "            if token == PAD_TOKEN:\n",
    "                continue # what if pad token will be in the middle of sentence\n",
    "            text.append(ORD2CHAR[token])\n",
    "        return ''.join(text)\n",
    "    \n",
    "    def decode(string: str) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        decode string into vocab size space so that i can put it as my target while training\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for symbol in string:\n",
    "            out.append(CHAR2ORD[symbol])\n",
    "        \n",
    "        return torch.tensor(out)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    X_val = torch.from_numpy(X_val)\n",
    "    y_val = torch.from_numpy(y_val).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54719, 128, 82, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples, frames, features = X_train.shape\n",
    "X_train = X_train.view(num_examples, frames, features // 2, 2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    num_examples, frames, features = X_val.shape\n",
    "    X_val = X_val.view(num_examples, frames, features // 2, 2)\n",
    "    X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    y_val = y_val.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54719, 33])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids_train = torch.zeros_like(y_train)\n",
    "decoder_input_ids_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    decoder_input_ids_train[i] = torch.concat((torch.tensor([SOS_TOKEN]), y_train[i][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    decoder_input_ids_val = torch.zeros_like(y_val)\n",
    "    decoder_input_ids_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    for i in range(len(y_val)):\n",
    "        decoder_input_ids_val[i] = torch.concat((torch.tensor([SOS_TOKEN]), y_val[i][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids_train = decoder_input_ids_train.type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    decoder_input_ids_val = decoder_input_ids_val.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, decoder_input_ids):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.decoder_input_ids = decoder_input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        decoder_input_ids = self.decoder_input_ids[index]\n",
    "        return x, y, decoder_input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, decoder_input_ids_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset(X_val, y_val, decoder_input_ids_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(target: torch.tensor):\n",
    "    answer = []\n",
    "    for x in target:\n",
    "        if x != PAD_TOKEN:\n",
    "            answer.append(ORD2CHAR[x.item()])\n",
    "    return \"\".join(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred: torch.tensor, target:torch.tensor):\n",
    "    # shouldn't count pad token \n",
    "    # if i would use it in model\n",
    "    # since levenshtein distance is not linear i'll return N and D of each batch and then sum them\n",
    "    D = 0\n",
    "    N = 0\n",
    "    for i in range(len(pred)):# through batches\n",
    "        p = encode(pred[i])\n",
    "        t = encode_target(target[i])\n",
    "        distance = Levenshtein.distance(p, t)\n",
    "        \n",
    "        D += distance\n",
    "        N += len(p) + len(t)\n",
    "    \n",
    "    return N, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing metric\n",
    "# for idx, (x, y) in enumerate(train_dataloader):\n",
    "#     out = model(x)\n",
    "#     print(metric(out, y))\n",
    "#     if idx > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train parameters(optimizer, loss, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_cnn = nn.NLLLoss()\n",
    "transformer_optimizer = torch.optim.AdamW(\n",
    "    transformer.parameters(),\n",
    "    lr = 1e-6\n",
    ")\n",
    "cnn_optimizer = torch.optim.AdamW(\n",
    "    cnn.parameters(),\n",
    "    lr = 1e-6\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cnn = cnn.to(device)\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "transformer, transformer_optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    transformer, transformer_optimizer, train_dataloader, val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting on single example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32\n",
      "0 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>transformer_optimizer.step()                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>transformer_optimizer.zero_grad()                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>20 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>loss_cnn = loss_fn_cnn(signs, y)                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>loss_cnn.backward()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>cnn_optimizer.step()                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>cnn_optimizer.zero_grad()                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">216</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index = ignore_index                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 215 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 216 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.nll_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, ignore_index=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 217 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 218 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 219 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">NLLLoss2d</span>(NLLLoss):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2704</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">nll_loss</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2701 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2702 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2703 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2704 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.nll_loss_nd(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(reduction  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2705 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2706 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2707 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">poisson_nll_loss</span>(                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Expected target size <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">63</span><span style=\"font-weight: bold\">]</span>, got <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m20\u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m      \u001b[0mtransformer_optimizer.step()                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m      \u001b[0mtransformer_optimizer.zero_grad()                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m      \u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m20 \u001b[2m      \u001b[0mloss_cnn = loss_fn_cnn(signs, y)                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m      \u001b[0mloss_cnn.backward()                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m      \u001b[0mcnn_optimizer.step()                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m      \u001b[0mcnn_optimizer.zero_grad()                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtorch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtorch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m216\u001b[0m in \u001b[92mforward\u001b[0m                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 213 \u001b[0m\u001b[2m      \u001b[0m\u001b[96mself\u001b[0m.ignore_index = ignore_index                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 214 \u001b[0m\u001b[2m   \u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 215 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 216 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m F.nll_loss(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight, ignore_index=\u001b[96mself\u001b[0m.ignore_in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 217 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 218 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 219 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mNLLLoss2d\u001b[0m(NLLLoss):                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtorch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m2704\u001b[0m in \u001b[92mnll_loss\u001b[0m                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2701 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2702 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2703 \u001b[0m\u001b[2m      \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2704 \u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.nll_loss_nd(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(reduction  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2705 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2706 \u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2707 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpoisson_nll_loss\u001b[0m(                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mExpected target size \u001b[1m[\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m63\u001b[0m\u001b[1m]\u001b[0m, got \u001b[1m[\u001b[0m\u001b[1;36m64\u001b[0m, \u001b[1;36m33\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    losses = []\n",
    "    # loop = tqdm(train_dataloader, leave=False)\n",
    "    #train_NDs = [] # array with pairs (N, D) \n",
    "    for (x, y, decoder_input_ids) in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "        signs = cnn(x)\n",
    "        input_ids = signs.argmax(dim=-1)\n",
    "        out = transformer(input_ids, labels=y, decoder_input_ids=decoder_input_ids)\n",
    "        \n",
    "        loss_transformer = out.loss\n",
    "        accelerator.backward(loss_transformer)\n",
    "        transformer_optimizer.step()\n",
    "        transformer_optimizer.zero_grad()\n",
    "        \n",
    "        loss_cnn = loss_fn_cnn(signs, y)\n",
    "        loss_cnn.backward()\n",
    "        cnn_optimizer.step()\n",
    "        cnn_optimizer.zero_grad()\n",
    "\n",
    "        losses.append([loss_transformer.item(), loss_cnn.item()])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if epoch % 5 == 0:\n",
    "        #     train_NDs.append(metric(out, y))\n",
    "        \n",
    "    \n",
    "    transformer_mean_loss = sum(losses, key=lambda x: x[0]) / len(losses)\n",
    "    cnn_mean_loss = sum(losses, key=lambda x: x[1]) / len(losses)\n",
    "    epoch_losses.append([transformer_mean_loss, cnn_mean_loss])\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"epoch {epoch + 1}\\n transformer_mean_loss = {transformer_mean_loss}\\cnn_mean_loss = {cnn_mean_loss}\")\n",
    "\n",
    "\n",
    "        # validation score \n",
    "    # CHANGE NAME FOR LOOP!!!!!!!!!!!!!!!!!!!!!\n",
    "        # loop = tqdm(val_dataloader, leave=False)\n",
    "        # for (x, y) in loop:\n",
    "        #     x = x.to(device)\n",
    "        #     y = y.to(device)\n",
    "        #     with torch.no_grad():\n",
    "        #         out = model(x)\n",
    "        #     loss = loss_fn(out.view(BATCH_SIZE, -1, 31), y)\n",
    "        #     val_losses.append(loss.item())\n",
    "        \n",
    "        # print(f\"Validation loss on epoch {epoch + 1} = {sum(val_losses) / len(val_losses)}\\nbtw train loss = {mean_loss}\")\n",
    "        \n",
    "        \n",
    "    #val_losses = []\n",
    "    # if epoch % 5 == 0:\n",
    "    #     # compute levenshtein distance on validation data\n",
    "    #     loop = tqdm(val_dataloader, leave=False)\n",
    "    #     val_NDs = []\n",
    "    #     for (x,y) in loop:\n",
    "    #         x = x.to(device)\n",
    "    #         y = y.to(device)\n",
    "    #         with torch.no_grad():\n",
    "    #             out = model(x)\n",
    "    #         val_NDs.append(metric(out, y))\n",
    "            \n",
    "    #     train_distance = 1 - sum(x[1] for x in train_NDs) / sum(x[0] for x in train_NDs)\n",
    "    #     val_distance = 1 - sum(x[1] for x in val_NDs) / sum(x[0] for x in val_NDs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #     print(f\"epoch {epoch + 1}\\ntrain_distance = {train_distance}\\nval_distance = {val_distance}\\n\\n\")\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sequential      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 1\n",
    "for x in y.shape:\n",
    "    product *= x\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(out[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt_train = y.type(torch.LongTensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(torch.transpose(out, 1, 2), Yt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import  AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "mname = \"Helsinki-NLP/opus-mt-ru-fr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(mname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=None, logits=tensor([[[ -1.3973, -12.1024,  -3.6717,  ..., -12.1039, -12.1037,   0.0000],\n",
       "         [ -4.4700, -14.4538,  -6.5072,  ..., -14.4591, -14.4613,   0.0000]]],\n",
       "       grad_fn=<AddBackward0>), past_key_values=((tensor([[[[ 0.1202,  0.9309, -0.6240,  ..., -0.9568,  1.5552, -1.4000],\n",
       "          [ 0.6468,  1.0183, -0.5855,  ..., -1.3328,  1.7627, -1.8537]],\n",
       "\n",
       "         [[ 1.7458, -0.8240, -1.6842,  ..., -1.3492,  1.9502,  0.6336],\n",
       "          [ 1.1572, -0.2653, -0.7925,  ..., -1.7627,  3.7647,  1.7054]],\n",
       "\n",
       "         [[ 0.2190, -0.2175,  0.0326,  ..., -0.8406,  0.7209,  0.0771],\n",
       "          [-0.3864, -0.0734,  0.2335,  ..., -0.1937,  0.9352, -0.5549]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8143, -1.4174,  1.4170,  ..., -0.9163,  0.2304,  0.8446],\n",
       "          [-3.0297, -2.4983,  1.4386,  ..., -1.1109,  0.8090,  0.9012]],\n",
       "\n",
       "         [[-0.8551,  1.0457,  2.2835,  ..., -0.0140,  1.2346,  0.8761],\n",
       "          [-0.6907,  1.0890,  1.3075,  ..., -1.4660,  0.5024,  1.6909]],\n",
       "\n",
       "         [[-3.5175,  2.5684, -1.2313,  ..., -1.0101,  1.0141, -1.2146],\n",
       "          [-2.6708,  2.3877,  1.1131,  ..., -1.7190,  3.7809,  1.4597]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.1946,  0.6428, -0.0230,  ...,  0.1610, -0.4837, -0.2923],\n",
       "          [ 0.0045,  0.4022, -0.3303,  ..., -0.0932, -0.4786,  0.5948]],\n",
       "\n",
       "         [[-0.7506,  0.3181,  0.4667,  ...,  0.5932,  0.6366,  0.0312],\n",
       "          [-0.9829, -0.8578,  0.1185,  ..., -0.2110,  0.3140,  1.5500]],\n",
       "\n",
       "         [[ 0.3844, -0.2402,  0.0735,  ...,  0.7431,  0.5911, -0.3707],\n",
       "          [-0.8018,  1.2855, -0.5995,  ...,  0.8429, -0.1974, -0.1183]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1440,  0.0881,  0.0890,  ..., -0.1512, -0.3183, -0.1369],\n",
       "          [-0.4002,  0.5299,  1.0549,  ...,  0.3092, -0.6108, -0.1839]],\n",
       "\n",
       "         [[-0.3026, -0.8565, -0.5466,  ...,  0.1292,  0.6679,  0.7001],\n",
       "          [-0.9438, -0.9332,  0.7465,  ...,  0.6318,  0.7837,  0.1395]],\n",
       "\n",
       "         [[-0.1291,  0.2212, -0.0787,  ...,  0.1007, -0.3732,  0.0509],\n",
       "          [-0.0711,  1.2661,  0.1244,  ..., -0.1242, -0.3131,  0.0201]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-5.0119e-01,  6.5764e-01, -6.1943e-01,  ...,  3.7632e-01,\n",
       "            2.6037e-01, -3.3770e-01],\n",
       "          [-4.9447e-01,  1.6723e+00, -9.9235e-01,  ..., -9.2153e-02,\n",
       "            1.0937e+00, -8.2983e-01],\n",
       "          [-9.0442e-01,  1.6405e+00, -1.0096e+00,  ...,  1.7942e-01,\n",
       "            1.0767e+00, -9.2178e-01],\n",
       "          ...,\n",
       "          [-5.0299e-01,  8.6095e-01, -4.6990e-02,  ...,  6.0662e-01,\n",
       "            1.1934e-01, -5.6678e-01],\n",
       "          [ 5.7586e-01,  2.4575e-01,  6.2967e-02,  ...,  3.8039e-01,\n",
       "           -8.8299e-02, -4.8075e-02],\n",
       "          [ 2.3681e-01,  3.5603e-01, -1.2268e+00,  ...,  1.9704e+00,\n",
       "            4.4002e-01, -2.0636e-01]],\n",
       "\n",
       "         [[-7.0747e-01, -2.2786e-01,  1.1526e+00,  ...,  1.2672e+00,\n",
       "            7.0918e-01, -2.3784e-01],\n",
       "          [-1.4595e+00, -1.9847e-01,  8.4719e-01,  ...,  1.5433e+00,\n",
       "            2.8211e-01, -6.7714e-01],\n",
       "          [-1.0823e+00, -5.1016e-01,  8.9119e-01,  ...,  1.1821e+00,\n",
       "            4.2689e-01, -2.7429e-01],\n",
       "          ...,\n",
       "          [-8.7844e-01, -9.7699e-01,  5.2675e-01,  ..., -1.3556e+00,\n",
       "            8.1496e-01,  8.2993e-01],\n",
       "          [ 2.1929e-02, -1.3308e+00,  1.3341e-01,  ..., -3.9524e-01,\n",
       "            6.2195e-01, -2.3838e-01],\n",
       "          [ 3.3450e-01, -2.2124e+00, -4.7853e-01,  ..., -1.2847e+00,\n",
       "            2.3620e-01,  3.2286e-01]],\n",
       "\n",
       "         [[ 1.0212e+00, -5.2078e-01, -7.6657e-02,  ...,  9.7305e-01,\n",
       "            9.1583e-01,  1.3857e-01],\n",
       "          [ 9.3246e-01, -3.1243e-01, -5.1226e-01,  ..., -1.3297e-01,\n",
       "           -1.0199e-01, -1.0393e-02],\n",
       "          [ 1.0331e+00, -3.9535e-01, -1.5808e-02,  ...,  4.0936e-01,\n",
       "            4.6628e-01,  1.4008e-01],\n",
       "          ...,\n",
       "          [ 9.4383e-01, -4.3996e-01,  1.1585e-01,  ...,  6.0013e-01,\n",
       "            9.7396e-02,  3.1779e-01],\n",
       "          [ 3.2944e-01, -1.9657e+00,  3.5112e-01,  ...,  7.1024e-01,\n",
       "           -3.5487e-02,  1.8310e-03],\n",
       "          [ 4.4902e-01, -2.8550e+00,  2.4206e-01,  ...,  4.5310e-01,\n",
       "            4.7140e-01,  1.4104e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.0064e-01,  1.1372e+00,  6.3288e-01,  ..., -5.6652e-01,\n",
       "           -1.0024e+00,  2.5417e-01],\n",
       "          [-1.0447e-01,  7.8258e-01,  1.1684e+00,  ..., -1.3529e-02,\n",
       "           -1.3365e+00,  6.4727e-01],\n",
       "          [-6.1955e-01,  9.3355e-01,  8.5989e-01,  ...,  2.7456e-01,\n",
       "           -8.3203e-01,  3.8978e-01],\n",
       "          ...,\n",
       "          [ 6.3400e-01,  6.0819e-01, -3.7877e-01,  ...,  1.5257e+00,\n",
       "            1.6958e-02,  5.1306e-01],\n",
       "          [-3.9440e-01, -6.8277e-01, -8.2560e-01,  ...,  7.4977e-02,\n",
       "            6.8627e-01,  1.1578e+00],\n",
       "          [-7.4796e-02, -1.5197e-01, -1.1307e-01,  ..., -1.9531e-01,\n",
       "            1.9631e-01,  8.3776e-01]],\n",
       "\n",
       "         [[ 3.5917e-01,  4.5165e-01, -2.1358e-01,  ..., -9.9507e-01,\n",
       "            6.0241e-01, -3.1971e-01],\n",
       "          [ 6.7394e-01,  1.7289e-01,  5.8427e-01,  ..., -7.0890e-01,\n",
       "            7.4283e-01,  3.5131e-01],\n",
       "          [ 6.7154e-01, -1.2171e-01,  7.5274e-01,  ..., -6.4416e-01,\n",
       "            6.7344e-01,  1.2882e-01],\n",
       "          ...,\n",
       "          [-1.0506e-01, -4.6608e-02, -3.1730e-02,  ..., -3.8498e-01,\n",
       "           -1.7512e-01,  3.9574e-01],\n",
       "          [ 3.7856e-02,  5.6854e-01, -2.3138e-02,  ...,  7.0063e-01,\n",
       "           -8.8449e-01,  3.1340e-01],\n",
       "          [ 8.5215e-02, -5.5907e-02,  2.0690e-01,  ..., -5.7085e-02,\n",
       "           -4.3847e-02,  3.8781e-01]],\n",
       "\n",
       "         [[-7.1608e-01, -2.7870e-01, -1.5192e-01,  ...,  1.0905e+00,\n",
       "            2.0495e+00, -5.3568e-01],\n",
       "          [-7.1547e-01, -6.9049e-01, -5.2894e-01,  ...,  9.7566e-01,\n",
       "            1.3945e+00,  9.0347e-01],\n",
       "          [-7.3086e-01, -6.9356e-01,  2.0276e-01,  ...,  6.9301e-01,\n",
       "            1.5238e+00,  1.5648e-01],\n",
       "          ...,\n",
       "          [-5.0572e-01, -1.1036e+00,  3.2585e-01,  ...,  1.3568e+00,\n",
       "            1.0773e+00, -5.5397e-01],\n",
       "          [ 5.4374e-01,  5.6948e-01,  8.0549e-01,  ...,  5.7190e-01,\n",
       "            1.0063e+00, -3.8255e-01],\n",
       "          [-1.2797e-02,  1.2179e-02,  6.7071e-01,  ...,  5.1308e-01,\n",
       "            6.3615e-01, -9.3963e-02]]]], grad_fn=<CloneBackward0>), tensor([[[[ 1.4502e-01, -1.5945e-01,  2.8675e-01,  ...,  5.3120e-02,\n",
       "           -4.6096e-01, -5.6299e-01],\n",
       "          [-1.5701e-01, -6.3445e-01,  6.9449e-01,  ...,  4.1240e-01,\n",
       "           -4.5953e-01, -3.6655e-01],\n",
       "          [-1.6443e-01, -4.6413e-01,  5.7095e-01,  ...,  4.5233e-01,\n",
       "           -5.4885e-01, -9.1735e-02],\n",
       "          ...,\n",
       "          [ 6.7657e-01, -6.3589e-01, -1.6578e-02,  ..., -3.7188e-02,\n",
       "            1.5009e-01, -1.6089e-01],\n",
       "          [-1.0909e-01,  2.0981e-01, -1.8758e-02,  ...,  2.0952e-01,\n",
       "           -4.8818e-02,  4.6106e-01],\n",
       "          [ 9.4009e-03,  1.8345e-02, -8.8767e-02,  ...,  1.4244e-02,\n",
       "            1.8349e-03, -5.2951e-02]],\n",
       "\n",
       "         [[ 2.4567e-01,  3.6035e-01,  1.2781e+00,  ..., -1.2385e-01,\n",
       "            2.3354e-01,  1.0971e-01],\n",
       "          [ 2.7093e-01,  3.8272e-01,  9.6348e-01,  ..., -6.2957e-01,\n",
       "            1.8706e-01,  5.5994e-02],\n",
       "          [-1.3544e-01,  2.7924e-01,  1.4686e+00,  ..., -5.1255e-01,\n",
       "           -2.2930e-02,  7.9267e-02],\n",
       "          ...,\n",
       "          [-3.1468e-01, -6.4444e-03,  1.9399e-01,  ..., -6.4717e-01,\n",
       "            3.7965e-01, -5.5719e-01],\n",
       "          [-5.3490e-01,  1.4257e-01, -8.2284e-02,  ...,  5.9742e-01,\n",
       "           -2.8929e-01, -3.6572e-01],\n",
       "          [ 8.8658e-02, -1.7821e-02, -1.1218e-03,  ...,  9.4187e-03,\n",
       "           -4.8439e-02,  5.5120e-04]],\n",
       "\n",
       "         [[ 2.1995e-01, -5.0377e-01, -5.0361e-01,  ..., -4.3724e-01,\n",
       "           -9.8498e-02, -7.4648e-02],\n",
       "          [ 2.8609e-01, -3.7313e-01,  1.5793e-01,  ..., -7.2198e-01,\n",
       "           -5.5915e-01, -5.5418e-02],\n",
       "          [ 2.7572e-01, -3.7955e-01,  1.9049e-01,  ..., -6.4840e-01,\n",
       "           -5.5216e-01,  2.1284e-01],\n",
       "          ...,\n",
       "          [ 8.9731e-02,  7.9807e-02,  7.7944e-02,  ...,  5.2787e-01,\n",
       "            1.4357e-01,  6.0960e-01],\n",
       "          [ 3.1534e-01, -4.0306e-01,  2.1375e-01,  ...,  4.7636e-01,\n",
       "           -2.2535e-01, -1.3724e-01],\n",
       "          [-2.5274e-01, -2.2995e-02, -2.2906e-01,  ...,  2.1727e-01,\n",
       "            2.8305e-01, -3.4455e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3150e-01, -2.7659e-01, -3.8342e-01,  ...,  6.5521e-02,\n",
       "            5.6480e-01,  1.1435e-01],\n",
       "          [ 1.1788e-02, -6.5528e-01,  1.4048e-02,  ...,  2.3364e-01,\n",
       "            2.9964e-01,  6.3504e-01],\n",
       "          [ 2.6593e-01, -4.6410e-01,  5.2936e-01,  ...,  2.2489e-01,\n",
       "            3.5489e-01,  5.4479e-01],\n",
       "          ...,\n",
       "          [-7.7074e-01, -1.2553e-01, -2.6740e-01,  ..., -8.3482e-02,\n",
       "           -1.3267e-01,  2.5245e-01],\n",
       "          [ 6.4557e-01,  2.3577e-01,  1.0594e-01,  ...,  7.5512e-02,\n",
       "           -7.6328e-01, -1.5714e-02],\n",
       "          [-5.5947e-02,  3.0901e-03,  1.6598e-02,  ...,  9.7251e-03,\n",
       "           -8.6933e-02,  3.9145e-02]],\n",
       "\n",
       "         [[ 4.9289e-01,  7.0379e-01, -5.0550e-01,  ..., -1.7648e-01,\n",
       "           -5.1872e-01,  6.6639e-01],\n",
       "          [ 4.3401e-01,  5.2463e-01, -1.0913e+00,  ..., -4.0492e-01,\n",
       "           -4.7915e-01,  2.7819e-01],\n",
       "          [ 2.8156e-01,  5.5493e-01, -6.9327e-01,  ..., -3.7534e-01,\n",
       "           -2.2638e-01,  2.6486e-01],\n",
       "          ...,\n",
       "          [ 1.6356e-02,  4.9685e-01, -2.2603e-01,  ..., -1.9080e-02,\n",
       "           -4.7390e-02,  1.4206e-01],\n",
       "          [ 3.1269e-01, -7.7477e-01, -3.7939e-02,  ...,  2.6100e-01,\n",
       "            3.6498e-01, -2.3140e-02],\n",
       "          [-7.8722e-02,  1.1921e-01,  1.8514e-02,  ..., -3.7468e-02,\n",
       "           -5.3960e-02,  3.3831e-02]],\n",
       "\n",
       "         [[-1.4521e-01,  5.6318e-01, -3.7973e-01,  ...,  1.6424e-01,\n",
       "           -2.9028e-01, -2.1026e-01],\n",
       "          [-5.1103e-01,  7.2587e-01, -2.0179e-01,  ..., -1.8372e-01,\n",
       "           -7.4325e-01, -1.9306e-01],\n",
       "          [-4.2275e-01,  4.4966e-01,  4.2247e-02,  ..., -2.1307e-01,\n",
       "           -6.4016e-01, -9.4218e-02],\n",
       "          ...,\n",
       "          [-2.7062e-01, -1.4540e-01, -5.7669e-01,  ..., -1.4341e-01,\n",
       "           -3.3401e-01,  1.9750e-01],\n",
       "          [ 2.8698e-01, -1.0150e-01,  2.5628e-01,  ..., -5.7198e-01,\n",
       "            3.9905e-01,  3.6860e-01],\n",
       "          [ 5.7425e-02,  4.1193e-02, -1.1386e-01,  ...,  5.4991e-02,\n",
       "           -4.3695e-02, -1.6576e-02]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 0.4028, -4.3373,  0.6810,  ...,  1.0024,  0.2550,  0.2772],\n",
       "          [ 0.0380, -2.1304, -0.9431,  ...,  1.1316, -1.7654,  0.4968]],\n",
       "\n",
       "         [[-0.9609,  0.8073, -0.3587,  ..., -0.7456, -1.3896, -2.9152],\n",
       "          [ 0.4569, -0.0164,  0.5812,  ..., -0.1071, -1.1113, -2.5002]],\n",
       "\n",
       "         [[ 0.3817,  0.3627, -0.4315,  ..., -0.7458,  2.1394,  0.9066],\n",
       "          [-0.3423, -0.0105, -0.3844,  ..., -0.1102,  1.4343,  0.4190]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0817, -0.0967,  0.2914,  ...,  0.3479,  0.1769, -0.4890],\n",
       "          [-0.1818,  0.6127,  0.1915,  ..., -0.8779, -0.6138, -0.3865]],\n",
       "\n",
       "         [[ 1.5728, -0.9559,  0.3653,  ...,  1.0438, -1.5574, -0.2209],\n",
       "          [-0.0344,  0.6558,  0.0730,  ...,  0.7125,  0.6152, -1.6510]],\n",
       "\n",
       "         [[ 0.1620,  0.7509,  1.6378,  ..., -0.3336, -1.9890,  0.6770],\n",
       "          [-0.8693,  0.9276,  0.3605,  ..., -1.1195, -0.6927, -0.1183]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-1.1358e-01, -1.9511e-02,  5.9068e-01,  ...,  1.8065e-01,\n",
       "           -5.6198e-01, -9.8417e-02],\n",
       "          [-1.8277e-01,  2.0376e-01, -2.5559e-01,  ...,  4.8354e-01,\n",
       "           -8.6938e-01,  5.4978e-01]],\n",
       "\n",
       "         [[ 1.1956e+00, -3.9441e-04, -6.1106e-01,  ...,  2.6061e-01,\n",
       "           -3.0050e-01,  6.2854e-01],\n",
       "          [ 1.2042e+00,  3.6266e-01, -6.4173e-02,  ..., -2.6816e-01,\n",
       "            6.8248e-01, -6.0212e-01]],\n",
       "\n",
       "         [[-1.7733e-01, -1.0265e+00, -2.1179e-01,  ..., -1.3171e-01,\n",
       "           -1.7828e-01, -3.1793e-01],\n",
       "          [-7.1078e-02, -1.0950e+00, -5.9831e-01,  ...,  2.6571e-01,\n",
       "           -3.5911e-01,  4.1184e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3155e-02, -5.9349e-01, -1.6447e-01,  ...,  9.2039e-02,\n",
       "           -4.8475e-02,  2.4560e-01],\n",
       "          [ 3.5837e-01, -6.1939e-01,  7.2348e-01,  ..., -1.3629e+00,\n",
       "           -1.7882e-01, -7.9281e-01]],\n",
       "\n",
       "         [[ 1.0530e-01,  3.5480e-01,  4.0515e-02,  ..., -8.0512e-02,\n",
       "            3.7255e-01, -5.3805e-01],\n",
       "          [ 1.1628e+00,  7.6384e-01,  3.5451e-01,  ...,  1.7056e-01,\n",
       "            5.2014e-01, -7.1471e-01]],\n",
       "\n",
       "         [[ 2.2996e-01,  1.1201e+00, -6.9943e-01,  ...,  6.0779e-01,\n",
       "            3.3342e-01,  2.8006e-01],\n",
       "          [-8.3563e-02,  9.7695e-01, -5.5277e-01,  ..., -5.7806e-01,\n",
       "           -6.0007e-01, -1.6861e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-6.1393e-01, -1.0021e+00,  4.0199e-01,  ...,  8.3705e-01,\n",
       "           -4.2025e-01,  6.0058e-01],\n",
       "          [ 1.2881e-01, -1.3741e+00,  4.7740e-01,  ..., -1.1793e-01,\n",
       "           -1.6942e-01,  3.0263e-01],\n",
       "          [ 5.5708e-02, -1.1867e+00,  9.1393e-01,  ...,  2.7952e-01,\n",
       "           -4.5686e-01,  4.3507e-01],\n",
       "          ...,\n",
       "          [ 9.7561e-02, -6.4907e-01,  9.6195e-01,  ...,  9.1522e-01,\n",
       "            5.2591e-01,  1.1813e-02],\n",
       "          [ 4.8873e-01, -2.2301e-01, -1.5738e-02,  ...,  3.2679e-01,\n",
       "            2.3745e-02, -1.8243e-01],\n",
       "          [ 5.3601e-01, -2.0147e-01, -9.5076e-02,  ...,  2.8605e-01,\n",
       "            5.1071e-01, -9.4365e-01]],\n",
       "\n",
       "         [[ 9.9051e-01, -5.2768e-01, -2.5137e-02,  ...,  2.8158e-03,\n",
       "           -4.0361e-01, -9.4325e-01],\n",
       "          [ 1.0664e+00,  1.5755e-01, -7.8810e-02,  ...,  7.7360e-01,\n",
       "            1.7138e-03, -7.2301e-01],\n",
       "          [ 9.0688e-01, -2.6424e-01, -2.8386e-01,  ...,  1.0317e+00,\n",
       "           -3.9479e-01, -4.7360e-01],\n",
       "          ...,\n",
       "          [ 7.3886e-01,  1.0368e+00,  6.6288e-03,  ...,  4.6283e-03,\n",
       "           -1.0126e-01, -3.0444e-02],\n",
       "          [ 2.6473e-01, -2.4156e-01,  7.0775e-01,  ..., -6.4246e-01,\n",
       "            5.0742e-02,  9.5405e-01],\n",
       "          [ 2.3959e-02, -1.8937e-01,  1.8451e-01,  ...,  7.1451e-02,\n",
       "           -2.9619e-01,  1.7641e-01]],\n",
       "\n",
       "         [[ 2.9566e-01,  4.2077e-02, -7.3829e-03,  ...,  7.7853e-01,\n",
       "           -1.6062e-01,  5.5898e-01],\n",
       "          [-5.5019e-01, -9.8530e-01,  3.5775e-02,  ...,  6.8729e-01,\n",
       "           -2.0970e-01,  4.5834e-01],\n",
       "          [-6.6338e-01, -3.3198e-01, -5.6159e-01,  ...,  5.3973e-01,\n",
       "           -5.2253e-01,  5.6612e-01],\n",
       "          ...,\n",
       "          [-4.1124e-02,  2.3806e-01,  1.1330e-01,  ...,  1.4813e+00,\n",
       "           -1.1943e+00,  3.8376e-01],\n",
       "          [-1.1248e+00,  2.4188e-01, -9.7699e-02,  ...,  7.9512e-01,\n",
       "           -9.9124e-01,  2.7251e-03],\n",
       "          [-1.0847e+00, -2.4892e-01,  1.0681e-01,  ...,  1.5191e+00,\n",
       "           -1.3675e+00,  2.4047e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0260e-01, -5.2557e-01,  1.4384e+00,  ..., -1.2361e-02,\n",
       "           -2.7234e-02, -9.8884e-01],\n",
       "          [-1.8234e-01, -1.3795e+00,  1.1379e+00,  ...,  6.3022e-02,\n",
       "            6.5734e-01, -1.0142e+00],\n",
       "          [-3.0789e-01, -1.0352e+00,  1.4991e+00,  ...,  2.1102e-01,\n",
       "            6.1981e-01, -1.1754e+00],\n",
       "          ...,\n",
       "          [-9.4407e-01, -5.6619e-02,  1.4322e+00,  ..., -9.4637e-01,\n",
       "            8.9919e-01, -9.2744e-01],\n",
       "          [-1.3221e+00,  6.2166e-01,  1.1463e+00,  ...,  3.9939e-01,\n",
       "           -1.8890e-01, -7.1080e-01],\n",
       "          [-8.2331e-01,  9.5987e-02,  2.3414e+00,  ..., -2.5963e-01,\n",
       "            9.7564e-01, -1.0596e+00]],\n",
       "\n",
       "         [[ 3.2020e+00, -1.2962e-01,  7.6478e-01,  ...,  3.1988e-01,\n",
       "            1.6967e-03,  9.9679e-02],\n",
       "          [ 2.1171e+00, -6.8367e-02,  4.9487e-01,  ..., -1.6043e-01,\n",
       "           -7.6355e-01,  2.8434e-01],\n",
       "          [ 2.6321e+00,  1.6565e-01,  1.8899e-01,  ..., -2.5441e-01,\n",
       "           -2.8699e-02,  3.8454e-01],\n",
       "          ...,\n",
       "          [ 3.4205e+00, -3.2150e-01,  4.8597e-01,  ...,  1.4667e-01,\n",
       "           -1.6090e-01,  8.6713e-01],\n",
       "          [ 2.7438e+00, -1.4188e-01,  1.5737e-01,  ...,  1.3892e-01,\n",
       "           -2.5542e-01,  1.1466e-01],\n",
       "          [ 3.9691e+00, -3.7258e-01,  4.2611e-01,  ...,  2.2341e-01,\n",
       "           -3.8901e-01,  3.4217e-01]],\n",
       "\n",
       "         [[-6.4392e-01, -2.3746e-01,  4.1372e-01,  ..., -4.6265e-01,\n",
       "           -1.5272e-01, -1.3445e-01],\n",
       "          [-4.5693e-01, -2.2014e-01,  5.6496e-01,  ..., -5.0777e-01,\n",
       "            5.3933e-01, -1.7404e-01],\n",
       "          [-5.5187e-01, -3.2508e-01,  3.0892e-01,  ..., -5.4589e-01,\n",
       "            4.9542e-01, -9.5943e-02],\n",
       "          ...,\n",
       "          [-1.8776e-01, -1.2078e-01,  2.8250e-01,  ..., -1.8963e-02,\n",
       "            1.6642e-01, -4.6721e-01],\n",
       "          [ 3.5610e-01,  4.6171e-01, -5.6933e-01,  ...,  2.8253e-01,\n",
       "            2.2186e-01, -1.9518e-01],\n",
       "          [ 1.3707e-02, -2.7720e-01,  2.1145e-01,  ..., -3.2819e-02,\n",
       "           -3.7232e-01, -2.9655e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-1.2387e+00, -7.3429e-01,  1.9309e-01,  ..., -9.4197e-02,\n",
       "           -3.4938e-01, -9.1088e-01],\n",
       "          [-1.3057e+00,  6.7874e-02,  7.9819e-02,  ...,  3.1421e-01,\n",
       "           -5.4135e-01, -9.6245e-01],\n",
       "          [-1.0431e+00, -1.7442e-01, -9.2492e-02,  ...,  1.8544e-01,\n",
       "           -5.5602e-01, -1.2139e+00],\n",
       "          ...,\n",
       "          [-1.3202e+00, -1.2126e+00, -4.0193e-01,  ..., -1.2012e-01,\n",
       "           -2.6967e-01,  3.1746e-01],\n",
       "          [ 3.4954e-01,  9.5614e-02, -1.4728e+00,  ..., -8.3602e-01,\n",
       "            2.4615e-01, -1.8120e-02],\n",
       "          [ 4.7383e-02,  1.8859e-02,  7.9359e-02,  ..., -7.7872e-02,\n",
       "            6.6059e-02,  2.6223e-02]],\n",
       "\n",
       "         [[ 1.4931e-01,  6.4592e-01,  7.9488e-01,  ..., -5.8300e-01,\n",
       "           -9.2549e-01, -1.1280e-01],\n",
       "          [ 1.4901e-01,  9.0083e-01,  3.6341e-01,  ..., -1.3148e+00,\n",
       "           -7.4193e-01,  7.9406e-01],\n",
       "          [ 3.6230e-03,  9.1191e-01,  5.8126e-01,  ..., -9.3260e-01,\n",
       "           -9.5504e-01,  7.8733e-01],\n",
       "          ...,\n",
       "          [ 9.5897e-01,  1.5727e+00,  3.7880e-01,  ..., -2.9870e-01,\n",
       "           -1.1382e-01,  1.1782e-01],\n",
       "          [-1.4237e+00,  1.8598e-03, -2.3744e-01,  ...,  1.1487e+00,\n",
       "            4.1342e-01,  3.2134e-01],\n",
       "          [-1.7205e-01,  1.0390e-01, -7.2540e-02,  ...,  3.5380e-01,\n",
       "            1.1998e-01, -4.2936e-02]],\n",
       "\n",
       "         [[ 1.0156e+00, -3.4194e-01, -6.7770e-05,  ...,  3.3567e-01,\n",
       "           -3.5066e-01, -3.6212e-01],\n",
       "          [ 5.2906e-01,  3.2824e-01, -5.2116e-01,  ..., -2.0785e-01,\n",
       "            1.2426e-02, -1.1793e+00],\n",
       "          [ 1.3284e-01,  2.1761e-01, -3.8735e-01,  ..., -6.7772e-02,\n",
       "           -2.9479e-01, -1.2854e+00],\n",
       "          ...,\n",
       "          [-6.6225e-01,  5.1012e-01, -4.4340e-01,  ...,  4.4076e-01,\n",
       "            3.3087e-01,  6.9966e-01],\n",
       "          [-1.2268e-01,  2.3059e-01,  5.1633e-01,  ..., -8.1042e-01,\n",
       "           -2.2670e-01, -6.4916e-02],\n",
       "          [-1.7245e-02, -4.5182e-02, -1.7388e-02,  ...,  7.6459e-02,\n",
       "            2.3605e-02,  7.6999e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1664e+00,  1.2331e+00,  4.7329e-01,  ...,  8.9941e-01,\n",
       "            1.0354e-01,  2.4018e-01],\n",
       "          [ 5.4575e-01,  1.0782e+00,  2.9054e-01,  ...,  1.2164e+00,\n",
       "           -9.1586e-01, -5.9132e-02],\n",
       "          [ 2.9193e-01,  4.6861e-01, -1.9307e-01,  ...,  1.5036e+00,\n",
       "           -8.6600e-01,  6.5263e-01],\n",
       "          ...,\n",
       "          [-4.1971e-01,  4.7757e-01,  2.2500e-01,  ..., -4.6597e-01,\n",
       "            1.7809e+00,  8.9786e-01],\n",
       "          [ 2.2725e-01,  1.2267e+00, -3.1463e-01,  ...,  2.5236e-01,\n",
       "           -1.9830e-01, -1.4733e+00],\n",
       "          [ 2.1264e-01,  1.5446e-02, -9.1959e-02,  ...,  2.7204e-01,\n",
       "           -1.7673e-01,  1.4105e-01]],\n",
       "\n",
       "         [[-5.1418e-01, -8.2566e-01,  6.7046e-01,  ...,  1.1835e+00,\n",
       "           -4.0770e-02, -8.8761e-01],\n",
       "          [-9.1808e-01, -7.4438e-01,  6.0617e-01,  ...,  1.5961e+00,\n",
       "           -2.8618e-01, -3.5701e-01],\n",
       "          [-1.3777e-01, -4.9109e-01,  3.8727e-01,  ...,  1.3282e+00,\n",
       "           -5.9976e-01, -6.3843e-01],\n",
       "          ...,\n",
       "          [ 1.2605e+00, -7.1084e-01,  3.9690e-01,  ...,  7.0637e-01,\n",
       "            9.9703e-01, -8.4514e-01],\n",
       "          [ 6.0001e-01, -5.2799e-01, -5.7476e-01,  ...,  1.0364e-01,\n",
       "            2.6442e-01, -1.5402e-01],\n",
       "          [-3.0972e-01,  2.5331e-01, -3.4883e-01,  ..., -1.3338e-01,\n",
       "           -2.2246e-01, -1.5450e-01]],\n",
       "\n",
       "         [[ 2.9143e-01, -4.8093e-01, -1.3360e+00,  ...,  4.7578e-01,\n",
       "            4.9957e-01, -9.4537e-01],\n",
       "          [ 9.9295e-02, -2.6472e-01, -1.1449e+00,  ..., -1.4916e-01,\n",
       "            1.3948e+00, -1.2919e-01],\n",
       "          [-5.8396e-02,  2.9049e-01, -1.2313e+00,  ...,  5.8930e-02,\n",
       "            1.2839e+00, -5.7445e-01],\n",
       "          ...,\n",
       "          [-4.4922e-01,  4.2363e-01, -6.8625e-01,  ...,  1.4947e-01,\n",
       "           -2.3681e-01, -6.3367e-01],\n",
       "          [-3.4239e-01,  6.0491e-01,  3.9454e-01,  ...,  3.9166e-02,\n",
       "           -5.0007e-03, -6.0597e-01],\n",
       "          [ 4.8560e-01,  1.3705e+00, -2.1768e-01,  ..., -5.0195e-01,\n",
       "           -5.1799e-01, -2.8898e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 0.6050, -2.4711,  3.9816,  ...,  0.2625, -1.4278,  0.1912],\n",
       "          [-0.6983, -1.8396,  4.3225,  ..., -0.3831, -2.9026, -1.1964]],\n",
       "\n",
       "         [[ 1.1341,  4.3140,  1.0362,  ...,  2.7061, -2.9185,  3.1217],\n",
       "          [-0.4834,  3.0726,  0.6928,  ...,  2.8249, -3.6766,  1.9003]],\n",
       "\n",
       "         [[-1.9216,  2.5769,  0.9184,  ...,  0.9119, -4.2675, -3.1105],\n",
       "          [-1.2241, -0.3192,  0.1981,  ...,  0.8163, -2.2987, -0.9573]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4802,  0.6306, -0.2155,  ..., -0.9234,  1.4069,  0.1682],\n",
       "          [-0.1185,  0.1539, -0.7670,  ..., -0.0210,  0.6625,  0.0623]],\n",
       "\n",
       "         [[-0.8521, -2.5597,  0.2768,  ...,  1.1326, -0.4703, -0.5168],\n",
       "          [-0.5371, -1.5664,  0.8051,  ...,  0.2933, -0.6985, -0.0835]],\n",
       "\n",
       "         [[-0.5805, -0.7501,  0.8264,  ...,  1.6860, -4.0481, -3.4811],\n",
       "          [-0.8269, -0.5935,  1.5950,  ...,  1.7246, -3.5026, -2.0974]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.0400, -0.4454, -0.4408,  ...,  0.0824, -0.4517, -0.0651],\n",
       "          [ 0.5138,  0.7399,  0.0575,  ...,  0.0388, -0.6858, -0.3098]],\n",
       "\n",
       "         [[-0.4605,  0.3102, -0.0178,  ...,  0.0174,  0.6913, -0.0658],\n",
       "          [ 0.8911,  0.0458,  0.3398,  ..., -0.2160,  0.4659, -0.1627]],\n",
       "\n",
       "         [[ 0.0899, -0.8622, -0.4525,  ..., -0.0267, -0.4284,  0.0058],\n",
       "          [ 0.2830, -1.0488,  0.0577,  ...,  0.4270,  0.2233,  0.2138]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2515,  0.8915, -0.6432,  ...,  1.3957,  0.0572, -1.3881],\n",
       "          [ 0.7207,  0.7631, -0.9926,  ...,  0.4890,  0.6109,  1.2581]],\n",
       "\n",
       "         [[ 0.6058, -0.0868,  0.1304,  ...,  0.8957, -1.4864,  1.9934],\n",
       "          [ 1.1425,  0.4459,  0.7051,  ...,  0.7519, -1.3473,  0.1070]],\n",
       "\n",
       "         [[ 0.3491, -0.5073,  0.0104,  ...,  0.9518, -0.4952,  0.1748],\n",
       "          [-0.5145,  0.4881, -0.2778,  ...,  0.7473, -0.2984,  1.0235]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.7916,  1.6478,  0.8565,  ...,  1.0322,  0.6341,  0.3350],\n",
       "          [-0.8960,  1.9114,  1.0510,  ...,  2.0027,  0.2374,  0.4772],\n",
       "          [-0.8298,  1.8664,  0.9050,  ...,  1.6070,  0.4409,  0.3211],\n",
       "          ...,\n",
       "          [-0.0988, -0.1367,  0.4795,  ...,  0.1507,  0.3027,  0.0050],\n",
       "          [ 0.3120, -1.0403, -0.7082,  ...,  0.0967,  0.3786, -0.3523],\n",
       "          [-0.2360, -0.9165, -0.4262,  ...,  0.0493,  0.1664,  0.0190]],\n",
       "\n",
       "         [[ 0.6390, -0.6032,  1.2383,  ...,  0.3506,  0.2448, -0.1813],\n",
       "          [ 1.3743, -0.2935,  0.6206,  ...,  1.0960,  0.6882, -0.9117],\n",
       "          [ 0.8170, -0.4048,  0.6648,  ...,  0.8791,  0.4877, -0.8791],\n",
       "          ...,\n",
       "          [-0.1587,  0.0469,  2.1115,  ..., -0.5498,  0.6774, -0.5902],\n",
       "          [ 0.6873, -0.3997,  2.1339,  ...,  0.7578,  0.1320, -0.6109],\n",
       "          [ 0.0737, -0.0307,  3.2480,  ...,  0.8697,  0.2086, -0.3955]],\n",
       "\n",
       "         [[-0.3942,  0.9418, -0.1142,  ...,  0.8541, -0.3012, -0.6333],\n",
       "          [-0.5485,  0.8923, -0.6499,  ...,  0.4573, -0.4283, -0.5038],\n",
       "          [-0.4484,  0.9859, -0.4093,  ...,  0.4670, -0.0973, -0.4691],\n",
       "          ...,\n",
       "          [ 0.3411, -0.0733,  0.1168,  ...,  0.3187, -0.2597, -0.2004],\n",
       "          [-0.2198, -0.0617, -0.1953,  ..., -0.2817, -0.4059, -0.2999],\n",
       "          [-0.1258,  0.2897, -0.3233,  ...,  0.1375, -0.1327, -0.0883]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0471, -0.6989,  0.6662,  ..., -0.1865,  0.2533,  0.2572],\n",
       "          [ 0.2483, -0.3204,  0.7986,  ..., -0.5143,  0.1217,  0.2884],\n",
       "          [-0.1110, -0.3632,  0.1109,  ..., -0.4893, -0.3028,  0.1708],\n",
       "          ...,\n",
       "          [-0.5403, -0.4561,  0.2839,  ...,  0.2511,  0.1771,  0.7945],\n",
       "          [ 0.1279, -0.1207,  0.4404,  ...,  0.9736, -0.1147,  0.3907],\n",
       "          [-0.0266, -0.3271,  0.6804,  ..., -0.2844, -0.1884,  0.1091]],\n",
       "\n",
       "         [[ 0.0337,  0.1304,  1.2210,  ..., -1.0206,  0.8725,  0.3696],\n",
       "          [-0.4289, -0.7299,  0.9540,  ..., -0.8102,  1.0670,  0.6055],\n",
       "          [-0.2028, -0.4484,  0.7010,  ..., -0.8123,  1.2412,  0.3257],\n",
       "          ...,\n",
       "          [-0.0505,  0.1096,  0.6286,  ...,  0.7729,  1.3035,  0.3040],\n",
       "          [-0.2946,  0.5943,  0.2929,  ..., -0.1139, -0.0543, -0.3535],\n",
       "          [-0.1373,  0.0164, -0.0835,  ...,  0.2309,  0.3780,  0.1819]],\n",
       "\n",
       "         [[-0.4797,  0.7515,  0.5007,  ..., -0.5877,  1.2077,  0.9549],\n",
       "          [-0.6936,  0.8044,  0.3203,  ..., -1.2169,  1.3259,  0.3217],\n",
       "          [-0.8101,  0.5773,  0.2669,  ..., -0.4557,  1.0828,  0.8115],\n",
       "          ...,\n",
       "          [-0.1919,  0.6201, -0.4100,  ...,  0.4134,  0.8690,  0.7838],\n",
       "          [-0.1265,  0.0045,  0.5586,  ..., -0.1057,  0.7366,  1.1418],\n",
       "          [-0.8332, -1.1595,  0.3602,  ..., -0.2330,  1.3878,  1.0505]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 7.0280e-01,  6.5946e-01,  6.6989e-01,  ...,  1.6519e-01,\n",
       "            1.0793e-01, -3.4781e-02],\n",
       "          [ 3.0675e-01,  8.9562e-01,  5.1262e-01,  ...,  3.3796e-01,\n",
       "            9.9515e-01,  2.0859e-01],\n",
       "          [ 3.5686e-01,  1.3431e-01,  7.3225e-01,  ...,  2.5699e-01,\n",
       "            7.1914e-01,  3.0273e-01],\n",
       "          ...,\n",
       "          [ 5.8002e-01,  1.3366e+00,  9.6076e-01,  ..., -1.0837e-01,\n",
       "           -7.3604e-02,  1.7010e-01],\n",
       "          [-6.5578e-01, -5.2572e-02, -4.7850e-01,  ..., -6.4227e-01,\n",
       "           -2.0361e-01, -1.2578e-01],\n",
       "          [ 8.5656e-02,  6.4119e-02, -2.8120e-01,  ...,  5.3944e-01,\n",
       "            3.4998e-02,  6.2152e-03]],\n",
       "\n",
       "         [[ 1.1094e+00,  5.0338e-01,  3.8701e-01,  ...,  1.5019e+00,\n",
       "           -2.6981e-03, -2.8258e-01],\n",
       "          [ 8.5574e-01,  5.3970e-01, -8.9208e-01,  ...,  3.4299e-01,\n",
       "            2.3319e-01, -5.4712e-01],\n",
       "          [ 5.2115e-01,  5.7789e-01, -4.0074e-01,  ...,  6.3633e-01,\n",
       "            7.9948e-02, -5.2683e-01],\n",
       "          ...,\n",
       "          [ 4.1400e-01,  2.0062e-01,  1.3595e+00,  ..., -1.3911e-01,\n",
       "           -4.9575e-01,  5.2164e-01],\n",
       "          [ 4.4845e-01, -1.0768e-01, -6.3727e-03,  ..., -8.9240e-01,\n",
       "           -7.5938e-01, -4.5940e-01],\n",
       "          [-1.9303e-01,  1.7884e-01,  4.4630e-02,  ..., -3.0139e-02,\n",
       "            8.1651e-02,  1.5724e-02]],\n",
       "\n",
       "         [[ 3.1319e-01, -2.3263e-01, -3.2947e-01,  ..., -5.8690e-01,\n",
       "            7.3505e-01,  5.4622e-01],\n",
       "          [-5.9060e-01,  6.5954e-01, -7.1230e-01,  ..., -4.4378e-02,\n",
       "            1.3391e+00,  2.9685e-01],\n",
       "          [-1.3553e-01,  1.8497e-01, -5.6908e-01,  ..., -4.7081e-02,\n",
       "            1.1479e+00,  8.8321e-02],\n",
       "          ...,\n",
       "          [ 5.6820e-02,  4.0171e-01, -1.2013e-01,  ..., -5.1238e-01,\n",
       "            1.7370e-01,  4.2996e-01],\n",
       "          [ 7.6115e-03, -1.8516e-01,  6.3660e-01,  ...,  8.4988e-01,\n",
       "           -3.4273e-02,  2.4000e-01],\n",
       "          [-4.9839e-02, -2.9698e-01, -1.7082e-01,  ..., -2.6567e-02,\n",
       "           -2.1184e-01, -1.2913e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3223e-01, -3.0629e-01, -4.8214e-01,  ...,  3.3293e-01,\n",
       "            3.3085e-01, -2.5621e-02],\n",
       "          [ 8.3912e-02,  3.8082e-01, -8.0953e-01,  ...,  1.8831e-01,\n",
       "           -1.5113e-01,  1.6614e-01],\n",
       "          [ 3.0933e-01,  3.7172e-01, -4.2244e-01,  ...,  1.6505e-01,\n",
       "           -5.5370e-02, -3.4184e-01],\n",
       "          ...,\n",
       "          [-3.0888e-01,  6.8564e-01,  3.3082e-01,  ..., -5.6778e-01,\n",
       "            2.1904e-01, -4.1976e-01],\n",
       "          [-5.0083e-01,  1.0516e-01, -6.7928e-01,  ..., -4.1087e-01,\n",
       "           -7.6868e-02,  1.5141e+00],\n",
       "          [ 4.4324e-02, -6.3785e-02, -1.1168e-01,  ..., -3.7622e-02,\n",
       "            1.4523e-01,  3.1654e-02]],\n",
       "\n",
       "         [[-1.5404e-02, -3.4671e-01, -3.7394e-01,  ..., -4.3834e-02,\n",
       "           -1.0324e+00, -8.7574e-01],\n",
       "          [ 1.5845e-01, -7.5662e-01,  2.3096e-01,  ...,  7.6335e-03,\n",
       "           -1.1898e+00, -2.3970e-01],\n",
       "          [ 2.7425e-01, -7.4310e-01,  3.6275e-01,  ..., -1.7463e-01,\n",
       "           -1.0229e+00, -4.8279e-01],\n",
       "          ...,\n",
       "          [ 8.0348e-02, -8.6822e-02,  4.0119e-01,  ..., -3.3472e-01,\n",
       "           -4.8318e-02, -3.6965e-01],\n",
       "          [-3.4550e-01, -6.3184e-02, -3.8340e-01,  ..., -3.5841e-01,\n",
       "           -1.5971e-02,  2.7552e-01],\n",
       "          [-9.6164e-02, -9.2972e-02,  1.7480e-01,  ..., -1.1821e-01,\n",
       "           -1.0777e-01,  2.7146e-02]],\n",
       "\n",
       "         [[ 1.3375e-01, -4.7280e-01, -2.0300e-01,  ...,  3.5160e-01,\n",
       "           -2.2500e-01, -5.4454e-01],\n",
       "          [ 7.1255e-01, -5.6062e-01, -2.1052e-02,  ...,  3.7887e-01,\n",
       "            1.3151e-01, -2.6573e-01],\n",
       "          [ 4.4422e-01, -3.8418e-01, -5.0385e-01,  ...,  1.8049e-02,\n",
       "            1.4163e-01, -6.2429e-01],\n",
       "          ...,\n",
       "          [ 4.7585e-02,  1.7293e-01,  1.1843e-01,  ...,  1.5132e-01,\n",
       "            8.6041e-02, -5.3087e-01],\n",
       "          [ 5.2391e-01,  3.3575e-01, -6.5401e-02,  ..., -2.8008e-01,\n",
       "            1.7142e-01,  5.3747e-01],\n",
       "          [-6.2038e-02,  5.8796e-02,  1.9350e-02,  ..., -3.5547e-04,\n",
       "           -8.9169e-02, -1.4989e-02]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 1.7410, -0.3732,  0.1758,  ..., -0.2382,  1.8237, -1.6803],\n",
       "          [ 1.7949, -0.5292,  0.0523,  ..., -0.0559,  1.1643, -1.5500]],\n",
       "\n",
       "         [[-0.2034,  1.3034,  1.0488,  ...,  0.9376,  2.6290, -2.5840],\n",
       "          [-0.2953,  1.1536,  1.3691,  ...,  0.7794,  1.9022, -2.2647]],\n",
       "\n",
       "         [[-0.0474,  1.7355,  4.8928,  ..., -1.0424,  3.2022,  2.4193],\n",
       "          [ 0.9664,  1.4015,  5.5238,  ..., -1.1471,  3.2011,  2.0703]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8845,  1.5534, -2.1747,  ..., -0.3519,  5.5545, -1.3080],\n",
       "          [-1.4941,  0.8562, -1.6622,  ..., -0.4151,  4.9432, -1.2746]],\n",
       "\n",
       "         [[ 0.7754,  2.9064, -1.5965,  ...,  5.0619, -6.1260,  0.1185],\n",
       "          [ 1.3525,  2.7941, -1.3052,  ...,  4.5947, -6.2587,  0.6414]],\n",
       "\n",
       "         [[ 0.0711,  0.4784, -1.2136,  ...,  1.1400,  1.6543,  4.4699],\n",
       "          [ 0.2081,  0.2701, -0.7534,  ...,  1.3920,  1.3011,  4.3015]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-3.1914e-01,  2.2417e-01, -1.8790e-01,  ...,  8.5865e-01,\n",
       "           -2.9962e-01, -1.3787e+00],\n",
       "          [-2.3757e-01,  1.5486e-01,  1.7829e-01,  ...,  1.7918e+00,\n",
       "           -3.6949e-01, -1.4302e+00]],\n",
       "\n",
       "         [[-6.6091e-01, -1.3836e-01,  6.9164e-01,  ..., -5.4479e-01,\n",
       "            6.3782e-01, -7.1632e-01],\n",
       "          [-6.6660e-01, -5.0203e-01,  3.8895e-01,  ..., -6.4881e-01,\n",
       "            5.1450e-01, -5.4775e-01]],\n",
       "\n",
       "         [[ 8.0329e-02, -8.0546e-01, -7.0707e-01,  ..., -3.7375e-01,\n",
       "           -2.7579e-01, -7.8500e-01],\n",
       "          [-7.6868e-02, -4.5506e-01, -4.9215e-01,  ..., -3.5948e-01,\n",
       "           -2.9896e-02, -4.1161e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.4986e-01,  1.0771e+00,  1.0954e+00,  ...,  3.0469e-01,\n",
       "           -8.8667e-01,  4.2542e-01],\n",
       "          [ 5.4367e-01,  9.2869e-01,  1.7006e-01,  ...,  5.9080e-04,\n",
       "           -2.6967e-01,  2.6507e-01]],\n",
       "\n",
       "         [[-3.5865e-01, -4.2950e-01, -3.9893e-01,  ...,  5.8305e-01,\n",
       "           -8.0201e-02,  3.4061e-01],\n",
       "          [ 7.1680e-02, -3.8333e-01,  4.1592e-02,  ...,  2.5719e-01,\n",
       "            1.0144e-01,  3.7118e-01]],\n",
       "\n",
       "         [[-1.8180e-01,  3.6976e-01,  3.5671e-01,  ..., -5.2957e-01,\n",
       "           -2.8293e-01, -4.9444e-01],\n",
       "          [ 5.2624e-02,  4.8879e-01,  4.2896e-01,  ..., -6.2473e-01,\n",
       "           -5.8050e-02, -5.9827e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-1.2173e-02,  8.1346e-01,  2.2669e-01,  ...,  5.9620e-01,\n",
       "            5.2385e-01,  7.6991e-01],\n",
       "          [ 1.5666e-01,  1.3592e+00, -7.2043e-01,  ...,  4.7817e-01,\n",
       "            6.9611e-01,  7.3961e-01],\n",
       "          [ 8.8481e-02,  1.3104e+00, -4.4807e-01,  ...,  2.5584e-01,\n",
       "            6.9216e-01,  6.1188e-01],\n",
       "          ...,\n",
       "          [-8.1841e-02, -5.9073e-01, -3.4198e-02,  ...,  1.9145e-01,\n",
       "            3.3390e-01, -1.2606e-01],\n",
       "          [-1.0655e+00, -4.2259e-01,  4.2523e-02,  ...,  1.2831e-01,\n",
       "            5.0871e-01, -1.4657e+00],\n",
       "          [-2.7946e-01,  1.8959e-01,  3.2071e-01,  ..., -1.7035e-01,\n",
       "            1.0179e+00, -2.5314e+00]],\n",
       "\n",
       "         [[-7.9954e-01,  3.5752e-01, -1.7691e-01,  ..., -2.5832e-01,\n",
       "           -8.7313e-01, -3.3547e-01],\n",
       "          [-1.3891e+00,  5.2304e-01,  1.2565e+00,  ..., -7.0081e-02,\n",
       "           -1.0154e+00, -3.3837e-01],\n",
       "          [-9.9535e-01,  4.8592e-01,  4.7784e-01,  ..., -1.0195e-01,\n",
       "           -5.3973e-01, -4.5675e-01],\n",
       "          ...,\n",
       "          [-1.0037e+00, -3.6244e-01, -2.9793e-01,  ...,  4.8812e-01,\n",
       "           -2.6815e-01, -2.1989e-01],\n",
       "          [ 2.7972e-01,  1.2533e-01, -3.9819e-01,  ...,  1.0818e+00,\n",
       "            1.2605e+00,  1.5384e-01],\n",
       "          [ 1.2037e+00,  9.4013e-01, -4.9856e-01,  ...,  2.3625e-01,\n",
       "           -1.5228e-01,  2.5699e-01]],\n",
       "\n",
       "         [[-5.2795e-02, -8.4972e-01,  2.1628e-01,  ..., -7.7606e-01,\n",
       "           -2.6712e-01, -4.1577e-01],\n",
       "          [-3.5003e-01, -1.2594e+00, -2.7941e-01,  ..., -5.6244e-01,\n",
       "            3.8650e-01, -5.2109e-01],\n",
       "          [-6.3056e-02, -8.6002e-01,  1.3380e-01,  ..., -1.0114e+00,\n",
       "           -3.3673e-01, -8.4626e-01],\n",
       "          ...,\n",
       "          [-2.1639e-01, -3.2383e-01,  1.8487e+00,  ...,  2.9486e-01,\n",
       "           -1.1601e+00, -2.3374e-01],\n",
       "          [ 3.6786e-01, -6.9813e-01,  1.7295e+00,  ...,  1.1160e+00,\n",
       "           -2.0593e-01, -1.9563e-01],\n",
       "          [-2.2968e-01, -7.1955e-01,  2.0042e+00,  ...,  6.7794e-01,\n",
       "           -4.8268e-01,  1.9171e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2812e+00,  1.1535e+00, -2.8576e+00,  ...,  5.2038e-01,\n",
       "           -7.8519e-01,  8.4318e-01],\n",
       "          [ 2.9345e-01,  4.6201e-01, -1.8562e+00,  ...,  9.0695e-01,\n",
       "           -1.6961e-01,  2.2741e-02],\n",
       "          [ 1.8284e-01,  5.0673e-01, -1.8563e+00,  ...,  3.6428e-01,\n",
       "           -2.8489e-01,  6.3746e-01],\n",
       "          ...,\n",
       "          [-7.9691e-01,  2.4863e+00, -3.7163e+00,  ..., -8.0352e-01,\n",
       "           -2.1108e-01,  4.9749e-01],\n",
       "          [-8.0674e-01,  2.0332e+00, -3.6379e+00,  ..., -1.4061e+00,\n",
       "           -3.7134e-01,  3.8046e-01],\n",
       "          [-1.8181e+00,  2.6990e+00, -4.7601e+00,  ..., -6.2369e-01,\n",
       "            4.3095e-01,  9.6432e-01]],\n",
       "\n",
       "         [[ 4.2294e-01, -8.2806e-01, -3.3560e-01,  ...,  6.1093e-01,\n",
       "            3.9300e-01,  7.3760e-02],\n",
       "          [ 3.6719e-01, -3.3084e-01,  8.4471e-02,  ...,  2.6901e-01,\n",
       "            7.1260e-01, -7.3061e-01],\n",
       "          [ 4.5608e-01, -6.2217e-01, -1.4250e-01,  ...,  1.1447e-01,\n",
       "            3.7499e-01, -3.5135e-01],\n",
       "          ...,\n",
       "          [-6.7377e-01, -1.8189e+00,  4.0083e-01,  ..., -6.3615e-01,\n",
       "           -6.5293e-01,  6.0610e-01],\n",
       "          [-7.5864e-01, -5.3860e-02,  1.3546e-01,  ..., -3.5443e-01,\n",
       "            1.9740e-01,  1.1728e+00],\n",
       "          [-7.5168e-01, -8.7426e-01,  4.2608e-01,  ..., -7.7969e-01,\n",
       "           -8.7917e-01,  2.0514e+00]],\n",
       "\n",
       "         [[ 1.1909e+00,  1.1415e+00, -2.4085e+00,  ...,  1.4827e-01,\n",
       "           -1.3031e+00,  7.3747e-01],\n",
       "          [ 1.7169e+00,  9.8523e-01, -1.7907e+00,  ...,  1.7618e-01,\n",
       "           -1.1747e+00,  1.1183e+00],\n",
       "          [ 1.1360e+00,  1.1709e+00, -1.6444e+00,  ..., -3.2149e-03,\n",
       "           -1.1941e+00,  1.4464e+00],\n",
       "          ...,\n",
       "          [ 2.9450e-02,  1.1048e+00, -1.5333e+00,  ...,  1.0697e+00,\n",
       "           -1.7065e+00,  1.2824e-01],\n",
       "          [-9.6245e-02,  7.6291e-01, -1.0924e+00,  ...,  2.9849e-01,\n",
       "           -1.1109e+00,  2.7057e-02],\n",
       "          [ 2.2912e-01,  3.5743e-01, -1.3442e+00,  ..., -3.7746e-02,\n",
       "           -1.2791e+00,  1.5775e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[-5.8906e-01, -9.6325e-01, -7.8921e-02,  ...,  1.1086e+00,\n",
       "           -6.0488e-01,  5.6051e-01],\n",
       "          [-1.2570e-01, -7.6595e-01, -1.9886e-02,  ...,  9.7777e-01,\n",
       "           -2.9381e-01,  6.8666e-03],\n",
       "          [-9.8139e-02, -7.1677e-01, -1.4735e-02,  ...,  1.1689e+00,\n",
       "           -5.0633e-02, -3.0923e-01],\n",
       "          ...,\n",
       "          [ 7.3512e-01, -1.8338e-01,  7.5340e-01,  ..., -5.1476e-01,\n",
       "            1.6339e-01,  3.6485e-01],\n",
       "          [ 1.6676e-01, -9.6611e-01, -5.7129e-01,  ..., -7.4082e-01,\n",
       "           -7.8505e-01,  6.7783e-01],\n",
       "          [-1.8310e-01,  3.2609e-02, -2.7205e-02,  ..., -1.7444e-01,\n",
       "            1.0079e-02,  8.9627e-02]],\n",
       "\n",
       "         [[-6.8663e-01,  1.9850e-01, -9.1850e-01,  ..., -9.6673e-01,\n",
       "           -3.1194e-01,  9.1124e-01],\n",
       "          [-1.0094e+00, -6.8083e-01,  4.0126e-02,  ..., -4.3702e-01,\n",
       "           -6.4665e-02,  1.2486e+00],\n",
       "          [-1.2191e+00, -4.7123e-01, -3.8674e-01,  ..., -4.1254e-01,\n",
       "            3.0990e-02,  1.3323e+00],\n",
       "          ...,\n",
       "          [-1.4712e-02,  6.1325e-01,  8.2171e-02,  ..., -5.5417e-01,\n",
       "           -8.7471e-01, -8.5474e-01],\n",
       "          [ 3.2609e-01, -1.2312e-02,  5.8338e-01,  ..., -3.6671e-01,\n",
       "            3.5255e-01, -1.9612e-01],\n",
       "          [-7.9793e-02, -1.7203e-02,  9.8509e-02,  ...,  5.0947e-02,\n",
       "           -1.7950e-02, -2.1192e-01]],\n",
       "\n",
       "         [[-2.3437e-01,  1.8218e-01,  7.2372e-01,  ..., -2.1785e-01,\n",
       "           -1.4943e-01,  4.1743e-03],\n",
       "          [-6.6769e-01,  3.7261e-01,  4.7098e-01,  ..., -1.4850e-01,\n",
       "           -1.7405e-01,  1.5640e-01],\n",
       "          [-6.3620e-01, -1.1929e-02,  4.3321e-01,  ..., -3.1380e-01,\n",
       "            2.5575e-01,  3.3324e-01],\n",
       "          ...,\n",
       "          [ 7.1687e-01,  7.5210e-01,  3.2886e-01,  ..., -2.0350e-01,\n",
       "           -7.3321e-01, -2.9765e-01],\n",
       "          [ 5.7617e-01, -1.5826e-01,  6.9250e-01,  ...,  2.7243e-01,\n",
       "           -7.9971e-02,  5.6527e-01],\n",
       "          [-1.2851e-03,  8.6633e-02, -4.0311e-02,  ..., -1.1119e-01,\n",
       "           -1.8223e-01,  5.0517e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.8335e-01, -9.4615e-02, -3.1868e-02,  ..., -7.4396e-01,\n",
       "           -1.7451e-02,  5.8613e-01],\n",
       "          [ 7.8148e-01,  1.3261e-01,  4.2286e-01,  ..., -6.5869e-01,\n",
       "           -6.8388e-02,  2.2216e-01],\n",
       "          [ 6.0530e-01,  2.7391e-02,  2.2691e-01,  ..., -1.0391e+00,\n",
       "           -1.8669e-01,  3.5758e-01],\n",
       "          ...,\n",
       "          [ 3.6068e-01,  3.6959e-02,  3.2895e-01,  ...,  5.9404e-01,\n",
       "           -2.6592e-01,  6.3490e-02],\n",
       "          [ 2.0125e-01,  4.6425e-01,  2.2109e-03,  ...,  3.9807e-01,\n",
       "           -1.1902e-01, -4.4647e-02],\n",
       "          [-1.7268e-03,  1.5741e-02,  2.8015e-01,  ..., -5.9426e-01,\n",
       "            1.1649e-01,  3.2334e-02]],\n",
       "\n",
       "         [[-4.5492e-01,  4.0326e-01,  1.0355e-01,  ...,  2.3811e-01,\n",
       "           -9.9699e-02,  7.2981e-01],\n",
       "          [-1.4639e-01,  2.6017e-01,  4.4371e-01,  ..., -4.4427e-02,\n",
       "           -3.9060e-01,  5.0713e-01],\n",
       "          [-2.8739e-01,  2.4611e-01,  3.7657e-01,  ...,  3.6390e-01,\n",
       "           -2.5213e-01,  4.7701e-01],\n",
       "          ...,\n",
       "          [-2.5829e-01,  4.5167e-02,  7.8188e-01,  ...,  2.1485e-01,\n",
       "            8.1327e-01,  2.7295e-01],\n",
       "          [-4.4023e-01, -1.1506e+00,  2.2239e-01,  ..., -4.2896e-01,\n",
       "            1.7480e-01,  1.5432e-01],\n",
       "          [-2.1576e-02,  1.8491e-03,  3.0159e-03,  ...,  2.4653e-01,\n",
       "            2.4551e-01,  7.1480e-02]],\n",
       "\n",
       "         [[-6.4363e-01,  8.5983e-01,  2.2193e-01,  ..., -5.4912e-01,\n",
       "            9.5255e-01,  3.1612e-01],\n",
       "          [-5.0088e-01,  5.4549e-01,  1.3457e-01,  ..., -6.0440e-01,\n",
       "            2.8793e-01, -5.0653e-01],\n",
       "          [-6.1802e-01,  2.4719e-01,  2.7107e-01,  ..., -2.2606e-01,\n",
       "            3.7260e-01,  1.2402e-01],\n",
       "          ...,\n",
       "          [ 3.1274e-01,  3.7105e-01, -2.6859e-01,  ..., -2.2435e-01,\n",
       "           -4.8412e-02, -1.4404e-01],\n",
       "          [-3.8671e-01, -8.7733e-03,  2.7985e-02,  ..., -1.8258e-01,\n",
       "           -4.6456e-01, -3.1954e-01],\n",
       "          [ 4.7289e-02,  5.5786e-02, -2.7906e-01,  ...,  1.4153e-01,\n",
       "           -9.2087e-03, -2.7951e-01]]]], grad_fn=<CloneBackward0>)), (tensor([[[[ 5.4266, -2.7376, -2.6432,  ...,  3.3807, -1.9171, -1.2062],\n",
       "          [ 5.1605, -2.9183, -2.3908,  ...,  3.4667, -2.1482, -0.8966]],\n",
       "\n",
       "         [[-5.8098, -4.1571, -1.8877,  ...,  4.1145,  2.0258,  1.3862],\n",
       "          [-5.0915, -3.0403, -1.3525,  ...,  4.0113,  2.4412,  1.8487]],\n",
       "\n",
       "         [[ 3.8664,  1.3112,  1.0239,  ...,  2.0017,  0.3487, -2.3547],\n",
       "          [ 3.4628,  0.6056,  0.8901,  ...,  2.1435,  0.2250, -2.1957]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6553,  1.3942, -0.3352,  ...,  4.4601,  2.3484, -1.3981],\n",
       "          [ 2.0475,  1.3986, -0.0640,  ...,  3.9425,  1.8350, -1.1196]],\n",
       "\n",
       "         [[ 0.9227,  1.2422,  0.7761,  ..., -1.9413, -4.9211,  0.3846],\n",
       "          [ 1.0024,  1.3496,  0.4851,  ..., -2.1203, -5.1308,  0.2005]],\n",
       "\n",
       "         [[ 2.4664, -1.0083,  1.0424,  ..., -2.3486, -0.5020,  2.0209],\n",
       "          [ 2.7164, -0.8344,  0.5124,  ..., -2.2640, -0.2637,  1.7211]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.3609,  0.2187,  0.2188,  ...,  0.5132, -0.0494,  0.1500],\n",
       "          [ 0.6442,  0.5702,  0.4574,  ...,  0.4726,  0.0746,  0.3280]],\n",
       "\n",
       "         [[-0.5180,  0.8459,  0.3035,  ...,  0.1619, -0.7094, -0.3703],\n",
       "          [-0.1051,  0.7163,  0.1964,  ...,  0.0548, -0.5315,  0.1004]],\n",
       "\n",
       "         [[ 1.0333,  0.1181, -0.6816,  ...,  0.5051,  0.0780, -0.0378],\n",
       "          [ 0.4021,  0.2729, -0.8330,  ...,  0.3239,  0.0222, -0.1452]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6474, -0.4175,  0.1892,  ..., -0.5466, -1.1273,  1.1247],\n",
       "          [-0.4596, -0.2338,  0.3922,  ..., -0.8327, -0.7960,  1.2677]],\n",
       "\n",
       "         [[-0.2348, -0.2200, -0.1452,  ...,  0.7813, -0.1373, -0.8726],\n",
       "          [-0.0868, -0.1620, -0.1941,  ...,  0.8158,  0.0503, -0.4402]],\n",
       "\n",
       "         [[ 0.1131, -0.1893,  0.7329,  ..., -0.2390, -0.6897, -1.0133],\n",
       "          [ 0.0546, -0.2984,  0.3531,  ..., -0.3500, -0.3355, -0.9088]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 0.4649,  0.6416, -0.2250,  ..., -0.1429, -0.3017,  1.4142],\n",
       "          [ 1.2866,  0.9735, -1.4924,  ..., -0.1629,  0.0206,  1.8949],\n",
       "          [ 0.8917,  1.2235, -0.9368,  ..., -0.6186, -0.3274,  1.3456],\n",
       "          ...,\n",
       "          [-1.5175,  0.4130,  1.2627,  ..., -0.7914, -1.2393,  0.0358],\n",
       "          [-1.3364,  0.1596,  1.9920,  ..., -0.6207, -0.8783, -0.1925],\n",
       "          [-0.5568,  0.2465,  2.3367,  ..., -0.3158, -0.4575, -0.1069]],\n",
       "\n",
       "         [[-0.7086,  0.8988,  0.1532,  ...,  0.4186, -0.9140, -0.9078],\n",
       "          [-1.9979,  0.2929, -0.0857,  ...,  0.1363, -0.4833, -0.4112],\n",
       "          [-1.3765,  0.1591, -0.3201,  ...,  0.0650, -0.2198, -0.3071],\n",
       "          ...,\n",
       "          [ 0.9931,  0.4343, -0.8177,  ...,  0.7482, -1.1150, -1.9681],\n",
       "          [ 0.4017,  0.3982, -1.1012,  ..., -0.3273, -0.4553, -0.5914],\n",
       "          [ 0.0531,  0.2865, -1.1141,  ..., -0.0754, -0.0679, -1.2489]],\n",
       "\n",
       "         [[-1.3992, -2.1070,  0.3581,  ...,  0.5789,  0.1803, -0.4890],\n",
       "          [-1.2543, -1.4485, -0.7181,  ...,  0.5031, -1.3144,  0.2982],\n",
       "          [-1.0271, -2.1043, -0.2911,  ...,  0.1672, -0.7987, -0.2482],\n",
       "          ...,\n",
       "          [-1.1886, -2.2180,  1.0712,  ...,  0.6386,  0.1599, -1.3719],\n",
       "          [-0.7321, -2.7154,  1.1880,  ..., -0.2661,  0.9307, -1.7541],\n",
       "          [-1.8442, -2.9637,  0.4881,  ...,  0.5132,  0.7910, -1.6123]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0510,  0.2576,  0.7060,  ..., -0.7754,  0.8189,  1.2605],\n",
       "          [-0.8242,  0.0484,  0.2504,  ..., -1.2829,  0.6803,  1.0672],\n",
       "          [-1.0364,  0.3036,  0.4471,  ..., -0.7832,  0.9029,  1.1028],\n",
       "          ...,\n",
       "          [ 0.1135,  0.4282,  0.9428,  ..., -0.6494,  0.5990,  0.5885],\n",
       "          [-0.3677, -0.4331,  0.2366,  ...,  0.2388,  1.1125,  0.1464],\n",
       "          [-0.8209, -0.0690,  0.3035,  ..., -0.1176,  0.4682,  0.5938]],\n",
       "\n",
       "         [[ 0.0173,  2.1350, -0.3964,  ..., -0.5921,  0.7140, -0.5578],\n",
       "          [-0.0200,  1.1901,  0.2258,  ..., -0.0649,  0.2269,  0.4575],\n",
       "          [ 0.0225,  1.5150, -0.2151,  ..., -0.3632,  0.7951,  0.0238],\n",
       "          ...,\n",
       "          [-0.5915,  3.2066, -1.4197,  ..., -0.9913,  0.8903, -0.3722],\n",
       "          [-0.3121,  2.6024, -1.7843,  ..., -0.1838,  1.6259,  0.4247],\n",
       "          [-0.3221,  3.0918, -1.3838,  ..., -0.5197,  1.9579, -0.6278]],\n",
       "\n",
       "         [[-0.2119, -0.4367, -0.3984,  ..., -0.3206, -0.1013,  1.7794],\n",
       "          [-0.3840, -0.8160, -0.6518,  ..., -0.8398, -0.1954,  2.0228],\n",
       "          [-0.3705, -1.0972, -0.6237,  ..., -0.4233, -0.0675,  1.5879],\n",
       "          ...,\n",
       "          [-0.5505, -0.4334, -0.6982,  ..., -1.3369,  0.1431,  0.7593],\n",
       "          [ 0.2661, -0.6563, -0.2717,  ..., -1.7729,  1.0057,  1.5933],\n",
       "          [ 0.1883, -1.4220, -0.7325,  ..., -2.0236,  0.8948,  2.0841]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.1237, -0.8134,  0.3312,  ...,  0.3047,  0.2091, -0.5235],\n",
       "          [-0.9490, -0.3475,  0.2316,  ...,  0.0033, -0.3342, -0.3703],\n",
       "          [-0.8413, -0.1978,  0.5163,  ...,  0.3331, -0.4665, -0.5604],\n",
       "          ...,\n",
       "          [-0.9701, -0.8353,  0.3124,  ..., -0.1095, -0.1925, -1.0182],\n",
       "          [-0.1149, -0.2257, -0.7164,  ...,  0.1028,  0.3681,  0.4893],\n",
       "          [ 0.0547, -0.0060, -0.1188,  ...,  0.1013,  0.1908,  0.1105]],\n",
       "\n",
       "         [[-0.0614, -0.2012, -0.1310,  ...,  0.3314,  0.1255,  0.9098],\n",
       "          [ 0.0723,  0.0953, -0.8032,  ...,  0.4159, -0.4122,  0.7339],\n",
       "          [-0.0492,  0.1148, -0.4908,  ...,  0.1525, -0.6105,  0.4093],\n",
       "          ...,\n",
       "          [ 0.9232,  0.4276, -0.5191,  ..., -0.2922,  0.0333,  0.0248],\n",
       "          [-0.6421, -0.0925, -0.0259,  ..., -0.6984, -0.0805,  0.2037],\n",
       "          [ 0.0261,  0.0212,  0.0018,  ..., -0.0409,  0.1579, -0.2118]],\n",
       "\n",
       "         [[ 0.0879,  0.3223, -0.2588,  ...,  0.3735,  0.3811,  0.1551],\n",
       "          [ 0.2008, -0.1361,  0.0823,  ...,  0.1534, -0.0913,  0.3469],\n",
       "          [ 0.4441, -0.2724, -0.2557,  ...,  0.0072, -0.1548,  0.0720],\n",
       "          ...,\n",
       "          [ 0.3310, -0.0671, -0.1960,  ..., -0.9389,  0.3043, -0.7827],\n",
       "          [-0.2670, -0.0291, -0.5813,  ..., -0.4293,  0.3147,  0.4719],\n",
       "          [ 0.0781, -0.0619,  0.1165,  ...,  0.0368, -0.0884,  0.1712]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.3106, -0.1294,  0.0758,  ..., -0.6619, -0.0136,  0.8338],\n",
       "          [-0.2657,  0.0035, -0.2200,  ..., -0.1334, -0.1963,  0.6328],\n",
       "          [ 0.0434,  0.1125, -0.3004,  ...,  0.3402, -0.3734,  0.8938],\n",
       "          ...,\n",
       "          [ 0.0226, -0.0115, -0.2183,  ..., -0.0937,  0.1415, -0.0753],\n",
       "          [ 0.1260,  0.1810, -0.0172,  ..., -0.3638, -0.2581, -0.5204],\n",
       "          [ 0.1108,  0.0962, -0.0880,  ...,  0.0403, -0.1062,  0.0578]],\n",
       "\n",
       "         [[-0.4620,  0.4757,  0.0816,  ..., -0.9028,  0.5011,  0.9444],\n",
       "          [-0.4818,  0.4166,  0.2459,  ..., -0.6111,  0.5501,  0.4206],\n",
       "          [-0.3886,  0.5733, -0.0355,  ..., -0.5579, -0.1069,  0.2547],\n",
       "          ...,\n",
       "          [-0.2584, -0.1737, -0.4945,  ...,  0.0249, -0.4298,  0.3369],\n",
       "          [ 0.7197, -0.2686,  0.5439,  ...,  0.4841,  0.0937,  0.2176],\n",
       "          [-0.0755, -0.1505, -0.0269,  ..., -0.0628, -0.2004,  0.0178]],\n",
       "\n",
       "         [[-0.6595,  0.4054, -0.4982,  ...,  0.3789, -0.4071, -0.4357],\n",
       "          [-0.5795,  0.7249, -0.3479,  ...,  0.3665, -0.3341,  0.0480],\n",
       "          [-0.6233,  0.2640, -0.5832,  ...,  0.4090, -0.3415, -0.2311],\n",
       "          ...,\n",
       "          [-0.7658,  0.9649,  0.2713,  ..., -0.7163,  0.1070,  0.9358],\n",
       "          [ 0.8295,  0.6690,  0.1172,  ...,  0.9351, -0.4394,  0.3801],\n",
       "          [ 0.2702,  0.0951, -0.0535,  ...,  0.0722,  0.0524,  0.0978]]]],\n",
       "       grad_fn=<CloneBackward0>)), (tensor([[[[-1.9016e+00, -2.3007e+00, -1.1660e-01,  ...,  1.6919e+00,\n",
       "           -9.0249e-01, -9.3598e-01],\n",
       "          [-2.1447e+00, -2.2321e+00, -5.9621e-02,  ...,  1.4077e+00,\n",
       "           -8.2736e-01, -6.6620e-01]],\n",
       "\n",
       "         [[ 1.3892e-01, -1.6666e+00,  1.9763e+00,  ..., -1.3383e+00,\n",
       "           -5.4025e+00,  8.8261e-02],\n",
       "          [ 3.8980e-01, -1.1602e+00,  1.6801e+00,  ..., -1.2483e+00,\n",
       "           -5.0566e+00,  4.1282e-01]],\n",
       "\n",
       "         [[-3.6501e-01,  6.8326e-01,  2.7572e+00,  ..., -8.5552e-01,\n",
       "            2.7462e+00, -1.3806e-01],\n",
       "          [-4.9190e-01,  7.1506e-01,  2.8306e+00,  ..., -6.3360e-01,\n",
       "            2.6470e+00, -7.4643e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.7025e+00,  3.0881e+00,  6.2491e-01,  ..., -3.0754e+00,\n",
       "            1.5580e+00,  3.9178e-01],\n",
       "          [ 4.4844e+00,  3.2262e+00,  5.3112e-01,  ..., -3.2146e+00,\n",
       "            1.1420e+00,  1.1119e-01]],\n",
       "\n",
       "         [[-5.5948e-01,  5.1128e-01, -2.8340e+00,  ..., -3.6740e+00,\n",
       "           -3.0336e+00, -3.7373e-01],\n",
       "          [-8.8283e-01,  1.0081e-01, -2.2026e+00,  ..., -3.5309e+00,\n",
       "           -3.4125e+00, -7.6585e-01]],\n",
       "\n",
       "         [[ 2.1280e+00, -2.2742e+00,  1.9896e+00,  ..., -5.0429e-01,\n",
       "           -4.9286e-01,  5.3260e-04],\n",
       "          [ 2.2403e+00, -2.3669e+00,  1.6759e+00,  ..., -1.2599e-01,\n",
       "           -1.0524e-01,  3.2811e-01]]]], grad_fn=<CloneBackward0>), tensor([[[[ 0.0647,  0.0137, -0.5086,  ..., -0.4151, -0.7708, -0.5779],\n",
       "          [ 0.2582,  0.1466, -0.5530,  ..., -0.2267, -0.4500, -0.6014]],\n",
       "\n",
       "         [[ 0.5495,  0.4456, -0.5211,  ...,  0.0219, -0.2004, -0.0593],\n",
       "          [ 0.2980,  0.5903, -0.2233,  ...,  0.0125, -0.6841,  0.0125]],\n",
       "\n",
       "         [[ 0.4843,  0.2770,  0.2350,  ..., -1.5127,  1.1594, -0.5067],\n",
       "          [ 0.3663,  0.2737,  0.1505,  ..., -1.3722,  1.0575, -0.2306]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.4666,  0.4218,  0.0737,  ...,  0.2977,  0.5746, -0.1416],\n",
       "          [ 0.3281,  0.4981, -0.1667,  ...,  0.4825,  0.4095,  0.2477]],\n",
       "\n",
       "         [[ 0.8454,  0.2551, -0.3411,  ..., -0.6373, -0.4533, -0.5525],\n",
       "          [ 0.6671,  0.2249, -0.3199,  ..., -0.5969, -0.6296, -0.9248]],\n",
       "\n",
       "         [[-0.2522,  0.0826,  0.1606,  ..., -1.0990, -0.0960,  1.2838],\n",
       "          [-0.1429,  0.4561, -0.0864,  ..., -1.1959, -0.2285,  1.0963]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[-0.2513, -1.2348, -1.5078,  ...,  0.3231, -0.9230, -0.2733],\n",
       "          [-0.4342, -1.0598, -1.4450,  ...,  0.3139, -0.8881, -1.0525],\n",
       "          [-0.2332, -1.1580, -1.4506,  ...,  0.4026, -0.5265, -0.9943],\n",
       "          ...,\n",
       "          [-0.9224,  0.5268, -1.2788,  ...,  0.3002,  0.5270, -0.7226],\n",
       "          [ 0.3103,  1.1918, -1.1985,  ...,  1.3792, -0.5159,  0.1892],\n",
       "          [-0.3886,  0.8262, -1.3483,  ...,  0.8775,  0.0042, -0.0747]],\n",
       "\n",
       "         [[ 0.0975,  0.2396,  0.5860,  ..., -0.2544, -0.2521, -0.1234],\n",
       "          [ 0.5405,  1.0641,  1.0935,  ..., -0.9592,  0.1893,  0.2172],\n",
       "          [ 0.4793,  0.9228,  0.6378,  ..., -0.8133,  0.0342,  0.1543],\n",
       "          ...,\n",
       "          [-0.2187, -1.4149,  0.4598,  ...,  0.4323, -0.6622, -0.3891],\n",
       "          [-0.6455, -0.2492, -0.5806,  ..., -0.2668, -0.4266,  1.1583],\n",
       "          [-0.7662, -0.7798, -0.0553,  ..., -0.2241, -0.3104,  1.1572]],\n",
       "\n",
       "         [[-0.6630,  0.3075,  0.9713,  ...,  0.0404,  0.1616,  1.0455],\n",
       "          [ 0.2121,  0.6047,  0.2838,  ...,  0.8785,  1.4867,  1.0835],\n",
       "          [ 0.2240,  0.0782,  0.5242,  ...,  0.7341,  1.2198,  1.5981],\n",
       "          ...,\n",
       "          [ 1.2486, -0.4768,  0.7905,  ..., -0.3137, -1.3389,  0.3561],\n",
       "          [ 0.7954, -0.5711,  0.7664,  ..., -0.0359, -1.4178, -0.1514],\n",
       "          [ 1.1216, -0.2094,  0.9430,  ...,  0.4064, -1.4824,  1.0472]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.7260,  0.7894,  0.4606,  ...,  1.1389, -1.8195,  0.2689],\n",
       "          [ 0.8031,  0.7566,  0.2630,  ...,  1.3992, -0.7558, -0.7264],\n",
       "          [ 1.1906,  1.0660,  0.1989,  ...,  1.0172, -1.3340, -0.4285],\n",
       "          ...,\n",
       "          [ 0.1411,  0.1921,  1.3807,  ...,  0.3295, -0.0878, -0.2929],\n",
       "          [-1.2159,  0.8875,  1.7001,  ..., -0.3353, -0.1690, -0.0826],\n",
       "          [ 0.0046,  0.8104,  2.7187,  ..., -0.0610, -1.2920, -0.1251]],\n",
       "\n",
       "         [[-0.4808,  1.4040,  0.6557,  ..., -0.4111,  0.2902,  0.4969],\n",
       "          [ 0.1385,  0.5953,  0.2365,  ..., -0.9628,  1.0123, -0.0591],\n",
       "          [-0.6093,  0.9661,  0.7251,  ..., -0.8598,  1.3676,  0.3082],\n",
       "          ...,\n",
       "          [-1.2466,  0.5824, -0.2931,  ...,  0.1742, -0.9237,  1.1359],\n",
       "          [-1.6501,  0.9834,  0.3474,  ..., -0.7564, -0.8028,  1.3534],\n",
       "          [-2.3478,  1.1062, -0.5570,  ..., -0.6590, -0.4021,  1.7092]],\n",
       "\n",
       "         [[-0.3425,  2.0380, -0.6225,  ..., -0.9599, -0.1873,  1.2790],\n",
       "          [-0.0503,  1.6266, -0.2844,  ..., -2.0051, -1.3594,  1.7224],\n",
       "          [-0.8979,  1.5424,  0.1115,  ..., -1.1731, -1.4161,  1.2658],\n",
       "          ...,\n",
       "          [-1.4962,  2.0935, -0.5924,  ...,  0.0119,  1.3507,  1.5686],\n",
       "          [-0.7556,  2.2321, -0.3797,  ...,  0.0161, -0.2461,  1.9458],\n",
       "          [-2.2671,  2.4844, -0.3485,  ..., -0.2952,  0.4699,  1.8589]]]],\n",
       "       grad_fn=<CloneBackward0>), tensor([[[[ 8.2362e-01, -7.5945e-01,  5.6607e-01,  ..., -1.9705e-01,\n",
       "           -2.6457e-01, -3.1946e-01],\n",
       "          [ 5.8791e-01, -5.6700e-01,  3.1372e-01,  ..., -1.2426e-01,\n",
       "           -3.3156e-02, -4.4434e-01],\n",
       "          [ 6.3905e-01, -2.8594e-01,  6.1144e-01,  ..., -4.0505e-02,\n",
       "           -2.0777e-01, -6.1614e-01],\n",
       "          ...,\n",
       "          [ 3.0257e-01, -5.4080e-01,  2.1331e-01,  ..., -5.7705e-01,\n",
       "            8.5254e-02, -2.5805e-01],\n",
       "          [ 8.1770e-03,  3.8272e-01,  1.3973e-01,  ...,  8.4968e-02,\n",
       "           -2.7724e-02, -5.2607e-01],\n",
       "          [ 1.9334e-01, -1.9885e-01,  4.2412e-01,  ...,  1.6507e-01,\n",
       "            1.7552e-01, -1.4440e-01]],\n",
       "\n",
       "         [[-8.9565e-01, -4.6893e-01,  3.2284e-01,  ..., -6.4630e-01,\n",
       "            6.4779e-03, -1.0295e-01],\n",
       "          [-9.8375e-01, -7.9135e-02, -2.4317e-01,  ..., -3.8218e-02,\n",
       "           -4.3902e-01,  2.0480e-03],\n",
       "          [-1.0135e+00, -1.9386e-01,  1.3472e-01,  ..., -5.3467e-01,\n",
       "           -1.0184e-01, -1.7140e-02],\n",
       "          ...,\n",
       "          [-8.2502e-01,  7.9761e-01,  2.1704e-01,  ..., -6.6569e-01,\n",
       "            1.4941e-01, -3.0024e-01],\n",
       "          [-4.6346e-01,  1.3610e-01,  5.8030e-01,  ..., -7.6575e-02,\n",
       "            1.4069e-01, -1.5484e-02],\n",
       "          [-9.5181e-03,  8.4907e-02, -1.4564e-01,  ...,  3.6487e-02,\n",
       "           -7.6112e-02, -8.3691e-02]],\n",
       "\n",
       "         [[-2.8758e-01, -1.8744e-01,  8.4831e-02,  ...,  5.4117e-01,\n",
       "            8.6039e-02,  1.0418e-01],\n",
       "          [ 1.5112e-01, -4.1489e-02, -2.1973e-01,  ...,  3.3403e-01,\n",
       "            4.8028e-01, -3.5648e-01],\n",
       "          [ 6.6012e-02,  1.4674e-01,  2.6915e-02,  ...,  4.2890e-01,\n",
       "            2.1658e-01, -1.4394e-01],\n",
       "          ...,\n",
       "          [-9.8199e-01, -1.7437e-01,  2.5842e-01,  ...,  1.1192e+00,\n",
       "           -6.4206e-01, -2.6479e-01],\n",
       "          [-1.3435e-01,  4.4935e-02,  7.8377e-03,  ...,  5.0178e-01,\n",
       "            2.5555e-01, -1.4986e-01],\n",
       "          [-7.0653e-02,  8.6174e-03, -4.6150e-02,  ...,  5.4689e-02,\n",
       "            9.8545e-02, -1.3429e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.6213e-01, -2.3632e-01,  3.9356e-01,  ..., -1.1550e-01,\n",
       "            9.3036e-01,  2.2222e-01],\n",
       "          [-5.9494e-01, -3.1321e-01, -1.6286e-01,  ..., -2.8808e-01,\n",
       "            1.0598e+00,  3.5041e-03],\n",
       "          [-1.0888e-01, -7.5369e-01, -8.3186e-03,  ..., -1.3624e-01,\n",
       "            1.0458e+00, -1.9526e-01],\n",
       "          ...,\n",
       "          [-5.1010e-01,  1.8295e-01, -3.7604e-02,  ...,  1.8036e-01,\n",
       "            7.4138e-01, -7.2250e-02],\n",
       "          [-1.3149e+00,  2.3893e-01,  4.2477e-01,  ...,  6.8632e-01,\n",
       "           -1.3948e-04,  7.3800e-01],\n",
       "          [-1.2295e-01, -1.2286e-01, -2.6129e-03,  ..., -1.5269e-01,\n",
       "            4.5609e-02,  9.3862e-02]],\n",
       "\n",
       "         [[ 1.5939e-01,  2.6039e-01,  7.6036e-02,  ..., -6.2226e-01,\n",
       "            4.9611e-01,  3.0943e-01],\n",
       "          [ 9.4813e-03, -4.2086e-01,  1.2930e-02,  ..., -5.7814e-01,\n",
       "            6.1611e-01,  3.2336e-01],\n",
       "          [ 4.0913e-01, -5.0785e-01,  2.5746e-01,  ..., -2.6889e-03,\n",
       "            2.7495e-01,  2.5191e-01],\n",
       "          ...,\n",
       "          [ 4.2197e-01,  9.3741e-01,  2.3267e-01,  ..., -3.8783e-01,\n",
       "            4.1087e-01, -1.1074e-01],\n",
       "          [ 1.3548e-02,  1.1081e-01,  1.8516e-03,  ...,  8.3537e-02,\n",
       "            3.6097e-01,  5.9842e-01],\n",
       "          [-6.6124e-02, -1.5145e-01, -5.5891e-02,  ...,  2.1516e-02,\n",
       "            1.5607e-02, -1.4111e-01]],\n",
       "\n",
       "         [[ 2.2829e-01, -4.6691e-01, -2.9967e-01,  ...,  2.1760e-01,\n",
       "           -6.1931e-01, -3.6556e-01],\n",
       "          [-1.6673e-01, -5.8531e-01,  2.4082e-02,  ...,  9.2248e-02,\n",
       "           -4.0735e-01, -4.5913e-01],\n",
       "          [-1.3262e-01, -2.5814e-01, -3.7657e-01,  ..., -1.4925e-01,\n",
       "           -4.6762e-01, -1.1261e-01],\n",
       "          ...,\n",
       "          [ 4.8090e-01,  1.3924e-01, -5.5823e-01,  ..., -1.1701e-01,\n",
       "           -8.7232e-01,  2.4273e-01],\n",
       "          [-6.9611e-02,  2.7643e-01,  1.6930e-04,  ...,  4.5802e-01,\n",
       "            4.5270e-03, -6.1025e-01],\n",
       "          [ 2.1220e-01, -1.3486e-01,  5.7656e-02,  ..., -6.2545e-02,\n",
       "           -1.1872e-01,  1.4587e-01]]]], grad_fn=<CloneBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[ 0.1095,  0.5291,  0.1799,  ...,  0.1385,  0.0513,  0.1089],\n",
       "         [ 0.5189,  0.7736, -0.2372,  ..., -0.0176,  0.0649,  0.1205],\n",
       "         [ 0.0696,  0.6044, -0.1807,  ...,  0.2840,  0.0128,  0.1529],\n",
       "         ...,\n",
       "         [-0.0834, -0.0459,  0.0362,  ...,  0.4206, -0.0913,  0.0160],\n",
       "         [-0.1947,  0.1064,  0.1507,  ..., -0.4860,  0.3502, -0.2948],\n",
       "         [-0.0977,  0.1718, -0.0807,  ..., -0.0343, -0.0597, -0.1761]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \",  ?\"\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "out = model(input_ids, decoder_input_ids=torch.tensor([[0, 321]]))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = out.logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> <pad>'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[64376, 64376]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(out.logits.shape[-1]):\n",
    "    if tokenizer.decode(torch.tensor(i)) == \"<SOS\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1 tokenizer.decode(model.generate(tokenizer.encode(<span style=\"color: #808000; text-decoration-color: #808000\">\"  ?\"</span>, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"p</span>     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">transformers/models/marian/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_marian.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">266</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">         </span><span style=\"color: #808000; text-decoration-color: #808000\">`str`: The decoded sentence.</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>266 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().decode(token_ids, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">268 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert_tokens_to_string</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, tokens: List[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>]) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">      </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Uses source spm if _decode_use_source_tokenizer is True, and target spm other</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3525</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3522 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Convert inputs to python lists</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3523 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>token_ids = to_py_obj(token_ids)                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3524 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>3525 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._decode(                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3526 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>token_ids=token_ids,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3527 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>skip_special_tokens=skip_special_tokens,                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3528 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>clean_up_tokenization_spaces=clean_up_tokenization_spaces,                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">931</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_decode</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">928 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">   </span>) -&gt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">929 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._decode_use_source_tokenizer = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"use_source_tokenizer\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">930 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>931 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>filtered_tokens = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.convert_ids_to_tokens(token_ids, skip_special_tokens=skip   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">932 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">933 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># To avoid mixing byte-level and unicode for byte-level BPT</span>                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">934 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># we need to build string separately for added tokens and byte-level tokens</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">906</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert_ids_to_tokens</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">903 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._convert_id_to_token(ids)                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">904 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>tokens = []                                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">905 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> index <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> ids:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>906 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(index)                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">907 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> skip_special_tokens <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> index <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.all_special_ids:                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">908 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">909 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> index <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.added_tokens_decoder:                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">int</span><span style=\"font-weight: bold\">()</span> argument must be a string, a bytes-like object or a real number, not <span style=\"color: #008000; text-decoration-color: #008000\">'list'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1 tokenizer.decode(model.generate(tokenizer.encode(\u001b[33m\"\u001b[0m\u001b[33m  ?\u001b[0m\u001b[33m\"\u001b[0m, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mp\u001b[0m     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtransformers/models/marian/\u001b[0m\u001b[1;33mtokenization_marian.py\u001b[0m:\u001b[94m266\u001b[0m in \u001b[92mdecode\u001b[0m                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33mReturns:\u001b[0m                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2;33m         \u001b[0m\u001b[33m`str`: The decoded sentence.\u001b[0m                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2;33m      \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m266 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().decode(token_ids, **kwargs)                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mconvert_tokens_to_string\u001b[0m(\u001b[96mself\u001b[0m, tokens: List[\u001b[96mstr\u001b[0m]) -> \u001b[96mstr\u001b[0m:                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2;90m      \u001b[0m\u001b[33m\"\"\"Uses source spm if _decode_use_source_tokenizer is True, and target spm other\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtransformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m3525\u001b[0m in \u001b[92mdecode\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3522 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Convert inputs to python lists\u001b[0m                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3523 \u001b[0m\u001b[2m      \u001b[0mtoken_ids = to_py_obj(token_ids)                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3524 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m3525 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._decode(                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3526 \u001b[0m\u001b[2m         \u001b[0mtoken_ids=token_ids,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3527 \u001b[0m\u001b[2m         \u001b[0mskip_special_tokens=skip_special_tokens,                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m3528 \u001b[0m\u001b[2m         \u001b[0mclean_up_tokenization_spaces=clean_up_tokenization_spaces,                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtransformers/\u001b[0m\u001b[1;33mtokenization_utils.py\u001b[0m:\u001b[94m931\u001b[0m in \u001b[92m_decode\u001b[0m                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m928 \u001b[0m\u001b[2m   \u001b[0m) -> \u001b[96mstr\u001b[0m:                                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m929 \u001b[0m\u001b[2m      \u001b[0m\u001b[96mself\u001b[0m._decode_use_source_tokenizer = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33muse_source_tokenizer\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m)      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m930 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m931 \u001b[2m      \u001b[0mfiltered_tokens = \u001b[96mself\u001b[0m.convert_ids_to_tokens(token_ids, skip_special_tokens=skip   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m932 \u001b[0m\u001b[2m      \u001b[0m                                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m933 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[0m                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m934 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# we need to build string separately for added tokens and byte-level tokens\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33mtransformers/\u001b[0m\u001b[1;33mtokenization_utils.py\u001b[0m:\u001b[94m906\u001b[0m in \u001b[92mconvert_ids_to_tokens\u001b[0m                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m903 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._convert_id_to_token(ids)                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m904 \u001b[0m\u001b[2m      \u001b[0mtokens = []                                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m905 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mfor\u001b[0m index \u001b[95min\u001b[0m ids:                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m906 \u001b[2m         \u001b[0mindex = \u001b[96mint\u001b[0m(index)                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m skip_special_tokens \u001b[95mand\u001b[0m index \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.all_special_ids:                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m908 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mcontinue\u001b[0m                                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m909 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mif\u001b[0m index \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.added_tokens_decoder:                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mint\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m argument must be a string, a bytes-like object or a real number, not \u001b[32m'list'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(tokenizer.encode(\"  ?\", return_tensors=\"pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
