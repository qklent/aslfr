{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77447172-73ab-438c-9352-b6a9c7fa9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 01:30:09.862258: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-24 01:30:10.076276: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-24 01:30:10.077524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 01:30:11.757603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aad240ac-d0f5-4c0d-b0a8-de66cf723664",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 32, 60)\n",
    "conv = nn.Conv1d(32, 64, 2, stride=2, groups=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8baae50b-1914-4e4d-8349-6dc47bb3ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 30])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39785c87-32ad-4f42-acfa-37bd8dd937ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4160"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 0\n",
    "for x in conv.parameters():\n",
    "    curr = 1\n",
    "    for y in x.shape:\n",
    "        curr *= y\n",
    "        \n",
    "    params += curr\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "363a24da-c4d7-44bf-afd9-bf628fa0548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, out_dim, qk_dim, v_dim, num_head, kernel_size=1, stride=1):\n",
    "        super(MyMultiHeadAttention, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_head = num_head\n",
    "        self.qk_dim = qk_dim\n",
    "        self.v_dim = v_dim\n",
    "\n",
    "        self.q = tf.keras.layers.Conv1D(qk_dim*num_head, kernel_size, strides=stride)\n",
    "        self.k = tf.keras.layers.Conv1D(qk_dim*num_head, kernel_size, strides=stride)\n",
    "        self.v = tf.keras.layers.Conv1D(v_dim*num_head, kernel_size, strides=stride)\n",
    "\n",
    "        self.out = tf.keras.layers.Conv1D(out_dim, 1)\n",
    "        self.scale = 1 / tf.math.sqrt(qk_dim.float())\n",
    "\n",
    "    def call(self, x):\n",
    "        B, L, dim = x.shape\n",
    "\n",
    "        num_head = self.num_head\n",
    "        qk_dim = self.qk_dim\n",
    "        v_dim = self.v_dim\n",
    "\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        \n",
    "        q = tf.reshape(q, (B, L, num_head, qk_dim // self.kernel_size))\n",
    "        q = tf.transpose(q, perm=(0, 2, 1, 3))\n",
    "        \n",
    "        k = tf.reshape(k, (B, L, num_head, qk_dim // self.kernel_size))\n",
    "        \n",
    "        v = tf.reshape(v, (B, L, num_head, v_dim // self.kernel_size))\n",
    "        v = tf.transpose(v, perm=(0, 2, 1, 3))\n",
    "        \n",
    "        dot = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "        attn = tf.nn.softmax(dot, axis=-1)\n",
    "\n",
    "        v = tf.matmul(attn, v)\n",
    "        v = tf.transpose(v, perm=(0, 2, 1, 3))\n",
    "        v = tf.reshape(v, (B, L, v_dim*num_head))\n",
    "\n",
    "        out = self.out(v)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2fb3d32e-7ecc-4c29-9d57-5dd58de80d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m96\u001b[39m\n\u001b[1;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 9\u001b[0m mha \u001b[38;5;241m=\u001b[39m \u001b[43mMyMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqk_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m x  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,(batch_size, embed_dim, max_length))\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[0;32mIn[63], line 16\u001b[0m, in \u001b[0;36mMyMultiHeadAttention.__init__\u001b[0;34m(self, embed_dim, out_dim, qk_dim, v_dim, num_head, kernel_size, stride)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(v_dim\u001b[38;5;241m*\u001b[39mnum_head, kernel_size, strides\u001b[38;5;241m=\u001b[39mstride)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(out_dim, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqk_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'T' of int32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]"
     ]
    }
   ],
   "source": [
    "embed_dim = 512\n",
    "out_dim   = 512\n",
    "qk_dim    = 512//4 #for one head\n",
    "v_dim     = 512//4\n",
    "num_head  = 4\n",
    "max_length = 96\n",
    "batch_size = 4\n",
    "\n",
    "mha = MyMultiHeadAttention(\n",
    "    embed_dim,\n",
    "    out_dim,\n",
    "    qk_dim,\n",
    "    v_dim,\n",
    "    num_head,\n",
    ")\n",
    "x  = np.random.uniform(-1,1,(batch_size, embed_dim, max_length)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc2962-ff7a-49b4-8f3e-ca7e64f7dcba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
