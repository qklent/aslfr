{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "77ce83c7-ad92-47db-9258-e9ad89f7b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1a23a41d-029c-4eb2-a964-8c2d71c38667",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHRASE_LENGTH = 128\n",
    "MASK_TOKEN = 60\n",
    "N_UNIQUE_CHARACTERS = 60 + 1 # for mask token\n",
    "EMBED_DIM = 128\n",
    "PAD_TOKEN = 59\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5f8a81cb-7419-40a0-a161-4d421472ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/character_to_prediction_index.json\", \"r\") as f:\n",
    "    char_to_num = json.load(f)\n",
    "num_to_char = {j:i for i,j in char_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "09831edb-7a81-4deb-8bad-eab5f079bd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61955, 128)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"../data/y.npy\")[:, :MAX_PHRASE_LENGTH]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a2d5fb85-b9f7-469e-a556-87c3f40a89c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36, 61, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59], dtype=int8)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "fb233250-20ae-44d8-b3fc-259b258bfc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "       59, 59, 59, 59, 59, 59, 59, 59, 59], dtype=int8)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data == 61] = 59\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd5f6d04-96b0-4e6f-a9b5-e4b8dae3b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.scale = self.dim ** -0.5\n",
    "        self.num_heads = num_heads\n",
    "        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n",
    "        self.drop1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        qkv = self.qkv(inputs)\n",
    "        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n",
    "        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n",
    "\n",
    "        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask[:, None, None, :]\n",
    "\n",
    "        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n",
    "        attn = self.drop1(attn)\n",
    "\n",
    "        x = attn @ v\n",
    "        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def TransformerBlock(dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d7c8aea-de08-42b2-b73f-093a84b01009",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "460ea68f-e11b-431d-840b-238242e57732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_encoding_matrix(max_len, d_emb):\n",
    "    pos_enc = np.array(\n",
    "        [\n",
    "            [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)]\n",
    "            if pos != 0\n",
    "            else np.zeros(d_emb)\n",
    "            for pos in range(max_len)\n",
    "        ]\n",
    "    )\n",
    "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
    "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
    "    return pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "19d8cc0d-6de5-47ef-9cb4-ae76f6456238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Initial Loss Weights All Set To 1\n",
    "loss_weights = np.ones(N_UNIQUE_CHARACTERS-1, dtype=np.float32)\n",
    "# Set Loss Weight Of Pad Token To 0\n",
    "loss_weights[PAD_TOKEN] = 0\n",
    "def scce_with_ls(y_true, y_pred):\n",
    "    # Filter Pad Tokens\n",
    "    idxs = tf.where(y_true != PAD_TOKEN)\n",
    "    y_true = tf.gather_nd(y_true, idxs)\n",
    "    y_pred = tf.gather_nd(y_pred, idxs)\n",
    "    # One Hot Encode Sparsely Encoded Target Sign\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_true = tf.one_hot(y_true, N_UNIQUE_CHARACTERS-1, axis=1)\n",
    "    # Categorical Crossentropy with native label smoothing support\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing=0.25, from_logits=True)\n",
    "    loss = tf.math.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "191d39cb-9c8a-44fa-bf3d-3c1edc582d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " ctc_masked_out (InputLayer  [(None, 128)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " char_embedding (Embedding)  (None, 128, 128)             7808      ['ctc_masked_out[0][0]']      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 128, 128)             0         ['char_embedding[0][0]']      \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_76 (La  (None, 128, 128)             256       ['tf.__operators__.add_13[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_76[0][0]\n",
      " 46 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_46\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_75 (Add)                (None, 128, 128)             0         ['tf.__operators__.add_13[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'dropout_107[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_77 (La  (None, 128, 128)             256       ['add_75[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_154 (Dense)           (None, 128, 512)             65536     ['layer_normalization_77[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_155 (Dense)           (None, 128, 128)             65536     ['dense_154[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)       (None, 128, 128)             0         ['dense_155[0][0]']           \n",
      "                                                                                                  \n",
      " add_76 (Add)                (None, 128, 128)             0         ['add_75[0][0]',              \n",
      "                                                                     'dropout_108[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_78 (La  (None, 128, 128)             256       ['add_76[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_78[0][0]\n",
      " 47 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_47\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_77 (Add)                (None, 128, 128)             0         ['add_76[0][0]',              \n",
      "                                                                     'dropout_110[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_79 (La  (None, 128, 128)             256       ['add_77[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_158 (Dense)           (None, 128, 512)             65536     ['layer_normalization_79[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_159 (Dense)           (None, 128, 128)             65536     ['dense_158[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)       (None, 128, 128)             0         ['dense_159[0][0]']           \n",
      "                                                                                                  \n",
      " add_78 (Add)                (None, 128, 128)             0         ['add_77[0][0]',              \n",
      "                                                                     'dropout_111[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_80 (La  (None, 128, 128)             256       ['add_78[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_80[0][0]\n",
      " 48 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_48\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_79 (Add)                (None, 128, 128)             0         ['add_78[0][0]',              \n",
      "                                                                     'dropout_113[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_81 (La  (None, 128, 128)             256       ['add_79[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_162 (Dense)           (None, 128, 512)             65536     ['layer_normalization_81[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_163 (Dense)           (None, 128, 128)             65536     ['dense_162[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)       (None, 128, 128)             0         ['dense_163[0][0]']           \n",
      "                                                                                                  \n",
      " add_80 (Add)                (None, 128, 128)             0         ['add_79[0][0]',              \n",
      "                                                                     'dropout_114[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_82 (La  (None, 128, 128)             256       ['add_80[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_82[0][0]\n",
      " 49 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_49\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_81 (Add)                (None, 128, 128)             0         ['add_80[0][0]',              \n",
      "                                                                     'dropout_116[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_83 (La  (None, 128, 128)             256       ['add_81[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_166 (Dense)           (None, 128, 512)             65536     ['layer_normalization_83[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_167 (Dense)           (None, 128, 128)             65536     ['dense_166[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)       (None, 128, 128)             0         ['dense_167[0][0]']           \n",
      "                                                                                                  \n",
      " add_82 (Add)                (None, 128, 128)             0         ['add_81[0][0]',              \n",
      "                                                                     'dropout_117[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_84 (La  (None, 128, 128)             256       ['add_82[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_84[0][0]\n",
      " 50 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_50\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_83 (Add)                (None, 128, 128)             0         ['add_82[0][0]',              \n",
      "                                                                     'dropout_119[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_85 (La  (None, 128, 128)             256       ['add_83[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_170 (Dense)           (None, 128, 512)             65536     ['layer_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_171 (Dense)           (None, 128, 128)             65536     ['dense_170[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)       (None, 128, 128)             0         ['dense_171[0][0]']           \n",
      "                                                                                                  \n",
      " add_84 (Add)                (None, 128, 128)             0         ['add_83[0][0]',              \n",
      "                                                                     'dropout_120[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_86 (La  (None, 128, 128)             256       ['add_84[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_self_attention_  (None, 128, 128)             65536     ['layer_normalization_86[0][0]\n",
      " 51 (MultiHeadSelfAttention                                         ']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)       (None, 128, 128)             0         ['multi_head_self_attention_51\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " add_85 (Add)                (None, 128, 128)             0         ['add_84[0][0]',              \n",
      "                                                                     'dropout_122[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_87 (La  (None, 128, 128)             256       ['add_85[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_174 (Dense)           (None, 128, 512)             65536     ['layer_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_175 (Dense)           (None, 128, 128)             65536     ['dense_174[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)       (None, 128, 128)             0         ['dense_175[0][0]']           \n",
      "                                                                                                  \n",
      " add_86 (Add)                (None, 128, 128)             0         ['add_85[0][0]',              \n",
      "                                                                     'dropout_123[0][0]']         \n",
      "                                                                                                  \n",
      " classifier (Dense)          (None, 128, 60)              7740      ['add_86[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1198268 (4.57 MB)\n",
      "Trainable params: 1198268 (4.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inp[T] --> out[1], where K is hyperparameter that means how much inputs we wanna mask\n",
    "def get_model(num_blocks):\n",
    "\n",
    "    inp = tf.keras.Input(INPUT_SHAPE, name=\"ctc_masked_out\")\n",
    "\n",
    "    char_embedding = tf.keras.layers.Embedding(\n",
    "        N_UNIQUE_CHARACTERS, EMBED_DIM, name=\"char_embedding\"\n",
    "    )(inp)\n",
    "\n",
    "    position_embedding = position_embeddings = tf.keras.layers.Embedding(\n",
    "        input_dim=MAX_PHRASE_LENGTH,\n",
    "        output_dim=EMBED_DIM,\n",
    "        weights=[get_pos_encoding_matrix(MAX_PHRASE_LENGTH, EMBED_DIM)],\n",
    "        name=\"position_embedding\",\n",
    "    )(tf.range(start=0, limit=MAX_PHRASE_LENGTH, delta=1))\n",
    "    \n",
    "    x = char_embedding + position_embedding #tf.keras.layers.Add()([char_embedding, position_embedding])\n",
    "    for _ in range(num_blocks):\n",
    "        x = TransformerBlock(dim=EMBED_DIM)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(N_UNIQUE_CHARACTERS-1, name=\"classifier\", activation=\"softmax\")(x)# -1 since we don't wanna predict mask token\n",
    "\n",
    "    outputs = x\n",
    "    \n",
    "    model = tf.keras.Model(inp, outputs)\n",
    "\n",
    "    loss = scce_with_ls\n",
    "\n",
    "    optimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4)\n",
    "    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model(6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e93e09-fa2c-422a-8526-df02f143426a",
   "metadata": {},
   "source": [
    "## сначала восстанавливать те, в которых не уверен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b8ee5143-f07a-4b87-849e-74bd1bb99afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(out):\n",
    "    answer = [num_to_char[x] if x in num_to_char else '' for x in out]\n",
    "    return ''.join(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9721e25e-a114-418e-b702-4a4e6a62aee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 creekhouse'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8204da82-8934-4cdf-a967-52ccdb8e5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.copy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "126cd659-86dd-420d-a1f3-22f9d05d07a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18,  0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 60, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59], dtype=int8),\n",
       " array([18,  0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
       "        59, 59, 59, 59, 59, 59, 59, 59, 59], dtype=int8))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    curr = data[i]\n",
    "    length = len(curr[curr<PAD_TOKEN])\n",
    "    idx = np.random.randint(0, length)\n",
    "    data[i, idx] = MASK_TOKEN\n",
    "data[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4db8bfbc-9e18-4844-b74e-d3914524c932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55759, 128), (6196, 128))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8c8dd7c9-94c3-4bcd-aaec-35b3a48e79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(1000)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# We have 25000 examples for testing\n",
    "test_classifier_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(\n",
    "    BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "af7044c6-7dba-4172-9e7a-78d57860b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 20/872 [..............................] - ETA: 8:13 - loss: 4.0918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_classifier_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_classifier_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_classifier_ds, validation_data=test_classifier_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "21175f83-a631-4224-ac06-d5f23b2cfcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 128), dtype=int8, numpy=\n",
       " array([[20, 17, 19, ..., 59, 59, 59],\n",
       "        [44, 36, 51, ..., 59, 59, 59],\n",
       "        [54, 54, 54, ..., 59, 59, 59],\n",
       "        ...,\n",
       "        [20, 24, 15, ..., 59, 59, 59],\n",
       "        [49, 38, 12, ..., 59, 59, 59],\n",
       "        [17, 21, 20, ..., 59, 59, 59]], dtype=int8)>,\n",
       " <tf.Tensor: shape=(64,), dtype=int8, numpy=\n",
       " array([ 0, 44, 51, 18, 34, 43, 36, 47, 45,  0, 46, 46, 15, 49, 51, 33, 46,\n",
       "        43, 23, 12, 51, 40, 44, 23, 52, 32, 23, 20, 50, 21, 14, 54, 44, 21,\n",
       "        19, 49, 50, 20, 51, 38, 21, 46, 15, 49, 17, 34, 12, 36, 14, 50, 36,\n",
       "        12, 21, 49, 46, 23, 49, 21, 19, 54, 22, 50, 35,  0], dtype=int8)>)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_classifier_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38718a67-bbb3-44d5-aceb-6efe81cfb29f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
