{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "77447172-73ab-438c-9352-b6a9c7fa9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "aad240ac-d0f5-4c0d-b0a8-de66cf723664",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 32, 60)\n",
    "conv = nn.Conv1d(32, 64, 2, stride=1, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8baae50b-1914-4e4d-8349-6dc47bb3ec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 60])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(torch.from_numpy(x).float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39785c87-32ad-4f42-acfa-37bd8dd937ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 0\n",
    "for x in conv.parameters():\n",
    "    curr = 1\n",
    "    for y in x.shape:\n",
    "        curr *= y\n",
    "        \n",
    "    params += curr\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "008d0085-8411-4320-859b-63ae9a3a58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 60, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5d2f11da-67fc-4aff-b25a-081d18460cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 30, 64])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Conv1D(64, 2, 2)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3b7eb319-551e-4f0a-82fb-ed00d53fd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchMyMultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "            embed_dim,\n",
    "            out_dim,\n",
    "            qk_dim,\n",
    "            v_dim,\n",
    "            num_head,\n",
    "            kernel_size=2,\n",
    "            stride=2\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_head  = num_head\n",
    "        self.qk_dim = qk_dim\n",
    "        self.v_dim  = v_dim\n",
    "\n",
    "        self.q = nn.Conv1d(embed_dim, qk_dim*num_head,kernel_size, stride)\n",
    "        self.k = nn.Conv1d(embed_dim, qk_dim*num_head,kernel_size, stride) # stride=2 for token reduction, kernel>1 for mixing\n",
    "        self.v = nn.Conv1d(embed_dim, v_dim*num_head,kernel_size, stride)\n",
    "\n",
    "        self.out = nn.Conv1d(v_dim*num_head//kernel_size, out_dim, 1)\n",
    "        self.scale = 1/(qk_dim**0.5)\n",
    "\n",
    "    #https://github.com/pytorch/pytorch/issues/40497\n",
    "    def forward(self, x):\n",
    "        B,dim,L= x.shape\n",
    "\n",
    "        num_head = self.num_head\n",
    "        qk_dim = self.qk_dim\n",
    "        v_dim = self.v_dim\n",
    "\n",
    "        q = self.q(x) #B,qk_dim,L\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        # B, N, L, Q\n",
    "        q = q.reshape(B, num_head, qk_dim//self.kernel_size, L).permute(0,1,3,2).contiguous()\n",
    "        k = k.reshape(B, num_head, qk_dim//self.kernel_size, L)#.permute(0,1,2,3).contiguous()\n",
    "        v = v.reshape(B, num_head, v_dim//self.kernel_size,  L).permute(0,1,3,2).contiguous()\n",
    "\n",
    "        dot = torch.matmul(q, k) * self.scale  # H L L\n",
    "        attn = F.softmax(dot, -1)    # L L\n",
    "        print(attn.shape, v.shape)\n",
    "        v = torch.matmul(attn, v)  # L H dim\n",
    "        v = v.permute(0,1,3,2).reshape(B, v_dim*num_head//self.kernel_size,L).contiguous()\n",
    "        print(v.shape)\n",
    "        out = self.out(v)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "363a24da-c4d7-44bf-afd9-bf628fa0548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, out_dim, qk_dim, v_dim, num_head, kernel_size=2, stride=2):\n",
    "        super(MyMultiHeadAttention, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_head = num_head\n",
    "        self.qk_dim = qk_dim\n",
    "        self.v_dim = v_dim\n",
    "\n",
    "        self.q = tf.keras.layers.Conv1D(qk_dim*num_head, kernel_size, strides=stride)\n",
    "        self.k = tf.keras.layers.Conv1D(qk_dim*num_head, kernel_size, strides=stride)\n",
    "        self.v = tf.keras.layers.Conv1D(v_dim*num_head, kernel_size, strides=stride)\n",
    "\n",
    "        self.out = tf.keras.layers.Conv1D(out_dim, 1)\n",
    "        self.scale = 1 / np.sqrt(qk_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, L, dim = x.shape\n",
    "\n",
    "        num_head = self.num_head\n",
    "        qk_dim = self.qk_dim\n",
    "        v_dim = self.v_dim\n",
    "\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "\n",
    "        print(\"q shape:\", q.shape)\n",
    "        \n",
    "        q = tf.reshape(q, (B, num_head, L, qk_dim // self.kernel_size))\n",
    "        \n",
    "        \n",
    "        k = tf.reshape(k, (B, num_head, qk_dim // self.kernel_size, L))\n",
    "        \n",
    "        v = tf.reshape(v, (B, num_head, L, v_dim // self.kernel_size))\n",
    "        \n",
    "        dot = tf.matmul(q, k) * self.scale # H Q Q\n",
    "        attn = tf.nn.softmax(dot, axis=-1)\n",
    "        print(attn.shape, v.shape)\n",
    "        v = tf.matmul(attn, v)\n",
    "        v = tf.transpose(v, perm=(0, 2, 1, 3))\n",
    "        v = tf.reshape(v, (B, L, v_dim*num_head//self.kernel_size))\n",
    "        print(v.shape)\n",
    "        out = self.out(v)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2fb3d32e-7ecc-4c29-9d57-5dd58de80d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 512\n",
    "out_dim   = 512\n",
    "qk_dim    = 512//4#for one head\n",
    "v_dim     = 512//4\n",
    "num_head  = 4\n",
    "max_length = 96\n",
    "batch_size = 4\n",
    "\n",
    "mha = MyMultiHeadAttention(\n",
    "    embed_dim,\n",
    "    out_dim,\n",
    "    qk_dim,\n",
    "    v_dim,\n",
    "    num_head,\n",
    "    kernel_size=2,\n",
    "    stride=2\n",
    ")\n",
    "x  = np.random.uniform(-1,1,(batch_size, max_length, embed_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3fdc2962-ff7a-49b4-8f3e-ca7e64f7dcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q shape: (4, 48, 512)\n",
      "(4, 4, 96, 96) (4, 4, 96, 64)\n",
      "(4, 96, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 96, 512]), (4, 96, 512))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mha = mha(x)\n",
    "tf_mha.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "87d2ce1e-0d35-4d14-81bb-8583a356459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmha = TorchMyMultiHeadAttention(\n",
    "    embed_dim,\n",
    "    out_dim,\n",
    "    qk_dim,\n",
    "    v_dim,\n",
    "    num_head,\n",
    "    kernel_size=1,\n",
    "    stride=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cffef5c2-56b2-480a-9dd2-94c75a188a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 96, 96]) torch.Size([4, 4, 96, 128])\n",
      "torch.Size([4, 512, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 96])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mha = tmha(torch.from_numpy(x.reshape(4, 512, 96)).float())\n",
    "t_mha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1eea011e-ec76-496d-9b64-70124b850188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 96])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "78b2600c-7276-4313-a077-242df5a53f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 96, 512])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cee745ea-7454-4ce2-b7c2-1790426c41d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.80867741e-02,  2.98190303e-02,  2.72386409e-02, ...,\n",
       "          2.99011786e-02,  2.98229046e-02,  2.96823550e-02],\n",
       "        [ 3.80886160e-02,  4.00520228e-02,  3.79090272e-02, ...,\n",
       "          3.76826152e-02,  3.85475196e-02,  3.96766551e-02],\n",
       "        [-7.68204685e-03, -8.99784546e-03, -9.86262318e-03, ...,\n",
       "         -1.00490991e-02, -8.41784570e-03, -1.12638930e-02],\n",
       "        ...,\n",
       "        [-3.00749671e-02, -2.66081281e-02, -2.96260230e-02, ...,\n",
       "         -2.78310794e-02, -3.06129511e-02, -2.95400303e-02],\n",
       "        [ 6.34287521e-02,  6.58256114e-02,  6.29289597e-02, ...,\n",
       "          6.65333048e-02,  6.73640817e-02,  6.86542392e-02],\n",
       "        [ 3.19390371e-03,  3.80220124e-03,  1.92262977e-03, ...,\n",
       "          5.13247959e-03,  3.90551286e-03,  3.53754871e-03]],\n",
       "\n",
       "       [[-2.07740813e-05, -2.30960920e-03, -2.21466459e-03, ...,\n",
       "          3.02448869e-04, -2.20946968e-05, -2.13022530e-03],\n",
       "        [ 2.29673237e-02,  1.92526672e-02,  2.05304157e-02, ...,\n",
       "          2.08583903e-02,  2.04178561e-02,  1.95130091e-02],\n",
       "        [-3.84626165e-02, -4.06462178e-02, -4.08793911e-02, ...,\n",
       "         -3.89438048e-02, -3.93501446e-02, -3.72568220e-02],\n",
       "        ...,\n",
       "        [-6.55885115e-02, -6.62802309e-02, -7.07426369e-02, ...,\n",
       "         -6.90728724e-02, -6.66460320e-02, -6.55530691e-02],\n",
       "        [ 5.90392090e-02,  5.96697666e-02,  6.08296543e-02, ...,\n",
       "          5.86308576e-02,  5.87026626e-02,  5.86681813e-02],\n",
       "        [-4.63275984e-02, -5.07042147e-02, -4.97036427e-02, ...,\n",
       "         -4.93276305e-02, -5.01855575e-02, -4.87510785e-02]],\n",
       "\n",
       "       [[ 5.87398931e-02,  5.81612214e-02,  5.81454709e-02, ...,\n",
       "          6.15990236e-02,  5.96780069e-02,  6.05966561e-02],\n",
       "        [-2.27333233e-02, -2.08286885e-02, -1.83016304e-02, ...,\n",
       "         -2.07475871e-02, -2.18461938e-02, -2.21574120e-02],\n",
       "        [-5.34209237e-02, -4.91351634e-02, -5.05757593e-02, ...,\n",
       "         -5.03594503e-02, -4.90253195e-02, -4.83535677e-02],\n",
       "        ...,\n",
       "        [-3.22613344e-02, -3.60554419e-02, -3.17035355e-02, ...,\n",
       "         -3.22207808e-02, -3.32549587e-02, -3.51686291e-02],\n",
       "        [ 8.34528655e-02,  8.53287727e-02,  8.67101923e-02, ...,\n",
       "          8.23767930e-02,  8.81429464e-02,  8.46344605e-02],\n",
       "        [-1.99327134e-02, -2.01515611e-02, -2.09091045e-02, ...,\n",
       "         -2.08511632e-02, -2.23293994e-02, -2.11258326e-02]],\n",
       "\n",
       "       [[ 4.03655954e-02,  3.79247293e-02,  4.01291475e-02, ...,\n",
       "          4.09387723e-02,  3.94456238e-02,  4.27301005e-02],\n",
       "        [ 7.91985262e-03,  6.67138072e-03,  1.03848707e-02, ...,\n",
       "          6.06751442e-03,  8.78063217e-03,  6.14834111e-03],\n",
       "        [-2.16768570e-02, -2.46250518e-02, -2.33374685e-02, ...,\n",
       "         -2.27443222e-02, -2.33358331e-02, -2.08560675e-02],\n",
       "        ...,\n",
       "        [-2.42110062e-02, -2.42847335e-02, -2.50369292e-02, ...,\n",
       "         -2.51231287e-02, -2.53204349e-02, -2.90685073e-02],\n",
       "        [ 9.57960188e-02,  9.25370008e-02,  9.96035784e-02, ...,\n",
       "          9.72162932e-02,  9.61006433e-02,  9.74549130e-02],\n",
       "        [-1.71188060e-02, -1.67418309e-02, -1.59754828e-02, ...,\n",
       "         -1.53573025e-02, -1.46011468e-02, -1.59201734e-02]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mha.detach().numpy().reshape(4, 512, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "122ec6d3-4404-422c-aba2-e818e49d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECA(tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n",
    "        nn = tf.expand_dims(nn, -1)\n",
    "        nn = self.conv(nn)\n",
    "        nn = tf.squeeze(nn, -1)\n",
    "        nn = tf.nn.sigmoid(nn)\n",
    "        nn = nn[:,None,:]\n",
    "        return inputs * nn\n",
    "\n",
    "class CausalDWConv1D(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        name='', **kwargs):\n",
    "        super().__init__(name=name,**kwargs)\n",
    "        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n",
    "                            kernel_size,\n",
    "                            strides=1,\n",
    "                            dilation_rate=dilation_rate,\n",
    "                            padding='valid',\n",
    "                            use_bias=use_bias,\n",
    "                            depthwise_initializer=depthwise_initializer,\n",
    "                            name=name + '_dwconv')\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.causal_pad(inputs)\n",
    "        x = self.dw_conv(x)\n",
    "        return x\n",
    "\n",
    "def Conv1DBlock(channel_size,\n",
    "          kernel_size,\n",
    "          dilation_rate=1,\n",
    "          drop_rate=0.0,\n",
    "          expand_ratio=2,\n",
    "          se_ratio=0.25,\n",
    "          activation='swish',\n",
    "          name=None):\n",
    "    '''\n",
    "    efficient conv1d block, @hoyso48\n",
    "    '''\n",
    "    if name is None:\n",
    "        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n",
    "    # Expansion phase\n",
    "    def apply(inputs):\n",
    "        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n",
    "        channels_expand = channels_in * expand_ratio\n",
    "\n",
    "        skip = inputs\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channels_expand,\n",
    "            use_bias=True,\n",
    "            activation=activation,\n",
    "            name=name + '_expand_conv')(inputs)\n",
    "\n",
    "        # Depthwise Convolution\n",
    "        x = CausalDWConv1D(kernel_size,\n",
    "            dilation_rate=dilation_rate,\n",
    "            use_bias=False,\n",
    "            name=name + '_dwconv')(x)\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n",
    "\n",
    "        x  = ECA()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(\n",
    "            channel_size,\n",
    "            use_bias=True,\n",
    "            name=name + '_project_conv')(x)\n",
    "\n",
    "        if drop_rate > 0:\n",
    "            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n",
    "\n",
    "        if (channels_in == channel_size):\n",
    "            x = tf.keras.layers.add([x, skip], name=name + '_add')\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "059fb60b-af41-448a-b7d1-25d28f9bbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(4, 128, 384)\n",
    "conv = Conv1DBlock(10, kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b7bc1522-f831-45b5-b6b3-130bbefd1248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 128, 10])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2ce9d947-46e9-44d7-ad84-b69e8b3e166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 121, 10])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Conv1D(10, 8)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "00fb1c11-3dfc-4ff7-94e8-23ad3e92b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, out_dim, num_heads, kernel_size=17):\n",
    "        super(MyMultiHeadAttention, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.qk_dim = embed_dim // num_heads\n",
    "        self.v_dim = embed_dim // num_heads\n",
    "\n",
    "        assert (self.qk_dim * num_heads == embed_dim), \"num_heads should be divisible by embed_dim\"\n",
    "        assert (self.v_dim * num_heads == embed_dim), \"num_heads should be divisible by embed_dim\"\n",
    "\n",
    "        self.q = Conv1DBlock(qk_dim*num_head, kernel_size=kernel_size)\n",
    "        self.k = Conv1DBlock(qk_dim*num_head, kernel_size=kernel_size)\n",
    "        self.v = Conv1DBlock(v_dim*num_head, kernel_size=kernel_size)\n",
    "\n",
    "        self.out = tf.keras.layers.Conv1D(out_dim, 1)\n",
    "        self.scale = 1 / np.sqrt(qk_dim)\n",
    "\n",
    "        self.drop = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, L, dim = x.shape\n",
    "\n",
    "        num_heads = self.num_heads\n",
    "        qk_dim = self.qk_dim\n",
    "        v_dim = self.v_dim\n",
    "\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "\n",
    "#        print(\"q shape:\", q.shape)\n",
    "        \n",
    "        q = tf.reshape(q, (B, num_heads, L, qk_dim))\n",
    "        \n",
    "        \n",
    "        k = tf.reshape(k, (B, num_heads, qk_dim, L))\n",
    "        \n",
    "        v = tf.reshape(v, (B, num_heads, L, v_dim))\n",
    "        \n",
    "        dot = tf.matmul(q, k) * self.scale # H Q Q\n",
    "        attn = tf.nn.softmax(dot, axis=-1)\n",
    "        print(attn.shape, v.shape)\n",
    "        v = tf.matmul(attn, v)\n",
    "        v = tf.transpose(v, perm=(0, 2, 1, 3))\n",
    "        v = tf.reshape(v, (B, L, v_dim*num_heads))\n",
    "#        print(v.shape)\n",
    "        out = self.out(v)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e23aa396-bd5a-4677-8ab2-e1073358a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 128, 128) (4, 4, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 128, 384]), (4, 128, 384))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MyMultiHeadAttention(embed_dim, 384, num_head)\n",
    "out = mha(x)\n",
    "out.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "eec97136-5c26-4c09-a519-91844dd1aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TransformerBlock(embed_dim=512, dim=256, num_heads=4, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n",
    "    def apply(inputs):\n",
    "        x = inputs\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = MyMultiHeadAttention(embed_dim, out_dim=dim, num_heads=num_heads)(x) # add attentioin dropout \n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([inputs, x])\n",
    "        attn_out = x\n",
    "\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n",
    "        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n",
    "        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n",
    "        x = tf.keras.layers.Add()([attn_out, x])\n",
    "        return x\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6a7b3fe4-753a-41c1-9798-23e508b72a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 128, 128) (4, 4, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 128, 384]), (4, 128, 384))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TransformerBlock(dim=384)\n",
    "out = transformer(x)\n",
    "out.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a1c630ab-7fac-43f8-86a1-c102c5095135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.reshape(tf.range(12), (3,4))\n",
    "\n",
    "p, q, r = tf.unstack(x)\n",
    "p.shape.as_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "87ce3ecd-bff6-4f5f-aae9-6205853e6ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e03329ee-fe38-47a6-9646-f8c8e4bdae68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 5, 6, 7], dtype=int32)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9e88e769-a8df-4b1b-aa2b-6100e207a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 8,  9, 10, 11], dtype=int32)>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "75f20f47-6cb7-4886-9eea-b66070b9156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 5, 6, 7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 8,  9, 10, 11], dtype=int32)>)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, q, r = x\n",
    "p, q, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "91b2d668-65d0-481a-a56c-3a783ee2eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, j, k, l = tf.unstack(x, axis=1)\n",
    "i.shape.as_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c8470d45-4397-47a6-9f6c-623d6b79ccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 4, 8], dtype=int32)>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8fe224fd-410b-4f7e-8a5c-d4f74e4f4f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create your 2D and 1D arrays\n",
    "array_2d = np.array([[1, 2, 0],\n",
    "                     [1, 0, 1],\n",
    "                     [2, 2, 0]])\n",
    "array_1d = np.array([2, 0, 1])\n",
    "\n",
    "# Use advanced indexing to directly assign values in array_2d\n",
    "# array_2d[np.arange(len(array_1d)), array_1d] = -5\n",
    "\n",
    "# print(array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9e083b22-2fb7-4ce8-828c-d840479666a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d[np.arange(len(array_1d)), array_1d] = np.array([4, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a98a-45f9-4dbf-9a4e-6fe28723c9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
