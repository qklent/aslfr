{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import sklearn\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import Levenshtein\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share embedding for input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_folder = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ordinal Encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>~</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ordinal Encoding\n",
       "                  0\n",
       "!                 1\n",
       "#                 2\n",
       "$                 3\n",
       "%                 4\n",
       "&                 5\n",
       "'                 6\n",
       "(                 7\n",
       ")                 8\n",
       "*                 9\n",
       "+                10\n",
       ",                11\n",
       "-                12\n",
       ".                13\n",
       "/                14\n",
       "0                15\n",
       "1                16\n",
       "2                17\n",
       "3                18\n",
       "4                19\n",
       "5                20\n",
       "6                21\n",
       "7                22\n",
       "8                23\n",
       "9                24\n",
       ":                25\n",
       ";                26\n",
       "=                27\n",
       "?                28\n",
       "@                29\n",
       "[                30\n",
       "_                31\n",
       "a                32\n",
       "b                33\n",
       "c                34\n",
       "d                35\n",
       "e                36\n",
       "f                37\n",
       "g                38\n",
       "h                39\n",
       "i                40\n",
       "j                41\n",
       "k                42\n",
       "l                43\n",
       "m                44\n",
       "n                45\n",
       "o                46\n",
       "p                47\n",
       "q                48\n",
       "r                49\n",
       "s                50\n",
       "t                51\n",
       "u                52\n",
       "v                53\n",
       "w                54\n",
       "x                55\n",
       "y                56\n",
       "z                57\n",
       "~                58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_to_data_folder + \"/character_to_prediction_index.json\") as json_file:\n",
    "    CHAR2ORD = json.load(json_file)\n",
    "    \n",
    "ORD2CHAR = {j:i for i,j in CHAR2ORD.items()}\n",
    "    \n",
    "display(pd.Series(CHAR2ORD).to_frame('Ordinal Encoding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "SEED = 42\n",
    "DEBUG = True\n",
    "N_UNIQUE_CHARACTERS = len(CHAR2ORD) + 1 + 1 + 1 + 1#\n",
    "PAD_TOKEN = len(CHAR2ORD) # Padding\n",
    "SOS_TOKEN = len(CHAR2ORD) + 1 # Start Of Sentence\n",
    "EOS_TOKEN = len(CHAR2ORD) + 2 # End Of Sentence\n",
    "NAN_TOKEN = len(CHAR2ORD) + 3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20 #if IS_INTERACTIVE else 100\n",
    "NUM_WARMUP_EPOCHS = 10\n",
    "WEIGHT_DECAY = 0.05\n",
    "NUM_WORKERS = 2\n",
    "TRAIN_MODEL = True\n",
    "LOAD_WEIGHTS = False\n",
    "MAX_LR = 1e-3\n",
    "WARMUP_METHOD = 'exp'\n",
    "USE_VAL = True\n",
    "N_TARGET_FRAMES = 128\n",
    "N_COLS = 164\n",
    "MAX_PHRASE_LENGTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc44830fdb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORD2CHAR[PAD_TOKEN] = \"<PAD>\"\n",
    "ORD2CHAR[SOS_TOKEN] = \"<SOS>\"\n",
    "ORD2CHAR[EOS_TOKEN] = \"<EOS>\"\n",
    "ORD2CHAR[NAN_TOKEN] = \"<NAN>\"\n",
    "CHAR2ORD[\"<PAD>\"] = PAD_TOKEN\n",
    "CHAR2ORD[\"<SOS>\"] = SOS_TOKEN\n",
    "CHAR2ORD[\"<EOS>\"] = EOS_TOKEN\n",
    "CHAR2ORD[\"<NAN>\"] = NAN_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/asl-fingerspelling/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read Train DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m----> 3\u001b[0m     train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/asl-fingerspelling/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/asl-fingerspelling/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/asl-fingerspelling/train.csv'"
     ]
    }
   ],
   "source": [
    "# # Read Train DataFrame\n",
    "# if DEBUG:\n",
    "#     train = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv').head(5000)\n",
    "# else:\n",
    "#     train = pd.read_csv('/kaggle/input/asl-fingerspelling/train.csv')\n",
    "    \n",
    "# # Set Train Indexed By sqeuence_id\n",
    "# train_sequence_id = train.set_index('sequence_id')\n",
    "\n",
    "# # Number Of Train Samples\n",
    "# N_SAMPLES = len(train)\n",
    "# print(f'N_SAMPLES: {N_SAMPLES}')\n",
    "\n",
    "# display(train.info())\n",
    "# display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:21:46.518942Z",
     "iopub.status.busy": "2023-08-12T17:21:46.518549Z",
     "iopub.status.idle": "2023-08-12T17:21:46.526862Z",
     "shell.execute_reply": "2023-08-12T17:21:46.525198Z",
     "shell.execute_reply.started": "2023-08-12T17:21:46.518907Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_file_path(path):\n",
    "#     return f'/kaggle/input/asl-fingerspelling/{path}'\n",
    "\n",
    "# train['file_path'] = train['path'].apply(get_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:21:46.651234Z",
     "iopub.status.busy": "2023-08-12T17:21:46.649800Z",
     "iopub.status.idle": "2023-08-12T17:21:46.668304Z",
     "shell.execute_reply": "2023-08-12T17:21:46.667457Z",
     "shell.execute_reply.started": "2023-08-12T17:21:46.651197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 Inference Pickle Files\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE_FILE_PATHS = pd.Series(\n",
    "#         glob.glob('/kaggle/input/aslfr-preprocessing-dataset/train_landmark_subsets/*')\n",
    "#     )\n",
    "\n",
    "# print(f'Found {len(INFERENCE_FILE_PATHS)} Inference Pickle Files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (54719, 128, 164), X_val shape: (7236, 128, 164)\n"
     ]
    }
   ],
   "source": [
    "if USE_VAL:\n",
    "    # TRAIN\n",
    "    X_train = np.load(path_to_data_folder + '/X_train.npy')\n",
    "    y_train = np.load(path_to_data_folder + '/y_train.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    # VAL\n",
    "    X_val = np.load(path_to_data_folder + '/X_val.npy')\n",
    "    y_val = np.load(path_to_data_folder + '/y_val.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_VAL_SAMPLES = len(X_val)\n",
    "    # Shapes\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "# Train On All Data\n",
    "else:\n",
    "    # TRAIN\n",
    "    X_train = np.load(path_to_data_folder + '/X.npy')\n",
    "    y_train = np.load(path_to_data_folder + '/y.npy')[:,:MAX_PHRASE_LENGTH]\n",
    "    N_TRAIN_SAMPLES = len(X_train)\n",
    "    print(f'X_train shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164,), (164,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.load(path_to_data_folder + \"/MEANS.npy\")\n",
    "std = np.load(path_to_data_folder + \"/STDS.npy\")\n",
    "mean.shape, std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = (X_train[i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    for i in range(len(X_val)):\n",
    "        X_val[i] = (X_val[i] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in X i've right hand, left hand, lips coords(x,y) for i in range(number of frames)\n",
    "\n",
    "and in y i have char for X hands and lips position\n",
    "\n",
    "the main problem is that there are 128 frames and only 31 letters, so i gotta combine some frames that represent the same letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54719, 32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:31.556047Z",
     "iopub.status.busy": "2023-08-12T17:22:31.555602Z",
     "iopub.status.idle": "2023-08-12T17:22:33.061622Z",
     "shell.execute_reply": "2023-08-12T17:22:33.060697Z",
     "shell.execute_reply.started": "2023-08-12T17:22:31.555983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Recording: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_left_hand_0</th>\n",
       "      <th>x_left_hand_1</th>\n",
       "      <th>x_left_hand_2</th>\n",
       "      <th>x_left_hand_3</th>\n",
       "      <th>x_left_hand_4</th>\n",
       "      <th>x_left_hand_5</th>\n",
       "      <th>x_left_hand_6</th>\n",
       "      <th>x_left_hand_7</th>\n",
       "      <th>x_left_hand_8</th>\n",
       "      <th>x_left_hand_9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_face_314</th>\n",
       "      <th>y_face_317</th>\n",
       "      <th>y_face_318</th>\n",
       "      <th>y_face_321</th>\n",
       "      <th>y_face_324</th>\n",
       "      <th>y_face_375</th>\n",
       "      <th>y_face_402</th>\n",
       "      <th>y_face_405</th>\n",
       "      <th>y_face_409</th>\n",
       "      <th>y_face_415</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551424</td>\n",
       "      <td>0.538415</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.546458</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.543958</td>\n",
       "      <td>0.538425</td>\n",
       "      <td>0.549351</td>\n",
       "      <td>0.538230</td>\n",
       "      <td>0.540015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550706</td>\n",
       "      <td>0.538216</td>\n",
       "      <td>0.538723</td>\n",
       "      <td>0.545990</td>\n",
       "      <td>0.539296</td>\n",
       "      <td>0.543357</td>\n",
       "      <td>0.538225</td>\n",
       "      <td>0.548827</td>\n",
       "      <td>0.537376</td>\n",
       "      <td>0.539256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550613</td>\n",
       "      <td>0.537836</td>\n",
       "      <td>0.538564</td>\n",
       "      <td>0.545949</td>\n",
       "      <td>0.539212</td>\n",
       "      <td>0.543279</td>\n",
       "      <td>0.537961</td>\n",
       "      <td>0.548796</td>\n",
       "      <td>0.537360</td>\n",
       "      <td>0.539332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549740</td>\n",
       "      <td>0.536994</td>\n",
       "      <td>0.538449</td>\n",
       "      <td>0.545622</td>\n",
       "      <td>0.539666</td>\n",
       "      <td>0.543694</td>\n",
       "      <td>0.537328</td>\n",
       "      <td>0.548015</td>\n",
       "      <td>0.538301</td>\n",
       "      <td>0.539954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816796431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550614</td>\n",
       "      <td>0.538677</td>\n",
       "      <td>0.540376</td>\n",
       "      <td>0.547104</td>\n",
       "      <td>0.541524</td>\n",
       "      <td>0.545222</td>\n",
       "      <td>0.539203</td>\n",
       "      <td>0.549211</td>\n",
       "      <td>0.539734</td>\n",
       "      <td>0.541707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_left_hand_0  x_left_hand_1  x_left_hand_2  x_left_hand_3  \\\n",
       "sequence_id                                                               \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "\n",
       "             x_left_hand_4  x_left_hand_5  x_left_hand_6  x_left_hand_7  \\\n",
       "sequence_id                                                               \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "1816796431             NaN            NaN            NaN            NaN   \n",
       "\n",
       "             x_left_hand_8  x_left_hand_9  ...  y_face_314  y_face_317  \\\n",
       "sequence_id                                ...                           \n",
       "1816796431             NaN            NaN  ...    0.551424    0.538415   \n",
       "1816796431             NaN            NaN  ...    0.550706    0.538216   \n",
       "1816796431             NaN            NaN  ...    0.550613    0.537836   \n",
       "1816796431             NaN            NaN  ...    0.549740    0.536994   \n",
       "1816796431             NaN            NaN  ...    0.550614    0.538677   \n",
       "\n",
       "             y_face_318  y_face_321  y_face_324  y_face_375  y_face_402  \\\n",
       "sequence_id                                                               \n",
       "1816796431     0.539000    0.546458    0.539715    0.543958    0.538425   \n",
       "1816796431     0.538723    0.545990    0.539296    0.543357    0.538225   \n",
       "1816796431     0.538564    0.545949    0.539212    0.543279    0.537961   \n",
       "1816796431     0.538449    0.545622    0.539666    0.543694    0.537328   \n",
       "1816796431     0.540376    0.547104    0.541524    0.545222    0.539203   \n",
       "\n",
       "             y_face_405  y_face_409  y_face_415  \n",
       "sequence_id                                      \n",
       "1816796431     0.549351    0.538230    0.540015  \n",
       "1816796431     0.548827    0.537376    0.539256  \n",
       "1816796431     0.548796    0.537360    0.539332  \n",
       "1816796431     0.548015    0.538301    0.539954  \n",
       "1816796431     0.549211    0.539734    0.541707  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read First Parquet File\n",
    "# example_parquet_df = pd.read_parquet(train['file_path'][0])\n",
    "example_parquet_df = pd.read_parquet(INFERENCE_FILE_PATHS[0])\n",
    "\n",
    "# Each parquet file contains 1000 recordings\n",
    "print(f'# Unique Recording: {example_parquet_df.index.nunique()}')\n",
    "# Display DataFrame layout\n",
    "display(example_parquet_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.063684Z",
     "iopub.status.busy": "2023-08-12T17:22:33.063315Z",
     "iopub.status.idle": "2023-08-12T17:22:33.071981Z",
     "shell.execute_reply": "2023-08-12T17:22:33.070836Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.063648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get indices in original dataframe\n",
    "def get_idxs(df, words_pos, words_neg=[], ret_names=True, idxs_pos=None):\n",
    "    idxs = []\n",
    "    names = []\n",
    "    for w in words_pos:\n",
    "        for col_idx, col in enumerate(example_parquet_df.columns):\n",
    "            # Exclude Non Landmark Columns\n",
    "            if col in ['frame']:\n",
    "                continue\n",
    "                \n",
    "            col_idx = int(col.split('_')[-1])\n",
    "            # Check if column name contains all words\n",
    "            if (w in col) and (idxs_pos is None or col_idx in idxs_pos) and all([w not in col for w in words_neg]):\n",
    "                idxs.append(col_idx)\n",
    "                names.append(col)\n",
    "    # Convert to Numpy arrays\n",
    "    idxs = np.array(idxs)\n",
    "    names = np.array(names)\n",
    "    # Returns either both column indices and names\n",
    "    if ret_names:\n",
    "        return idxs, names\n",
    "    # Or only columns indices\n",
    "    else:\n",
    "        return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.074387Z",
     "iopub.status.busy": "2023-08-12T17:22:33.073218Z",
     "iopub.status.idle": "2023-08-12T17:22:33.088373Z",
     "shell.execute_reply": "2023-08-12T17:22:33.087366Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.074287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_COLS0: 164\n"
     ]
    }
   ],
   "source": [
    "LIPS_LANDMARK_IDXS = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "\n",
    "# Landmark Indices for Left/Right hand without z axis in raw data\n",
    "LEFT_HAND_IDXS0, LEFT_HAND_NAMES0 = get_idxs(example_parquet_df, ['left_hand'], ['z'])\n",
    "RIGHT_HAND_IDXS0, RIGHT_HAND_NAMES0 = get_idxs(example_parquet_df, ['right_hand'], ['z'])\n",
    "LIPS_IDXS0, LIPS_NAMES0 = get_idxs(example_parquet_df, ['face'], ['z'], idxs_pos=LIPS_LANDMARK_IDXS)\n",
    "COLUMNS0 = np.concatenate((LEFT_HAND_NAMES0, RIGHT_HAND_NAMES0, LIPS_NAMES0))\n",
    "N_COLS0 = len(COLUMNS0)\n",
    "# Only X/Y axes are used\n",
    "N_DIMS0 = 2\n",
    "\n",
    "print(f'N_COLS0: {N_COLS0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.108516Z",
     "iopub.status.busy": "2023-08-12T17:22:33.107839Z",
     "iopub.status.idle": "2023-08-12T17:22:33.116589Z",
     "shell.execute_reply": "2023-08-12T17:22:33.115943Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.108490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_COLS: 164\n"
     ]
    }
   ],
   "source": [
    "LEFT_HAND_IDXS = np.argwhere(np.isin(COLUMNS0, LEFT_HAND_NAMES0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(COLUMNS0, RIGHT_HAND_NAMES0)).squeeze()\n",
    "LIPS_IDXS = np.argwhere(np.isin(COLUMNS0, LIPS_NAMES0)).squeeze()\n",
    "HAND_IDXS = np.concatenate((LEFT_HAND_IDXS, RIGHT_HAND_IDXS), axis=0)\n",
    "N_COLS = N_COLS0\n",
    "# Only X/Y axes are used\n",
    "N_DIMS = 2\n",
    "\n",
    "print(f'N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.118494Z",
     "iopub.status.busy": "2023-08-12T17:22:33.117697Z",
     "iopub.status.idle": "2023-08-12T17:22:33.127444Z",
     "shell.execute_reply": "2023-08-12T17:22:33.126804Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.118461Z"
    }
   },
   "outputs": [],
   "source": [
    "HAND_X_IDXS = np.array(\n",
    "        [idx for idx, name in enumerate(LEFT_HAND_NAMES0) if 'x' in name]\n",
    "    ).squeeze()\n",
    "HAND_Y_IDXS = np.array(\n",
    "        [idx for idx, name in enumerate(LEFT_HAND_NAMES0) if 'y' in name]\n",
    "    ).squeeze()\n",
    "# Names in processed data by axes\n",
    "HAND_X_NAMES = LEFT_HAND_NAMES0[HAND_X_IDXS]\n",
    "HAND_Y_NAMES = LEFT_HAND_NAMES0[HAND_Y_IDXS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mmean\u001b[49m)\n\u001b[1;32m      2\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(std)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "mean = torch.from_numpy(mean)\n",
    "std = torch.from_numpy(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignRecognition(nn.Module):\n",
    "    def __init__(self, frames, kernel_size=2, stride=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(frames, frames // 4, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(frames // 4)\n",
    "        self.lin1 = nn.Linear(41, 128)\n",
    "        self.lin2 = nn.Linear(128, N_UNIQUE_CHARACTERS)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 128 41 1\n",
    "        x = self.gelu(self.bn1(x))\n",
    "        x = x.squeeze(dim=-1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        \n",
    "        assert (self.head_dim * heads == embed_size), \"Embed size needs to be divisible by heads\"\n",
    "        self.values = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.keys = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(embed_size, embed_size, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size) # concat them\n",
    "        \n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "        \n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(query)\n",
    "        \n",
    "        # split embedding into self.heads pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
    "        \n",
    "        # energy shape: (N, heads, query_len, key_len) table with attention on\n",
    "        # each word from target to input\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "            \n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)\n",
    "        # since value_len == key_len i use l for both\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads*self.head_dim,\n",
    "        ) # flatten last 2 dimensions\n",
    "        \n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "        \n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            scr_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "       # self.word_embedding = nn.Embedding(scr_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(embed_size, heads, dropout, forward_expansion)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )    \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length, vocab = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(device)\n",
    "        \n",
    "        out = self.dropout(x + self.position_embedding(positions))\n",
    "        # x B, Seq_len, vocab_size\n",
    "        # pos B, Seq_len, n_embd\n",
    "        for layer in self.layers:\n",
    "            # since we are in encoder and values, queries and keys are the same\n",
    "            out = layer(out, out, out, mask)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.transformer_block = TransformerBlock(\n",
    "            embed_size, heads, dropout, forward_expansion\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    # valule and key are from encoder\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            trg_vocab_size,\n",
    "            embed_size, \n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "        \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "        \n",
    "        out = self.fc_out(x) \n",
    "        return out\n",
    "        \n",
    "        \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            scr_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            src_pad_idx,\n",
    "            trg_pad_idx,\n",
    "            embed_size=63,\n",
    "            num_layers=6,\n",
    "            forward_expansion=4,\n",
    "            heads=9,\n",
    "            dropout=0,\n",
    "            device=\"cuda\",\n",
    "            max_length=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            scr_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length\n",
    "        )\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length\n",
    "        )\n",
    "        \n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        # (N, 1, 1, src_length)\n",
    "        # src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # return src_mask.to(self.device)\n",
    "        return None\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        N, trg_length = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_length, trg_length))).expand(\n",
    "            N, 1, trg_length, trg_length\n",
    "        )\n",
    "        return trg_mask.to(self.device)\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mtrain\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mtrain\u001b[49m, pd\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mframe\u001b[38;5;241m.\u001b[39mDataFrame)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "isinstance(train, pd.core.frame.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PreprocessLayer, self).__init__()\n",
    "        \n",
    "        self.normalisation_correction = torch.tensor(\n",
    "            [0.50 if 'x' in name else 0.00 for name in LEFT_HAND_NAMES0],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        \n",
    "    def forward(self, data0, resize=True):\n",
    "        # Fill NaN Values With 0\n",
    "        if isinstance(data0, pd.core.frame.DataFrame):\n",
    "            data0 = torch.tensor(data0.values)\n",
    "        data = torch.where(torch.isnan(data0), torch.tensor(0.0), data0)\n",
    "        \n",
    "        data = data.unsqueeze(0)\n",
    "        \n",
    "        # Empty Hand Frame Filtering\n",
    "        hands = data[:, :, :84]\n",
    "        hands = torch.abs(hands)\n",
    "        mask = torch.sum(hands, dim=2)\n",
    "        mask = mask != 0\n",
    "        data = data[mask]\n",
    "        \n",
    "        # Pad Zeros\n",
    "        N_FRAMES = len(data)\n",
    "        #print(data.shape)\n",
    "        if N_FRAMES < N_TARGET_FRAMES:\n",
    "            data = torch.cat((\n",
    "                data.unsqueeze(0),\n",
    "                torch.zeros(1, N_TARGET_FRAMES - N_FRAMES, N_COLS),\n",
    "            ), dim=1)\n",
    "\n",
    "        # Downsample\n",
    "        if len(data.shape) == 2:\n",
    "            data = data.unsqueeze(0)\n",
    "        resized_data = F.interpolate(\n",
    "            data.unsqueeze(0), \n",
    "            size=(N_TARGET_FRAMES, N_COLS), \n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        resized_data[0] = (resized_data[0] - mean) / std\n",
    "        return resized_data.view(len(resized_data), N_TARGET_FRAMES, N_COLS // 2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def decode(self, out: torch.tensor) -> str:\n",
    "        \"\"\"\n",
    "        decode output of model into text\n",
    "        \"\"\"\n",
    "        text = []\n",
    "        for x in out:\n",
    "            token = x.item()\n",
    "            if token == PAD_TOKEN:\n",
    "                continue # what if pad token will be in the middle of sentence\n",
    "            text.append(ORD2CHAR[token])\n",
    "        return ''.join(text)\n",
    "    \n",
    "    def encode(self, string: str) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        encode string into vocab size space so that i can put it as my target while training\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for symbol in string:\n",
    "            out.append(CHAR2ORD[symbol])\n",
    "        \n",
    "        return torch.tensor(out)        \n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device):\n",
    "        super().__init__()\n",
    "        self.cnn = SignRecognition(128).to(device)\n",
    "        self.transformer = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device)\n",
    "        self.preprocess_layer = PreprocessLayer()\n",
    "\n",
    "    def forward(self, x, decoder_input_ids=None):\n",
    "        self.train()\n",
    "        if decoder_input_ids is not None:\n",
    "            x = self.cnn(x) # [B, T, Vocab_size]\n",
    "            x = self.transformer(x, decoder_input_ids)\n",
    "        else:\n",
    "            x = self.inference(x)\n",
    "    \n",
    "        return x\n",
    "        \n",
    "    def inference(self, x):\n",
    "        self.eval()\n",
    "        x = self.preprocess_layer(x).to(device)\n",
    "#         if len(x.shape) == 3:\n",
    "#             x = x.unsqueeze(0)\n",
    "        #print(x.shape)\n",
    "        trg = torch.full((x.shape[0], 1), SOS_TOKEN, dtype=torch.long).to(device)\n",
    "        for _ in range(MAX_PHRASE_LENGTH):\n",
    "            with torch.no_grad():\n",
    "                out = self(x, trg)[:, -1, :]\n",
    "            token = out.argmax(-1).unsqueeze(-1)\n",
    "            trg = torch.cat((trg, token), -1)\n",
    "            \n",
    "            if (token == EOS_TOKEN).all():\n",
    "                break\n",
    "                \n",
    "        return tokenizer.decode(trg[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.365206Z",
     "iopub.status.busy": "2023-08-12T17:22:33.364549Z",
     "iopub.status.idle": "2023-08-12T17:22:33.486164Z",
     "shell.execute_reply": "2023-08-12T17:22:33.485108Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.365173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_raw_data shape: (122, 164)\n",
      "data shape: torch.Size([1, 128, 82, 2])\n"
     ]
    }
   ],
   "source": [
    "def test_preprocess_layer():\n",
    "    demo_sequence_id = example_parquet_df.index.unique()[19]\n",
    "    demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0]\n",
    "    data = preprocess_layer(demo_raw_data)\n",
    "    print(f'demo_raw_data shape: {demo_raw_data.shape}')\n",
    "    print(f'data shape: {data.shape}')\n",
    "    \n",
    "    return data\n",
    "\n",
    "preprocess_layer = PreprocessLayer()\n",
    "\n",
    "if IS_INTERACTIVE:\n",
    "    data = test_preprocess_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:33.487903Z",
     "iopub.status.busy": "2023-08-12T17:22:33.487483Z",
     "iopub.status.idle": "2023-08-12T17:22:33.520599Z",
     "shell.execute_reply": "2023-08-12T17:22:33.519583Z",
     "shell.execute_reply.started": "2023-08-12T17:22:33.487870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_left_hand_0</th>\n",
       "      <th>x_left_hand_1</th>\n",
       "      <th>x_left_hand_2</th>\n",
       "      <th>x_left_hand_3</th>\n",
       "      <th>x_left_hand_4</th>\n",
       "      <th>x_left_hand_5</th>\n",
       "      <th>x_left_hand_6</th>\n",
       "      <th>x_left_hand_7</th>\n",
       "      <th>x_left_hand_8</th>\n",
       "      <th>x_left_hand_9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_face_314</th>\n",
       "      <th>y_face_317</th>\n",
       "      <th>y_face_318</th>\n",
       "      <th>y_face_321</th>\n",
       "      <th>y_face_324</th>\n",
       "      <th>y_face_375</th>\n",
       "      <th>y_face_402</th>\n",
       "      <th>y_face_405</th>\n",
       "      <th>y_face_409</th>\n",
       "      <th>y_face_415</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536143</td>\n",
       "      <td>0.514210</td>\n",
       "      <td>0.519691</td>\n",
       "      <td>0.531983</td>\n",
       "      <td>0.523121</td>\n",
       "      <td>0.529981</td>\n",
       "      <td>0.516128</td>\n",
       "      <td>0.534680</td>\n",
       "      <td>0.520337</td>\n",
       "      <td>0.522814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535060</td>\n",
       "      <td>0.514881</td>\n",
       "      <td>0.519775</td>\n",
       "      <td>0.531294</td>\n",
       "      <td>0.522798</td>\n",
       "      <td>0.529248</td>\n",
       "      <td>0.516640</td>\n",
       "      <td>0.533826</td>\n",
       "      <td>0.520163</td>\n",
       "      <td>0.522484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534988</td>\n",
       "      <td>0.514349</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.531961</td>\n",
       "      <td>0.522935</td>\n",
       "      <td>0.530020</td>\n",
       "      <td>0.516407</td>\n",
       "      <td>0.534115</td>\n",
       "      <td>0.520159</td>\n",
       "      <td>0.522496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532536</td>\n",
       "      <td>0.511367</td>\n",
       "      <td>0.516521</td>\n",
       "      <td>0.529202</td>\n",
       "      <td>0.519584</td>\n",
       "      <td>0.526958</td>\n",
       "      <td>0.513265</td>\n",
       "      <td>0.531592</td>\n",
       "      <td>0.516477</td>\n",
       "      <td>0.519001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529577</td>\n",
       "      <td>0.507558</td>\n",
       "      <td>0.513263</td>\n",
       "      <td>0.526232</td>\n",
       "      <td>0.516685</td>\n",
       "      <td>0.524348</td>\n",
       "      <td>0.509678</td>\n",
       "      <td>0.528519</td>\n",
       "      <td>0.513844</td>\n",
       "      <td>0.516380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513958</td>\n",
       "      <td>0.493244</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.512223</td>\n",
       "      <td>0.504217</td>\n",
       "      <td>0.511437</td>\n",
       "      <td>0.495716</td>\n",
       "      <td>0.513554</td>\n",
       "      <td>0.502403</td>\n",
       "      <td>0.504038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514730</td>\n",
       "      <td>0.493438</td>\n",
       "      <td>0.500040</td>\n",
       "      <td>0.512429</td>\n",
       "      <td>0.504052</td>\n",
       "      <td>0.511178</td>\n",
       "      <td>0.495896</td>\n",
       "      <td>0.514143</td>\n",
       "      <td>0.502095</td>\n",
       "      <td>0.503897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.493771</td>\n",
       "      <td>0.499412</td>\n",
       "      <td>0.511476</td>\n",
       "      <td>0.503066</td>\n",
       "      <td>0.510184</td>\n",
       "      <td>0.495837</td>\n",
       "      <td>0.513310</td>\n",
       "      <td>0.501498</td>\n",
       "      <td>0.503101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.494097</td>\n",
       "      <td>0.500736</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>0.504525</td>\n",
       "      <td>0.511984</td>\n",
       "      <td>0.496671</td>\n",
       "      <td>0.515876</td>\n",
       "      <td>0.502480</td>\n",
       "      <td>0.504130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817282569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516257</td>\n",
       "      <td>0.495859</td>\n",
       "      <td>0.502002</td>\n",
       "      <td>0.513760</td>\n",
       "      <td>0.505389</td>\n",
       "      <td>0.512121</td>\n",
       "      <td>0.498271</td>\n",
       "      <td>0.515694</td>\n",
       "      <td>0.503123</td>\n",
       "      <td>0.505019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_left_hand_0  x_left_hand_1  x_left_hand_2  x_left_hand_3  \\\n",
       "sequence_id                                                               \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "...                    ...            ...            ...            ...   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "\n",
       "             x_left_hand_4  x_left_hand_5  x_left_hand_6  x_left_hand_7  \\\n",
       "sequence_id                                                               \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "...                    ...            ...            ...            ...   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "1817282569             NaN            NaN            NaN            NaN   \n",
       "\n",
       "             x_left_hand_8  x_left_hand_9  ...  y_face_314  y_face_317  \\\n",
       "sequence_id                                ...                           \n",
       "1817282569             NaN            NaN  ...    0.536143    0.514210   \n",
       "1817282569             NaN            NaN  ...    0.535060    0.514881   \n",
       "1817282569             NaN            NaN  ...    0.534988    0.514349   \n",
       "1817282569             NaN            NaN  ...    0.532536    0.511367   \n",
       "1817282569             NaN            NaN  ...    0.529577    0.507558   \n",
       "...                    ...            ...  ...         ...         ...   \n",
       "1817282569             NaN            NaN  ...    0.513958    0.493244   \n",
       "1817282569             NaN            NaN  ...    0.514730    0.493438   \n",
       "1817282569             NaN            NaN  ...    0.514045    0.493771   \n",
       "1817282569             NaN            NaN  ...    0.516267    0.494097   \n",
       "1817282569             NaN            NaN  ...    0.516257    0.495859   \n",
       "\n",
       "             y_face_318  y_face_321  y_face_324  y_face_375  y_face_402  \\\n",
       "sequence_id                                                               \n",
       "1817282569     0.519691    0.531983    0.523121    0.529981    0.516128   \n",
       "1817282569     0.519775    0.531294    0.522798    0.529248    0.516640   \n",
       "1817282569     0.519791    0.531961    0.522935    0.530020    0.516407   \n",
       "1817282569     0.516521    0.529202    0.519584    0.526958    0.513265   \n",
       "1817282569     0.513263    0.526232    0.516685    0.524348    0.509678   \n",
       "...                 ...         ...         ...         ...         ...   \n",
       "1817282569     0.499994    0.512223    0.504217    0.511437    0.495716   \n",
       "1817282569     0.500040    0.512429    0.504052    0.511178    0.495896   \n",
       "1817282569     0.499412    0.511476    0.503066    0.510184    0.495837   \n",
       "1817282569     0.500736    0.513854    0.504525    0.511984    0.496671   \n",
       "1817282569     0.502002    0.513760    0.505389    0.512121    0.498271   \n",
       "\n",
       "             y_face_405  y_face_409  y_face_415  \n",
       "sequence_id                                      \n",
       "1817282569     0.534680    0.520337    0.522814  \n",
       "1817282569     0.533826    0.520163    0.522484  \n",
       "1817282569     0.534115    0.520159    0.522496  \n",
       "1817282569     0.531592    0.516477    0.519001  \n",
       "1817282569     0.528519    0.513844    0.516380  \n",
       "...                 ...         ...         ...  \n",
       "1817282569     0.513554    0.502403    0.504038  \n",
       "1817282569     0.514143    0.502095    0.503897  \n",
       "1817282569     0.513310    0.501498    0.503101  \n",
       "1817282569     0.515876    0.502480    0.504130  \n",
       "1817282569     0.515694    0.503123    0.505019  \n",
       "\n",
       "[159 rows x 164 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_sequence_id = example_parquet_df.index.unique()[15]\n",
    "demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0]\n",
    "demo_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = PAD_TOKEN\n",
    "trg_pad_idx = PAD_TOKEN\n",
    "src_vocab_size = 63\n",
    "trg_vocab_size = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LEFT_HAND_NAMES0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pad_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_pad_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m model\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn \u001b[38;5;241m=\u001b[39m SignRecognition(\u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_layer \u001b[38;5;241m=\u001b[39m \u001b[43mPreprocessLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mPreprocessLayer.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(PreprocessLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalisation_correction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m----> 6\u001b[0m         [\u001b[38;5;241m0.50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.00\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mLEFT_HAND_NAMES0\u001b[49m],\n\u001b[1;32m      7\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m      8\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LEFT_HAND_NAMES0' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    X_val = torch.from_numpy(X_val)\n",
    "    y_val = torch.from_numpy(y_val).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18,  0, 34, 49, 36, 36, 42, 39, 46, 52, 50, 36, 61, 59, 59, 59, 59, 59,\n",
       "         59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59],\n",
       "        [39, 36, 45, 51, 32, 40, 39, 52, 33, 50, 13, 34, 46, 44, 61, 59, 59, 59,\n",
       "         59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59],\n",
       "        [16, 18, 23, 18,  0, 54, 40, 43, 43, 40, 32, 44,  0, 43, 32, 45, 40, 36,\n",
       "         49, 61, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59],\n",
       "        [24, 23, 23,  0, 37, 49, 32, 45, 42, 43, 40, 45,  0, 43, 32, 45, 36, 61,\n",
       "         59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498]],\n",
       "\n",
       "        [[-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498]],\n",
       "\n",
       "        [[-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498]],\n",
       "\n",
       "        [[-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498],\n",
       "         [-6.4010, -5.8373, -5.1874, -4.6228, -3.9383, -5.5864, -4.9335,\n",
       "          -4.4449, -4.0016, -5.9498]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[4:8, 20:30, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54719, 128, 82, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples, frames, features = X_train.shape\n",
    "X_train = X_train.view(num_examples, frames, features // 2, 2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    num_examples, frames, features = X_val.shape\n",
    "    X_val = X_val.view(num_examples, frames, features // 2, 2)\n",
    "    X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    y_val = y_val.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54719, 32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_ids_train = torch.zeros_like(y_train)\n",
    "decoder_input_ids_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    decoder_input_ids_train[i] = torch.concat((torch.tensor([SOS_TOKEN]), y_train[i][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    decoder_input_ids_val = torch.zeros_like(y_val)\n",
    "    decoder_input_ids_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    for i in range(len(y_val)):\n",
    "        decoder_input_ids_val[i] = torch.concat((torch.tensor([SOS_TOKEN]), y_val[i][:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids_train = decoder_input_ids_train.type(torch.LongTensor)\n",
    "if USE_VAL:\n",
    "    decoder_input_ids_val = decoder_input_ids_val.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.179274Z",
     "iopub.status.busy": "2023-08-12T12:02:00.179015Z",
     "iopub.status.idle": "2023-08-12T12:02:00.185816Z",
     "shell.execute_reply": "2023-08-12T12:02:00.184927Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.179252Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.187697Z",
     "iopub.status.busy": "2023-08-12T12:02:00.187226Z",
     "iopub.status.idle": "2023-08-12T12:02:00.196199Z",
     "shell.execute_reply": "2023-08-12T12:02:00.195359Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.187650Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, decoder_input_ids):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.decoder_input_ids = decoder_input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        decoder_input_ids = self.decoder_input_ids[index]\n",
    "        return x, y, decoder_input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.198063Z",
     "iopub.status.busy": "2023-08-12T12:02:00.197738Z",
     "iopub.status.idle": "2023-08-12T12:02:00.206353Z",
     "shell.execute_reply": "2023-08-12T12:02:00.205386Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.198033Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, decoder_input_ids_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.208303Z",
     "iopub.status.busy": "2023-08-12T12:02:00.207983Z",
     "iopub.status.idle": "2023-08-12T12:02:00.216679Z",
     "shell.execute_reply": "2023-08-12T12:02:00.215285Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.208273Z"
    }
   },
   "outputs": [],
   "source": [
    "if USE_VAL:\n",
    "    val_dataset = CustomDataset(X_val, y_val, decoder_input_ids_val)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.220084Z",
     "iopub.status.busy": "2023-08-12T12:02:00.219787Z",
     "iopub.status.idle": "2023-08-12T12:02:00.229683Z",
     "shell.execute_reply": "2023-08-12T12:02:00.228688Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.220061Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.231799Z",
     "iopub.status.busy": "2023-08-12T12:02:00.231077Z",
     "iopub.status.idle": "2023-08-12T12:02:00.240706Z",
     "shell.execute_reply": "2023-08-12T12:02:00.239882Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.231767Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_target(target: torch.tensor):\n",
    "    answer = []\n",
    "    for x in target:\n",
    "        if x != PAD_TOKEN:\n",
    "            answer.append(ORD2CHAR[x.item()])\n",
    "    return \"\".join(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.242845Z",
     "iopub.status.busy": "2023-08-12T12:02:00.242236Z",
     "iopub.status.idle": "2023-08-12T12:02:00.251014Z",
     "shell.execute_reply": "2023-08-12T12:02:00.250097Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.242813Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric(pred: torch.tensor, target:torch.tensor):\n",
    "    # shouldn't count pad token \n",
    "    # if i would use it in model\n",
    "    # since levenshtein distance is not linear i'll return N and D of each batch and then sum them\n",
    "    D = 0\n",
    "    N = 0\n",
    "    for i in range(len(pred)):# through batches\n",
    "        p = encode(pred[i])\n",
    "        t = encode_target(target[i])\n",
    "        distance = Levenshtein.distance(p, t)\n",
    "        \n",
    "        D += distance\n",
    "        N += len(p) + len(t)\n",
    "    \n",
    "    return N, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.253134Z",
     "iopub.status.busy": "2023-08-12T12:02:00.252471Z",
     "iopub.status.idle": "2023-08-12T12:02:00.260465Z",
     "shell.execute_reply": "2023-08-12T12:02:00.259495Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.253103Z"
    }
   },
   "outputs": [],
   "source": [
    "# # testing metric\n",
    "# for idx, (x, y) in enumerate(train_dataloader):\n",
    "#     out = model(x)\n",
    "#     print(metric(out, y))\n",
    "#     if idx > 5:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train parameters(optimizer, loss, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(100, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qklent/programming/machine_learning/alfa_bank_receipts/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.274225Z",
     "iopub.status.busy": "2023-08-12T12:02:00.273597Z",
     "iopub.status.idle": "2023-08-12T12:02:00.281357Z",
     "shell.execute_reply": "2023-08-12T12:02:00.280431Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.274193Z"
    }
   },
   "outputs": [],
   "source": [
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting on single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 82, 2]), torch.Size([1, 32]), torch.Size([1, 32]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_train[0].unsqueeze(0).to(device)\n",
    "y = y_train[0].unsqueeze(0).to(device)\n",
    "ids = decoder_input_ids_train[0].unsqueeze(0).to(device)\n",
    "x.shape, y.shape, ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(x, ids)\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      4\u001b[0m     loss \u001b[38;5;241m=\u001b[39m l\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    out = model(x, ids)\n",
    "    optimizer.zero_grad()\n",
    "    loss = l\n",
    "    loss = loss_fn(out.view(-1, N_UNIQUE_CHARACTERS), y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(f\"n = {i}, loss = {loss.item()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrfn(curr_epoch, num_cycles=0.50):\n",
    "    \n",
    "    if curr_epoch < NUM_WARMUP_EPOCHS:\n",
    "        if WARMUP_METHOD == 'log':\n",
    "            return MAX_LR * 0.10 ** (NUM_WARMUP_EPOCHS - curr_epoch)\n",
    "        else:\n",
    "            return MAX_LR * 2 ** -(NUM_WARMUP_EPOCHS - curr_epoch)\n",
    "    else:\n",
    "        progress = float(curr_epoch - NUM_WARMUP_EPOCHS) / float(max(1, NUM_EPOCHS - NUM_WARMUP_EPOCHS))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * float(num_cycles) * 2.0 * progress))) * MAX_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lrs.append(lrfn(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"learnig rate\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_learning_rate(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_learning_rate(optimizer, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop with lr scheduler\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    lr = lrfn(epoch)\n",
    "    set_learning_rate(optimizer, lr)\n",
    "    for idx, (x, y, decoder_input_ids) in enumerate(tqdm(train_dataloader, leave=False)):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AdamW' object has no attribute 'set_learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_learning_rate\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AdamW' object has no attribute 'set_learning_rate'"
     ]
    }
   ],
   "source": [
    "optimizer.set_learning_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:02:00.286230Z",
     "iopub.status.busy": "2023-08-12T12:02:00.284821Z",
     "iopub.status.idle": "2023-08-12T12:28:37.191547Z",
     "shell.execute_reply": "2023-08-12T12:28:37.190338Z",
     "shell.execute_reply.started": "2023-08-12T12:02:00.286198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2348e401e6fb4b4e97cad89b8ee77025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] Average Loss: 3.6485833376297068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] Average Loss: 2.979034242641172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] Average Loss: 2.8001710299306506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] Average Loss: 2.684578960059119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] Average Loss: 2.592265480854472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] Average Loss: 2.5163696261702992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40] Average Loss: 2.452917773215497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40] Average Loss: 2.3983193362345463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40] Average Loss: 2.350876331887703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40] Average Loss: 2.308725780848876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40] Average Loss: 2.2698094554472306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40] Average Loss: 2.232404386131769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40] Average Loss: 2.1948934313284987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40] Average Loss: 2.1578163003474824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40] Average Loss: 2.1223648807483197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40] Average Loss: 2.089654674993466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40] Average Loss: 2.0597638889833134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40] Average Loss: 2.0325539011586744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40] Average Loss: 2.0079489055785418\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40] Average Loss: 1.9850425051581944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40] Average Loss: 1.9640883184986875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40] Average Loss: 1.9445345270549943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40] Average Loss: 1.9261500120721322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/40] Average Loss: 1.9091417295312993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/40] Average Loss: 1.8925882039081297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/40] Average Loss: 1.8771341133173511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/40] Average Loss: 1.8624904426534505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/40] Average Loss: 1.8487874689649364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/40] Average Loss: 1.83545682329763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/40] Average Loss: 1.8230387518221656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/40] Average Loss: 1.8111366919946335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/40] Average Loss: 1.799624590460534\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/40] Average Loss: 1.7889782085630876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/40] Average Loss: 1.7786412230699347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/40] Average Loss: 1.7686405017169353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/40] Average Loss: 1.7593151395158968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/40] Average Loss: 1.7501832477102794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/40] Average Loss: 1.7415163632857436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/40] Average Loss: 1.7332004229134643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/40] Average Loss: 1.725244686251781\n"
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "for epoch in tqdm(range(NUM_EPOCHS * 2)):\n",
    "    total_loss = 0\n",
    "    # loop = tqdm(train_dataloader, leave=False)\n",
    "    #train_NDs = [] # array with pairs (N, D) \n",
    "    for (x, y, decoder_input_ids) in tqdm(train_dataloader, leave=False):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "        out = model(x, decoder_input_ids)\n",
    "        #print(out.shape)        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(out.view(-1, N_UNIQUE_CHARACTERS), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # if epoch % 5 == 0:\n",
    "        #     train_NDs.append(metric(out, y))\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS * 2}] Average Loss: {avg_loss}\")\n",
    "    epoch_losses.append(avg_loss)\n",
    "        \n",
    "\n",
    "\n",
    "        # validation score \n",
    "    # CHANGE NAME FOR LOOP!!!!!!!!!!!!!!!!!!!!!\n",
    "        # loop = tqdm(val_dataloader, leave=False)\n",
    "        # for (x, y) in loop:\n",
    "        #     x = x.to(device)\n",
    "        #     y = y.to(device)\n",
    "        #     with torch.no_grad():\n",
    "        #         out = model(x)\n",
    "        #     loss = loss_fn(out.view(BATCH_SIZE, -1, 31), y)\n",
    "        #     val_losses.append(loss.item())\n",
    "        \n",
    "        # print(f\"Validation loss on epoch â„–{epoch + 1} = {sum(val_losses) / len(val_losses)}\\nbtw train loss = {mean_loss}\")\n",
    "        \n",
    "        \n",
    "    #val_losses = []\n",
    "    # if epoch % 5 == 0:\n",
    "    #     # compute levenshtein distance on validation data\n",
    "    #     loop = tqdm(val_dataloader, leave=False)\n",
    "    #     val_NDs = []\n",
    "    #     for (x,y) in loop:\n",
    "    #         x = x.to(device)\n",
    "    #         y = y.to(device)\n",
    "    #         with torch.no_grad():\n",
    "    #             out = model(x)\n",
    "    #         val_NDs.append(metric(out, y))\n",
    "            \n",
    "    #     train_distance = 1 - sum(x[1] for x in train_NDs) / sum(x[0] for x in train_NDs)\n",
    "    #     val_distance = 1 - sum(x[1] for x in val_NDs) / sum(x[0] for x in val_NDs)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #     print(f\"epochâ„– {epoch + 1}\\ntrain_distance = {train_distance}\\nval_distance = {val_distance}\\n\\n\")\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:28:42.504791Z",
     "iopub.status.busy": "2023-08-12T12:28:42.504364Z",
     "iopub.status.idle": "2023-08-12T12:28:42.795150Z",
     "shell.execute_reply": "2023-08-12T12:28:42.794184Z",
     "shell.execute_reply.started": "2023-08-12T12:28:42.504758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_losses)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:06:03.471613Z",
     "iopub.status.busy": "2023-08-12T13:06:03.471161Z",
     "iopub.status.idle": "2023-08-12T13:06:03.476281Z",
     "shell.execute_reply": "2023-08-12T13:06:03.475286Z",
     "shell.execute_reply.started": "2023-08-12T13:06:03.471578Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/working/checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T12:50:29.909327Z",
     "iopub.status.busy": "2023-08-12T12:50:29.908598Z",
     "iopub.status.idle": "2023-08-12T12:50:29.945435Z",
     "shell.execute_reply": "2023-08-12T12:50:29.944438Z",
     "shell.execute_reply.started": "2023-08-12T12:50:29.909291Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:06:03.479265Z",
     "iopub.status.busy": "2023-08-12T13:06:03.478233Z",
     "iopub.status.idle": "2023-08-12T13:06:04.250615Z",
     "shell.execute_reply": "2023-08-12T13:06:04.248932Z",
     "shell.execute_reply.started": "2023-08-12T13:06:03.479231Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/checkpoint.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/checkpoint.pth.tar'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(PATH, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:06:48.516988Z",
     "iopub.status.busy": "2023-08-12T13:06:48.516560Z",
     "iopub.status.idle": "2023-08-12T13:06:48.529012Z",
     "shell.execute_reply": "2023-08-12T13:06:48.528041Z",
     "shell.execute_reply.started": "2023-08-12T13:06:48.516953Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_sequence_id = example_parquet_df.index.unique()[9]\n",
    "demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:06:48.836360Z",
     "iopub.status.busy": "2023-08-12T13:06:48.835386Z",
     "iopub.status.idle": "2023-08-12T13:06:49.237131Z",
     "shell.execute_reply": "2023-08-12T13:06:49.236005Z",
     "shell.execute_reply.started": "2023-08-12T13:06:48.836324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>8__mz(,1 (,1q[l:f m:$b?n umz:(_m'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(demo_raw_data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:06:32.648846Z",
     "iopub.status.busy": "2023-08-12T13:06:32.648557Z",
     "iopub.status.idle": "2023-08-12T13:06:32.655965Z",
     "shell.execute_reply": "2023-08-12T13:06:32.654967Z",
     "shell.execute_reply.started": "2023-08-12T13:06:32.648821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>8__mz(,1 (,1q[l:f m:$b?n umz:(_m'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:19:20.111254Z",
     "iopub.status.busy": "2023-08-12T17:19:20.110891Z",
     "iopub.status.idle": "2023-08-12T17:19:32.563332Z",
     "shell.execute_reply": "2023-08-12T17:19:32.562149Z",
     "shell.execute_reply.started": "2023-08-12T17:19:20.111224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx_tf\n",
      "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in /opt/conda/lib/python3.10/site-packages (from onnx_tf) (1.14.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from onnx_tf) (6.0)\n",
      "Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (from onnx_tf) (0.20.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.10/site-packages (from onnx>=1.10.2->onnx_tf) (4.6.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons->onnx_tf) (21.3)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons->onnx_tf) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow-addons->onnx_tf) (3.0.9)\n",
      "Installing collected packages: onnx_tf\n",
      "Successfully installed onnx_tf-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:19:32.566300Z",
     "iopub.status.busy": "2023-08-12T17:19:32.565593Z",
     "iopub.status.idle": "2023-08-12T17:19:45.655655Z",
     "shell.execute_reply": "2023-08-12T17:19:45.654433Z",
     "shell.execute_reply.started": "2023-08-12T17:19:32.566260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.12.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-lite (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-lite\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow tensorflow-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:21:20.740207Z",
     "iopub.status.busy": "2023-08-12T17:21:20.739459Z",
     "iopub.status.idle": "2023-08-12T17:21:31.072190Z",
     "shell.execute_reply": "2023-08-12T17:21:31.071236Z",
     "shell.execute_reply.started": "2023-08-12T17:21:20.740168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import tensorflow as tf\n",
    "import onnx_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:38.800597Z",
     "iopub.status.busy": "2023-08-12T17:22:38.800231Z",
     "iopub.status.idle": "2023-08-12T17:22:38.808471Z",
     "shell.execute_reply": "2023-08-12T17:22:38.807568Z",
     "shell.execute_reply.started": "2023-08-12T17:22:38.800563Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_tflite(nodel, name, path_to_models=\"../models\"):\n",
    "    demo_sequence_id = example_parquet_df.index.unique()[19]\n",
    "    demo_raw_data = example_parquet_df.loc[demo_sequence_id, COLUMNS0]\n",
    "    onnx_model_path = f\"{path_to_models}/{name}.onnx\"\n",
    "    tf_model_path = \"tf_model\"\n",
    "    tflite_model_path = f\"{path_to_models}/{name}.tflite\"\n",
    "    opset_version = 12 # ? i don't know if it's a right value\n",
    "    torch.onnx.export(\n",
    "        model,                       # PyTorch Model\n",
    "        torch.from_numpy(demo_raw_data.values),                # Input tensor\n",
    "        onnx_model_path,             # Output file (eg. 'output_model.onnx')\n",
    "        opset_version=opset_version, # Operator support version\n",
    "    )\n",
    "    \n",
    "    print(\"converting from onnx to tensorflow...\")\n",
    "    onnx_model = onnx.load(onnx_model_path)\n",
    "    tf_model = onnx_tf.backend.prepare(onnx_model)\n",
    "    tf_model.export_graph(tf_model_path)\n",
    "\n",
    "    print(\"converting from tensorflow to tflite\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "    tflite_model = converter.convert()\n",
    "    # Save the model\n",
    "    with open(tflite_model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"converting finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T17:22:38.810617Z",
     "iopub.status.busy": "2023-08-12T17:22:38.809976Z",
     "iopub.status.idle": "2023-08-12T17:22:45.271768Z",
     "shell.execute_reply": "2023-08-12T17:22:45.269876Z",
     "shell.execute_reply.started": "2023-08-12T17:22:38.810584Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/2885654078.py:14: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  data = torch.where(torch.isnan(data0), torch.tensor(0.0), data0)\n",
      "/tmp/ipykernel_28/2885654078.py:26: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  N_FRAMES = len(data)\n",
      "/tmp/ipykernel_28/2885654078.py:45: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  return resized_data.view(len(resized_data), N_TARGET_FRAMES, N_COLS // 2, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvert_to_tflite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_transformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 8\u001b[0m, in \u001b[0;36mconvert_to_tflite\u001b[0;34m(nodel, name, path_to_models)\u001b[0m\n\u001b[1;32m      6\u001b[0m tflite_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m opset_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;66;03m# ? i don't know if it's a right value\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# PyTorch Model\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_raw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Input tensor\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Output file (eg. 'output_model.onnx')\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Operator support version\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting from onnx to tensorflow...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(onnx_model_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    190\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[38;5;28mbool\u001b[39m, Collection[Type[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1563\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1564\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1112\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:989\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    984\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    985\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     )\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    991\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/onnx/utils.py:893\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    891\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    892\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 893\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    902\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/jit/_trace.py:1268\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1267\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1268\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/jit/_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 127\u001b[0m graph, out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[38;5;241m0\u001b[39m], ret_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/jit/_trace.py:118\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    117\u001b[0m     inputs_states\u001b[38;5;241m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 118\u001b[0m outs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    120\u001b[0m     inputs_states[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (inputs_states[\u001b[38;5;241m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[36], line 14\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x, decoder_input_ids)\u001b[0m\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x, decoder_input_ids)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[0;32mIn[36], line 27\u001b[0m, in \u001b[0;36mModel.inference\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_PHRASE_LENGTH):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     28\u001b[0m     token \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m     trg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((trg, token), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x, decoder_input_ids)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn(x) \u001b[38;5;66;03m# [B, T, Vocab_size]\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[30], line 221\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m    219\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_src_mask(src)\n\u001b[1;32m    220\u001b[0m trg_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_trg_mask(trg)\n\u001b[0;32m--> 221\u001b[0m enc_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(trg, enc_src, src_mask, trg_mask)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "Cell \u001b[0;32mIn[30], line 97\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m N, seq_length, vocab \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     95\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, seq_length)\u001b[38;5;241m.\u001b[39mexpand(N, seq_length)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# x B, Seq_len, vocab_size\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# pos B, Seq_len, n_embd\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# since we are in encoder and values, queries and keys are the same\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "convert_to_tflite(model, \"my_transformer\", path_to_models=\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:02:55.775320Z",
     "iopub.status.busy": "2023-08-12T13:02:55.774918Z",
     "iopub.status.idle": "2023-08-12T13:02:55.780853Z",
     "shell.execute_reply": "2023-08-12T13:02:55.779638Z",
     "shell.execute_reply.started": "2023-08-12T13:02:55.775287Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:13:34.628191Z",
     "iopub.status.busy": "2023-08-12T13:13:34.627766Z",
     "iopub.status.idle": "2023-08-12T13:13:35.767582Z",
     "shell.execute_reply": "2023-08-12T13:13:35.766121Z",
     "shell.execute_reply.started": "2023-08-12T13:13:34.628160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: tf_model/ (stored 0%)\n",
      "  adding: tf_model/variables/ (stored 0%)\n",
      "  adding: tf_model/variables/variables.data-00000-of-00001 (deflated 23%)\n",
      "  adding: tf_model/variables/variables.index (deflated 33%)\n",
      "  adding: tf_model/assets/ (stored 0%)\n",
      "  adding: tf_model/fingerprint.pb (stored 0%)\n",
      "  adding: tf_model/saved_model.pb (deflated 71%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r tf_model.zip tf_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-12T13:11:52.334262Z",
     "iopub.status.busy": "2023-08-12T13:11:52.333884Z",
     "iopub.status.idle": "2023-08-12T13:11:53.455940Z",
     "shell.execute_reply": "2023-08-12T13:11:53.454742Z",
     "shell.execute_reply.started": "2023-08-12T13:11:52.334234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_transformer.onnx  tf_model\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = SignRecognition(128)\n",
    "transformer = Transformer(63, 63, PAD_TOKEN, PAD_TOKEN, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.randn(1, 128, 82, 2)\n",
    "data2 = torch.randn(1, 128, 82, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20,  6, 39, 59,  6, 57, 36,  9, 60, 40, 39,  9, 39, 59, 40, 11, 41, 62,\n",
       "         11, 11,  6, 36, 30, 20, 43, 62, 15,  9, 60]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(cnn(data1), torch.randint(0, 63, size=[1, 29])).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52, 36, 38, 11,  4, 11, 33,  9, 26,  9, 39,  9, 15,  9,  9,  9, 36, 31,\n",
       "         62,  6, 57, 60, 30,  9, 54, 11, 11, 57, 62]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(cnn(data2), torch.randint(0, 63, size=[1, 29])).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignRecognition(\n",
       "  (conv1): Conv2d(128, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin1): Linear(in_features=41, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=63, bias=True)\n",
       "  (gelu): GELU(approximate='none')\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
